{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load required libraries\n",
    "library(caret)\n",
    "library(randomForest)\n",
    "library(MASS)\n",
    "library(mclust)\n",
    "library(glmnet)\n",
    "library(mgcv)\n",
    "\n",
    "###################\n",
    "# REGRESSION PART #\n",
    "###################\n",
    "\n",
    "# Best performing features from analysis\n",
    "SELECTED_FEATURES <- c(\"X1\", \"X10\", \"X13\", \"X15\", \"X19\", \"X2\", \"X20\", \"X21\", \n",
    "                      \"X25\", \"X27\", \"X29\", \"X3\", \"X30\", \"X31\", \"X33\", \"X4\", \n",
    "                      \"X40\", \"X42\", \"X43\", \"X44\", \"X45\", \"X46\", \"X47\", \"X48\", \n",
    "                      \"X51\", \"X54\", \"X55\", \"X56\", \"X57\", \"X58\", \"X59\", \"X6\", \n",
    "                      \"X61\", \"X62\", \"X67\", \"X69\", \"X71\", \"X72\", \"X76\", \"X77\", \n",
    "                      \"X8\", \"X80\", \"X81\", \"X84\", \"X87\", \"X89\", \"X92\", \"X93\", \n",
    "                      \"X96\", \"X99\")\n",
    "\n",
    "# Read and prepare regression data\n",
    "X.reg <- read.table(\"a24_reg_app.txt\")\n",
    "X <- X.reg[, -ncol(X.reg)]\n",
    "y <- X.reg$y\n",
    "\n",
    "# Train GAM model with selected features\n",
    "gam_formula <- as.formula(paste(\"y ~\", paste(sprintf(\"s(%s, bs='cr')\", SELECTED_FEATURES), collapse = \" + \")))\n",
    "reg <- gam(gam_formula, data = data.frame(X, y = y), method = \"REML\",select = TRUE)\n",
    "\n",
    "######################\n",
    "# CLASSIFICATION PART #\n",
    "######################\n",
    "\n",
    "# Utility functions for classification\n",
    "get_kernel_features <- function(x, centers, sigma = 1) {\n",
    "    kernels <- apply(centers, 1, function(c) {\n",
    "        exp(-rowSums((sweep(x, 2, c))^2) / (2 * sigma^2))\n",
    "    })\n",
    "    return(kernels)\n",
    "}\n",
    "\n",
    "get_gmm_predictions <- function(model, newdata) {\n",
    "    kernel_features <- get_kernel_features(newdata, model$centers, model$sigma)\n",
    "    probs <- predict(model$gmm, kernel_features, what = \"z\")\n",
    "    return(probs)\n",
    "}\n",
    "\n",
    "train_kernel_gmm <- function(data, G = 3, kernel_sigma = 1) {\n",
    "    scaled_data <- scale(data)\n",
    "    init_clusters <- kmeans(scaled_data, centers = G)\n",
    "    centers <- init_clusters$centers\n",
    "    kernel_features <- get_kernel_features(scaled_data, centers, kernel_sigma)\n",
    "    gmm_model <- Mclust(kernel_features, G = G)\n",
    "    return(list(\n",
    "        gmm = gmm_model,\n",
    "        centers = centers,\n",
    "        sigma = kernel_sigma\n",
    "    ))\n",
    "}\n",
    "\n",
    "get_qda_predictions <- function(model, newdata) {\n",
    "    pred_probs <- predict(model, newdata)$posterior\n",
    "    return(pred_probs)\n",
    "}\n",
    "\n",
    "get_rf_predictions <- function(model, newdata) {\n",
    "    pred_probs <- predict(model, newdata, type = \"prob\")\n",
    "    return(pred_probs)\n",
    "}\n",
    "\n",
    "combine_predictions <- function(qda_pred, skewed_pred, ord_pred) {\n",
    "    df1 <- as.data.frame(qda_pred)\n",
    "    names(df1) <- paste0(\"qda_\", 1:ncol(df1))\n",
    "    \n",
    "    df2 <- as.data.frame(skewed_pred)\n",
    "    names(df2) <- paste0(\"skewed_\", 1:ncol(df2))\n",
    "    \n",
    "    df3 <- as.data.frame(ord_pred)\n",
    "    names(df3) <- paste0(\"ord_\", 1:ncol(df3))\n",
    "    \n",
    "    combined_df <- cbind(df1, df2, df3)\n",
    "    return(as.data.frame(combined_df))\n",
    "}\n",
    "\n",
    "# Read and prepare classification data\n",
    "X.clas = read.table(\"a24_clas_app.txt\", header = TRUE, sep=\" \")\n",
    "X.clas$y <- as.factor(X.clas$y)\n",
    "\n",
    "# Train classification model\n",
    "clas <- {\n",
    "    # Define variable groups\n",
    "    gaussian_vars <- paste0(\"X\", 21:45)\n",
    "    skewed_vars <- paste0(\"X\", 1:20)\n",
    "    ordinal_vars <- paste0(\"X\", 46:50)\n",
    "    \n",
    "    # Preprocess parameters\n",
    "    preprocess_params <- preProcess(X.clas[, c(gaussian_vars, skewed_vars, ordinal_vars)], \n",
    "                                  method = c(\"center\", \"scale\"))\n",
    "    \n",
    "    data_scaled <- X.clas\n",
    "    data_scaled[, c(gaussian_vars, skewed_vars, ordinal_vars)] <- \n",
    "        predict(preprocess_params, X.clas[, c(gaussian_vars, skewed_vars, ordinal_vars)])\n",
    "    \n",
    "    # Train models\n",
    "    skewed_matrix <- as.matrix(data_scaled[, skewed_vars])\n",
    "    skewed_model <- train_kernel_gmm(skewed_matrix, G = 3)\n",
    "    qda_model <- qda(y ~ ., data = data_scaled[, c(\"y\", gaussian_vars)])\n",
    "    rf_model <- randomForest(y ~ ., \n",
    "                           data = data_scaled[, c(\"y\", ordinal_vars)],\n",
    "                           ntree = 500, \n",
    "                           mtry = ceiling(sqrt(length(ordinal_vars))),\n",
    "                           nodesize = 5)\n",
    "    \n",
    "    # Get training predictions\n",
    "    skewed_pred <- get_gmm_predictions(skewed_model, skewed_matrix)\n",
    "    qda_pred <- get_qda_predictions(qda_model, data_scaled[, gaussian_vars])\n",
    "    rf_pred <- get_rf_predictions(rf_model, data_scaled[, ordinal_vars])\n",
    "    \n",
    "    # Combine predictions\n",
    "    meta_features <- combine_predictions(qda_pred, skewed_pred, rf_pred)\n",
    "    \n",
    "    # Train meta-learner\n",
    "    meta_rf <- randomForest(\n",
    "        x = meta_features,\n",
    "        y = X.clas$y,\n",
    "        ntree = 500,\n",
    "        mtry = ceiling(sqrt(ncol(meta_features))),\n",
    "        nodesize = 5\n",
    "    )\n",
    "    \n",
    "    list(\n",
    "        skewed_model = skewed_model,\n",
    "        qda_model = qda_model,\n",
    "        rf_model = rf_model,\n",
    "        meta_rf = meta_rf,\n",
    "        preprocess_params = preprocess_params,\n",
    "        var_groups = list(\n",
    "            gaussian_vars = gaussian_vars,\n",
    "            skewed_vars = skewed_vars,\n",
    "            ordinal_vars = ordinal_vars\n",
    "        )\n",
    "    )\n",
    "}\n",
    "\n",
    "##################\n",
    "# FINAL FUNCTIONS #\n",
    "##################\n",
    "\n",
    "# Regression function\n",
    "regresseur <- function(test_set) {\n",
    "    library(mgcv)\n",
    "    predict(reg, test_set)\n",
    "}\n",
    "\n",
    "# Classification function\n",
    "classifieur <- function(test_set) {\n",
    "    library(caret)\n",
    "    library(randomForest)\n",
    "    library(MASS)\n",
    "    library(mclust)\n",
    "    \n",
    "    # Define utility functions inside classifieur\n",
    "    get_kernel_features <- function(x, centers, sigma = 1) {\n",
    "        kernels <- apply(centers, 1, function(c) {\n",
    "            exp(-rowSums((sweep(x, 2, c))^2) / (2 * sigma^2))\n",
    "        })\n",
    "        return(kernels)\n",
    "    }\n",
    "    \n",
    "    get_gmm_predictions <- function(model, newdata) {\n",
    "        kernel_features <- get_kernel_features(newdata, model$centers, model$sigma)\n",
    "        probs <- predict(model$gmm, kernel_features, what = \"z\")\n",
    "        return(probs)\n",
    "    }\n",
    "    \n",
    "    get_qda_predictions <- function(model, newdata) {\n",
    "        pred_probs <- predict(model, newdata)$posterior\n",
    "        return(pred_probs)\n",
    "    }\n",
    "    \n",
    "    get_rf_predictions <- function(model, newdata) {\n",
    "        pred_probs <- predict(model, newdata, type = \"prob\")\n",
    "        return(pred_probs)\n",
    "    }\n",
    "    \n",
    "    combine_predictions <- function(qda_pred, skewed_pred, ord_pred) {\n",
    "        df1 <- as.data.frame(qda_pred)\n",
    "        names(df1) <- paste0(\"qda_\", 1:ncol(df1))\n",
    "        \n",
    "        df2 <- as.data.frame(skewed_pred)\n",
    "        names(df2) <- paste0(\"skewed_\", 1:ncol(df2))\n",
    "        \n",
    "        df3 <- as.data.frame(ord_pred)\n",
    "        names(df3) <- paste0(\"ord_\", 1:ncol(df3))\n",
    "        \n",
    "        combined_df <- cbind(df1, df2, df3)\n",
    "        return(as.data.frame(combined_df))\n",
    "    }\n",
    "    \n",
    "    # Get variable groups\n",
    "    gaussian_vars <- clas$var_groups$gaussian_vars\n",
    "    skewed_vars <- clas$var_groups$skewed_vars\n",
    "    ordinal_vars <- clas$var_groups$ordinal_vars\n",
    "    \n",
    "    # Scale new data\n",
    "    scaled_data <- test_set\n",
    "    scaled_data[, c(gaussian_vars, skewed_vars, ordinal_vars)] <- \n",
    "        predict(clas$preprocess_params, test_set[, c(gaussian_vars, skewed_vars, ordinal_vars)])\n",
    "    \n",
    "    # Get predictions\n",
    "    skewed_matrix <- as.matrix(scaled_data[, skewed_vars])\n",
    "    skewed_pred <- get_gmm_predictions(clas$skewed_model, skewed_matrix)\n",
    "    qda_pred <- get_qda_predictions(clas$qda_model, scaled_data[, gaussian_vars])\n",
    "    rf_pred <- get_rf_predictions(clas$rf_model, scaled_data[, ordinal_vars])\n",
    "    \n",
    "    # Combine predictions\n",
    "    meta_features <- combine_predictions(qda_pred, skewed_pred, rf_pred)\n",
    "    \n",
    "    # Get final predictions\n",
    "    predict(clas$meta_rf, meta_features)\n",
    "}\n",
    "\n",
    "# Save everything needed\n",
    "save(\"clas\", \"reg\", \"classifieur\", \"regresseur\", file = \"env.Rdata\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression MSE: 77.08018 \n",
      "Classification Accuracy: 98.66667 %\n",
      "[1] \"Classification Confusion Matrix:\"\n",
      "                actual_labels_clas\n",
      "clas_predictions  1  2  3\n",
      "               1 29  0  0\n",
      "               2  0 62  0\n",
      "               3  1  1 57\n"
     ]
    }
   ],
   "source": [
    "# Test the saved models\n",
    "rm(list = ls())\n",
    "load(\"env.Rdata\")\n",
    "\n",
    "# Test regression\n",
    "test_reg <- read.table(\"a24_reg_app.txt\")\n",
    "set.seed(123)\n",
    "test_indices_reg <- sample(1:nrow(test_reg), size = round(0.3 * nrow(test_reg)))\n",
    "test_data_reg <- test_reg[test_indices_reg, -ncol(test_reg)]\n",
    "actual_values_reg <- test_reg[test_indices_reg, \"y\"]\n",
    "\n",
    "# Make regression predictions\n",
    "reg_predictions <- regresseur(test_data_reg)\n",
    "cat(\"Regression MSE:\", mean((reg_predictions - actual_values_reg)^2), \"\\n\")\n",
    "\n",
    "# Test classification\n",
    "test_clas <- read.table(\"a24_clas_app.txt\", header = TRUE, sep=\" \")\n",
    "set.seed(123)\n",
    "test_indices_clas <- sample(1:nrow(test_clas), size = round(0.3 * nrow(test_clas)))\n",
    "test_data_clas <- test_clas[test_indices_clas, -ncol(test_clas)]\n",
    "actual_labels_clas <- test_clas[test_indices_clas, \"y\"]\n",
    "\n",
    "# Make classification predictions\n",
    "clas_predictions <- classifieur(test_data_clas)\n",
    "cat(\"Classification Accuracy:\", mean(clas_predictions == actual_labels_clas) * 100, \"%\\n\")\n",
    "print(\"Classification Confusion Matrix:\")\n",
    "print(table(clas_predictions, actual_labels_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting nested cross-validation evaluation\n",
      "Fold 1/5 - LASSO MSE: 109.04, GAM MSE: 109.91\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load required packages\n",
    "library(glmnet)\n",
    "library(caret)\n",
    "library(dplyr)\n",
    "library(mgcv)\n",
    "\n",
    "# Best performing features from previous analysis\n",
    "SELECTED_FEATURES <- c(\"X1\", \"X10\", \"X13\", \"X15\", \"X19\", \"X2\", \"X20\", \"X21\", \n",
    "                      \"X25\", \"X27\", \"X29\", \"X3\", \"X30\", \"X31\", \"X33\", \"X4\", \n",
    "                      \"X40\", \"X42\", \"X43\", \"X44\", \"X45\", \"X46\", \"X47\", \"X48\", \n",
    "                      \"X51\", \"X54\", \"X55\", \"X56\", \"X57\", \"X58\", \"X59\", \"X6\", \n",
    "                      \"X61\", \"X62\", \"X67\", \"X69\", \"X71\", \"X72\", \"X76\", \"X77\", \n",
    "                      \"X8\", \"X80\", \"X81\", \"X84\", \"X87\", \"X89\", \"X92\", \"X93\", \n",
    "                      \"X96\", \"X99\")\n",
    "\n",
    "# Nested cross-validation evaluation\n",
    "evaluate_models <- function(X, y, outer_folds = 5, inner_folds = 5) {\n",
    "    set.seed(42)\n",
    "    outer_cv <- createFolds(y, k = outer_folds, list = TRUE)\n",
    "    \n",
    "    # Results storage\n",
    "    lasso_scores <- numeric(outer_folds)\n",
    "    gam_scores <- numeric(outer_folds)\n",
    "    \n",
    "    cat(\"\\nStarting nested cross-validation evaluation\\n\")\n",
    "    \n",
    "    for(fold in 1:outer_folds) {\n",
    "        # Split data\n",
    "        test_idx <- outer_cv[[fold]]\n",
    "        X_train <- X[-test_idx, ]\n",
    "        y_train <- y[-test_idx]\n",
    "        X_test <- X[test_idx, ]\n",
    "        y_test <- y[test_idx]\n",
    "        \n",
    "        # 1. LASSO\n",
    "        cv_lasso <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, nfolds = inner_folds)\n",
    "        lasso_pred <- predict(cv_lasso, newx = as.matrix(X_test), s = \"lambda.min\")\n",
    "        lasso_scores[fold] <- mean((y_test - lasso_pred)^2)\n",
    "        \n",
    "        # 2. GAM with pre-selected features\n",
    "        gam_formula <- as.formula(paste(\"y ~\", \n",
    "            paste(sprintf(\"s(%s, bs='cr')\", SELECTED_FEATURES), collapse = \" + \")))\n",
    "        gam_model <- gam(gam_formula, \n",
    "                        data = data.frame(X_train, y = y_train), \n",
    "                        method = \"REML\",select=TRUE)\n",
    "        \n",
    "        gam_pred <- predict(gam_model, \n",
    "                          newdata = data.frame(X_test))\n",
    "        gam_scores[fold] <- mean((y_test - gam_pred)^2)\n",
    "        \n",
    "        cat(sprintf(\"Fold %d/%d - LASSO MSE: %.2f, GAM MSE: %.2f\\n\", \n",
    "                   fold, outer_folds, lasso_scores[fold], gam_scores[fold]))\n",
    "        flush.console()\n",
    "    }\n",
    "    \n",
    "    # Summarize results\n",
    "    results <- data.frame(\n",
    "        Model = c(\"LASSO\", \"GAM (Pre-selected features)\"),\n",
    "        Mean_MSE = c(mean(lasso_scores), mean(gam_scores)),\n",
    "        SD_MSE = c(sd(lasso_scores), sd(gam_scores))\n",
    "    )\n",
    "    \n",
    "    return(list(\n",
    "        summary = results,\n",
    "        lasso_scores = lasso_scores,\n",
    "        gam_scores = gam_scores\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Main execution\n",
    "main <- function() {\n",
    "    # Read data\n",
    "    X.reg <- read.table(\"a24_reg_app.txt\")\n",
    "    X <- X.reg[, -ncol(X.reg)]\n",
    "    y <- X.reg$y\n",
    "    \n",
    "    # Run evaluation\n",
    "    results <- evaluate_models(X, y)\n",
    "    \n",
    "    # Print results\n",
    "    cat(\"\\n=== FINAL RESULTS ===\\n\")\n",
    "    print(results$summary)\n",
    "    \n",
    "    return(results)\n",
    "}\n",
    "\n",
    "# Run analysis\n",
    "results <- main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting nested cross-validation evaluation\n",
      "Fold 1/5 - Accuracy: 0.7000\n",
      "Fold 2/5 - Accuracy: 0.6337\n",
      "Fold 3/5 - Accuracy: 0.7030\n",
      "Fold 4/5 - Accuracy: 0.7172\n",
      "Fold 5/5 - Accuracy: 0.6970\n",
      "\n",
      "=== NESTED CV RESULTS ===\n",
      "Individual fold accuracies:\n",
      "[1] 0.7000000 0.6336634 0.7029703 0.7171717 0.6969697\n",
      "\n",
      "Mean Accuracy: 0.6902 (±0.0325)\n",
      "\n",
      "Confusion Matrix:\n",
      "         Actual\n",
      "Predicted   1   2   3\n",
      "        1  27  14  17\n",
      "        2  30 190  46\n",
      "        3  25  23 128\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries\n",
    "library(caret)\n",
    "library(randomForest)\n",
    "library(MASS)\n",
    "\n",
    "# Function to evaluate classifier with nested CV\n",
    "evaluate_classifier <- function(data, outer_folds=5, inner_folds=5) {\n",
    "    set.seed(123)\n",
    "    \n",
    "    # Define variable groups\n",
    "    gaussian_vars <- paste0(\"X\", 21:45)\n",
    "    ordinal_vars <- paste0(\"X\", 46:50)\n",
    "    \n",
    "    # Create outer folds\n",
    "    outer_cv <- createFolds(data$y, k=outer_folds, list=TRUE)\n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    \n",
    "    cat(\"\\nStarting nested cross-validation evaluation\\n\")\n",
    "    \n",
    "    confusion_matrices <- list()\n",
    "    \n",
    "    for(fold in 1:outer_folds) {\n",
    "        # Split data\n",
    "        test_idx <- outer_cv[[fold]]\n",
    "        train_data <- data[-test_idx, ]\n",
    "        test_data <- data[test_idx, ]\n",
    "        \n",
    "        # Train QDA on continuous variables\n",
    "        qda_model <- qda(y ~ ., data = train_data[, c(\"y\", gaussian_vars)])\n",
    "        \n",
    "        # Train RF on ordinal variables\n",
    "        rf_model <- randomForest(y ~ ., \n",
    "                               data = train_data[, c(\"y\", ordinal_vars)],\n",
    "                               ntree = 500,\n",
    "                               mtry = ceiling(sqrt(length(ordinal_vars))),\n",
    "                               nodesize = 5)\n",
    "        \n",
    "        # Get predictions for training meta-learner\n",
    "        train_qda_pred <- predict(qda_model, train_data[, gaussian_vars])$posterior\n",
    "        train_rf_pred <- predict(rf_model, train_data[, ordinal_vars], type = \"prob\")\n",
    "        \n",
    "        # Combine predictions for meta-learner\n",
    "        meta_features_train <- cbind(train_qda_pred, train_rf_pred)\n",
    "        \n",
    "        # Train meta-learner\n",
    "        meta_rf <- randomForest(\n",
    "            x = meta_features_train,\n",
    "            y = train_data$y,\n",
    "            ntree = 500,\n",
    "            mtry = ceiling(sqrt(ncol(meta_features_train))),\n",
    "            nodesize = 5\n",
    "        )\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        test_qda_pred <- predict(qda_model, test_data[, gaussian_vars])$posterior\n",
    "        test_rf_pred <- predict(rf_model, test_data[, ordinal_vars], type = \"prob\")\n",
    "        \n",
    "        # Combine test predictions\n",
    "        meta_features_test <- cbind(test_qda_pred, test_rf_pred)\n",
    "        \n",
    "        # Get final predictions\n",
    "        predictions <- predict(meta_rf, meta_features_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy <- mean(predictions == test_data$y)\n",
    "        outer_scores[fold] <- accuracy\n",
    "        \n",
    "        # Store confusion matrix for this fold\n",
    "        confusion_matrices[[fold]] <- table(Predicted = predictions, \n",
    "                                          Actual = test_data$y)\n",
    "        \n",
    "        cat(sprintf(\"Fold %d/%d - Accuracy: %.4f\\n\", \n",
    "                   fold, outer_folds, accuracy))\n",
    "    }\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    mean_accuracy <- mean(outer_scores)\n",
    "    sd_accuracy <- sd(outer_scores)\n",
    "    \n",
    "    # Combine confusion matrices\n",
    "    total_conf_matrix <- Reduce('+', confusion_matrices)\n",
    "    \n",
    "    # Return results\n",
    "    return(list(\n",
    "        fold_scores = outer_scores,\n",
    "        mean_accuracy = mean_accuracy,\n",
    "        sd_accuracy = sd_accuracy,\n",
    "        confusion_matrix = total_conf_matrix\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Read and prepare data\n",
    "X.clas <- read.table(\"a24_clas_app.txt\", header = TRUE, sep=\" \")\n",
    "X.clas$y <- as.factor(X.clas$y)\n",
    "\n",
    "# Run nested CV evaluation\n",
    "results <- evaluate_classifier(X.clas)\n",
    "\n",
    "# Print comprehensive results\n",
    "cat(\"\\n=== NESTED CV RESULTS ===\\n\")\n",
    "cat(\"Individual fold accuracies:\\n\")\n",
    "print(results$fold_scores)\n",
    "cat(sprintf(\"\\nMean Accuracy: %.4f (±%.4f)\\n\", \n",
    "            results$mean_accuracy, results$sd_accuracy))\n",
    "cat(\"\\nConfusion Matrix:\\n\")\n",
    "print(results$confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "library(caret)\n",
    "library(randomForest)\n",
    "library(MASS)\n",
    "library(mgcv)\n",
    "\n",
    "###################\n",
    "# REGRESSION PART #\n",
    "###################\n",
    "\n",
    "# Best performing features from analysis\n",
    "SELECTED_FEATURES <- c(\"X1\", \"X10\", \"X13\", \"X15\", \"X19\", \"X2\", \"X20\", \"X21\", \n",
    "                      \"X25\", \"X27\", \"X29\", \"X3\", \"X30\", \"X31\", \"X33\", \"X4\", \n",
    "                      \"X40\", \"X42\", \"X43\", \"X44\", \"X45\", \"X46\", \"X47\", \"X48\", \n",
    "                      \"X51\", \"X54\", \"X55\", \"X56\", \"X57\", \"X58\", \"X59\", \"X6\", \n",
    "                      \"X61\", \"X62\", \"X67\", \"X69\", \"X71\", \"X72\", \"X76\", \"X77\", \n",
    "                      \"X8\", \"X80\", \"X81\", \"X84\", \"X87\", \"X89\", \"X92\", \"X93\", \n",
    "                      \"X96\", \"X99\")\n",
    "\n",
    "# Read and prepare regression data\n",
    "X.reg <- read.table(\"a24_reg_app.txt\")\n",
    "X <- X.reg[, -ncol(X.reg)]\n",
    "y <- X.reg$y\n",
    "\n",
    "# Train GAM model with selected features\n",
    "gam_formula <- as.formula(paste(\"y ~\", paste(sprintf(\"s(%s, bs='cr')\", SELECTED_FEATURES), collapse = \" + \")))\n",
    "reg <- gam(gam_formula, data = data.frame(X, y = y), method = \"REML\",select=TRUE)\n",
    "\n",
    "######################\n",
    "# CLASSIFICATION PART #\n",
    "######################\n",
    "\n",
    "# Read classification data\n",
    "X.clas <- read.table(\"a24_clas_app.txt\", header = TRUE, sep=\" \")\n",
    "X.clas$y <- as.factor(X.clas$y)\n",
    "\n",
    "# Define variable groups\n",
    "gaussian_vars <- paste0(\"X\", 21:45)\n",
    "ordinal_vars <- paste0(\"X\", 46:50)\n",
    "\n",
    "# Train QDA on gaussian variables\n",
    "qda_model <- qda(y ~ ., data = X.clas[, c(\"y\", gaussian_vars)])\n",
    "\n",
    "# Train RF on ordinal variables\n",
    "rf_model <- randomForest(y ~ ., \n",
    "                        data = X.clas[, c(\"y\", ordinal_vars)],\n",
    "                        ntree = 500,\n",
    "                        mtry = ceiling(sqrt(length(ordinal_vars))),\n",
    "                        nodesize = 5)\n",
    "\n",
    "# Get predictions for training meta-learner\n",
    "train_qda_pred <- predict(qda_model, X.clas[, gaussian_vars])$posterior\n",
    "train_rf_pred <- predict(rf_model, X.clas[, ordinal_vars], type = \"prob\")\n",
    "\n",
    "# Combine predictions for meta-learner\n",
    "meta_features <- cbind(train_qda_pred, train_rf_pred)\n",
    "\n",
    "# Train meta-learner\n",
    "meta_rf <- randomForest(\n",
    "    x = meta_features,\n",
    "    y = X.clas$y,\n",
    "    ntree = 500,\n",
    "    mtry = ceiling(sqrt(ncol(meta_features))),\n",
    "    nodesize = 5\n",
    ")\n",
    "\n",
    "# Store classification model and parameters\n",
    "clas <- list(\n",
    "    qda_model = qda_model,\n",
    "    rf_model = rf_model,\n",
    "    meta_rf = meta_rf,\n",
    "    var_groups = list(\n",
    "        gaussian_vars = gaussian_vars,\n",
    "        ordinal_vars = ordinal_vars\n",
    "    )\n",
    ")\n",
    "\n",
    "##################\n",
    "# FINAL FUNCTIONS #\n",
    "##################\n",
    "\n",
    "# Regression function\n",
    "regresseur <- function(test_set) {\n",
    "    library(mgcv)\n",
    "    predict(reg, test_set)\n",
    "}\n",
    "\n",
    "# Classification function\n",
    "classifieur <- function(test_set) {\n",
    "    library(caret)\n",
    "    library(randomForest)\n",
    "    library(MASS)\n",
    "    \n",
    "    # Get variable groups\n",
    "    gaussian_vars <- clas$var_groups$gaussian_vars\n",
    "    ordinal_vars <- clas$var_groups$ordinal_vars\n",
    "    \n",
    "    # Get predictions from both models\n",
    "    qda_pred <- predict(clas$qda_model, test_set[, gaussian_vars])$posterior\n",
    "    rf_pred <- predict(clas$rf_model, test_set[, ordinal_vars], type = \"prob\")\n",
    "    \n",
    "    # Combine predictions for meta-learner\n",
    "    meta_features <- cbind(qda_pred, rf_pred)\n",
    "    \n",
    "    # Get final predictions\n",
    "    predict(clas$meta_rf, meta_features)\n",
    "}\n",
    "\n",
    "# Save everything needed\n",
    "save(\"clas\", \"reg\", \"classifieur\", \"regresseur\", file = \"env.Rdata\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression MSE: 77.71846 \n",
      "Classification Accuracy: 88 %\n",
      "[1] \"Classification Confusion Matrix:\"\n",
      "                actual_labels_clas\n",
      "clas_predictions  1  2  3\n",
      "               1 10  1  1\n",
      "               2  0 23  4\n",
      "               3  0  0 11\n"
     ]
    }
   ],
   "source": [
    "# Test the saved models\n",
    "rm(list = ls())\n",
    "load(\"env.Rdata\")\n",
    "\n",
    "# Test regression\n",
    "test_reg <- read.table(\"a24_reg_app.txt\")\n",
    "set.seed(123)\n",
    "test_indices_reg <- sample(1:nrow(test_reg), size = round(0.1 * nrow(test_reg)))\n",
    "test_data_reg <- test_reg[test_indices_reg, -ncol(test_reg)]\n",
    "actual_values_reg <- test_reg[test_indices_reg, \"y\"]\n",
    "\n",
    "# Make regression predictions\n",
    "reg_predictions <- regresseur(test_data_reg)\n",
    "cat(\"Regression MSE:\", mean((reg_predictions - actual_values_reg)^2), \"\\n\")\n",
    "\n",
    "# Test classification\n",
    "test_clas <- read.table(\"a24_clas_app.txt\", header = TRUE, sep=\" \")\n",
    "set.seed(123)\n",
    "test_indices_clas <- sample(1:nrow(test_clas), size = round(0.1 * nrow(test_clas)))\n",
    "test_data_clas <- test_clas[test_indices_clas, -ncol(test_clas)]\n",
    "actual_labels_clas <- test_clas[test_indices_clas, \"y\"]\n",
    "\n",
    "# Make classification predictions\n",
    "clas_predictions <- classifieur(test_data_clas)\n",
    "cat(\"Classification Accuracy:\", mean(clas_predictions == actual_labels_clas) * 100, \"%\\n\")\n",
    "print(\"Classification Confusion Matrix:\")\n",
    "print(table(clas_predictions, actual_labels_clas))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
