{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking and installing required packages...\n",
      "Package 'caret' is already installed and loaded\n",
      "Package 'MASS' is already installed and loaded\n",
      "Package 'randomForest' is already installed and loaded\n",
      "Package 'e1071' is already installed and loaded\n",
      "Package 'ggplot2' is already installed and loaded\n",
      "Package 'dplyr' is already installed and loaded\n",
      "Package 'corrplot' is already installed and loaded\n",
      "Package 'nnet' is already installed and loaded\n",
      "Package 'naivebayes' is already installed and loaded\n",
      "\n",
      "All required packages are installed and loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "required_packages <- c(\n",
    "\"caret\",\n",
    "\"MASS\",\n",
    "\"randomForest\",\n",
    "\"e1071\",\n",
    "\"ggplot2\",\n",
    "\"dplyr\",\n",
    "\"corrplot\",\n",
    "\"nnet\",\n",
    "\"naivebayes\"\n",
    ")\n",
    "\n",
    "# Function to install and load packages\n",
    "install_and_load_packages <- function(packages) {\n",
    "  cat(\"Checking and installing required packages...\\n\")\n",
    "  \n",
    "  for (package in packages) {\n",
    "    if (!require(package, character.only = TRUE, quietly = TRUE)) {\n",
    "      cat(sprintf(\"Installing package: %s\\n\", package))\n",
    "      install.packages(package, dependencies = TRUE)\n",
    "      if (!require(package, character.only = TRUE, quietly = TRUE)) {\n",
    "        stop(sprintf(\"Package '%s' installation failed\", package))\n",
    "      }\n",
    "    } else {\n",
    "      cat(sprintf(\"Package '%s' is already installed and loaded\\n\", package))\n",
    "    }\n",
    "  }\n",
    "  cat(\"\\nAll required packages are installed and loaded!\\n\\n\")\n",
    "}\n",
    "\n",
    "# Install and load all required packages\n",
    "install_and_load_packages(required_packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(MASS)\n",
    "library(randomForest)\n",
    "library(naivebayes)\n",
    "library(e1071)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(corrplot)\n",
    "library(nnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows deleted due to outliers: 27.6 %\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "data <- read.table(\"a24_clas_app.txt\", header = TRUE, sep=\" \")\n",
    "\n",
    "# Convert y to a factor\n",
    "data$y <- as.factor(data$y)\n",
    "\n",
    "# Make a copy of the original data for processing\n",
    "data_cleaned <- data\n",
    "\n",
    "# Identify excluded variables (0-13 values)\n",
    "excluded_vars <- c(\"X46\", \"X47\", \"X48\", \"X49\", \"X50\") \n",
    "numeric_vars <- names(data_cleaned)[sapply(data_cleaned, is.numeric) & !(names(data_cleaned) %in% excluded_vars) & names(data_cleaned) != \"y\"]\n",
    "\n",
    "# Outlier Removal\n",
    "# ------------------\n",
    "# Calculate skewness and IQR filtering for outliers on selected numeric variables only\n",
    "for (var in numeric_vars) {\n",
    "  Q1 <- quantile(data_cleaned[[var]], 0.25, na.rm = TRUE)\n",
    "  Q3 <- quantile(data_cleaned[[var]], 0.75, na.rm = TRUE)\n",
    "  IQR_val <- Q3 - Q1\n",
    "  \n",
    "  lower_bound <- Q1 - 1.5 * IQR_val\n",
    "  upper_bound <- Q3 + 1.5 * IQR_val\n",
    "  \n",
    "  # Remove rows with outliers in any numeric variable\n",
    "  data_cleaned <- data_cleaned[!(data_cleaned[[var]] < lower_bound | data_cleaned[[var]] > upper_bound), ]\n",
    "}\n",
    "\n",
    "# Calculate the ratio of rows deleted\n",
    "cat(\"Rows deleted due to outliers:\", (1 - nrow(data_cleaned) / nrow(data)) * 100, \"%\\n\")\n",
    "\n",
    "# Scaling\n",
    "# ----------\n",
    "# Apply scaling to numeric variables only\n",
    "preprocess_params <- preProcess(data_cleaned[, numeric_vars], method = c(\"center\", \"scale\"))\n",
    "data_scaled <- data_cleaned\n",
    "data_scaled[, numeric_vars] <- predict(preprocess_params, data_cleaned[, numeric_vars])\n",
    "\n",
    "# Separate datasets with and without excluded variables\n",
    "data_with_excluded <- data_scaled\n",
    "data_without_excluded <- data_scaled %>% select(-all_of(excluded_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 69.332750\n",
      "iter  20 value 37.702710\n",
      "iter  30 value 20.341340\n",
      "iter  40 value 3.166699\n",
      "iter  50 value 0.013181\n",
      "final  value 0.000074 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.619008\n",
      "iter  20 value 47.665652\n",
      "iter  30 value 42.906933\n",
      "iter  40 value 41.328498\n",
      "iter  50 value 41.131396\n",
      "iter  60 value 41.109130\n",
      "iter  70 value 41.108523\n",
      "final  value 41.108518 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 69.335180\n",
      "iter  20 value 37.718825\n",
      "iter  30 value 20.435934\n",
      "iter  40 value 4.055007\n",
      "iter  50 value 1.108322\n",
      "iter  60 value 1.031528\n",
      "iter  70 value 0.948186\n",
      "iter  80 value 0.886681\n",
      "iter  90 value 0.861517\n",
      "iter 100 value 0.843646\n",
      "final  value 0.843646 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 57.207446\n",
      "iter  20 value 30.370845\n",
      "iter  30 value 9.329850\n",
      "iter  40 value 0.320099\n",
      "iter  50 value 0.002426\n",
      "final  value 0.000081 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 63.240464\n",
      "iter  20 value 45.449708\n",
      "iter  30 value 42.536892\n",
      "iter  40 value 42.081307\n",
      "iter  50 value 41.984716\n",
      "iter  60 value 41.969047\n",
      "iter  70 value 41.967458\n",
      "final  value 41.967450 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 57.214159\n",
      "iter  20 value 30.393444\n",
      "iter  30 value 9.489507\n",
      "iter  40 value 1.134822\n",
      "iter  50 value 0.954469\n",
      "iter  60 value 0.900729\n",
      "iter  70 value 0.860249\n",
      "iter  80 value 0.835779\n",
      "iter  90 value 0.820488\n",
      "iter 100 value 0.810314\n",
      "final  value 0.810314 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.320329\n",
      "iter  20 value 44.422003\n",
      "iter  30 value 26.558127\n",
      "iter  40 value 6.326938\n",
      "iter  50 value 0.023226\n",
      "final  value 0.000071 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 79.839125\n",
      "iter  20 value 57.438969\n",
      "iter  30 value 53.204853\n",
      "iter  40 value 52.329098\n",
      "iter  50 value 51.904261\n",
      "iter  60 value 51.830298\n",
      "iter  70 value 51.827731\n",
      "final  value 51.827706 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.323057\n",
      "iter  20 value 44.441529\n",
      "iter  30 value 26.678152\n",
      "iter  40 value 6.981319\n",
      "iter  50 value 2.292992\n",
      "iter  60 value 2.091103\n",
      "iter  70 value 1.996983\n",
      "iter  80 value 1.912999\n",
      "iter  90 value 1.831877\n",
      "iter 100 value 1.760405\n",
      "final  value 1.760405 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 123.791409\n",
      "iter  20 value 78.963165\n",
      "iter  30 value 61.774996\n",
      "iter  40 value 46.360130\n",
      "iter  50 value 24.299482\n",
      "iter  60 value 1.708333\n",
      "iter  70 value 0.003807\n",
      "final  value 0.000071 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 82.426729\n",
      "iter  20 value 44.788721\n",
      "iter  30 value 30.084284\n",
      "iter  40 value 15.306979\n",
      "iter  50 value 0.403008\n",
      "iter  60 value 0.000867\n",
      "final  value 0.000062 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 85.122181\n",
      "iter  20 value 56.962433\n",
      "iter  30 value 54.017957\n",
      "iter  40 value 53.310129\n",
      "iter  50 value 53.183466\n",
      "iter  60 value 53.162137\n",
      "iter  70 value 53.161476\n",
      "final  value 53.161467 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 82.429640\n",
      "iter  20 value 44.806286\n",
      "iter  30 value 30.159766\n",
      "iter  40 value 15.791562\n",
      "iter  50 value 3.970221\n",
      "iter  60 value 3.588532\n",
      "iter  70 value 3.296619\n",
      "iter  80 value 3.059448\n",
      "iter  90 value 2.863701\n",
      "iter 100 value 2.733870\n",
      "final  value 2.733870 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 82.031301\n",
      "iter  20 value 49.930756\n",
      "iter  30 value 32.315965\n",
      "iter  40 value 9.258728\n",
      "iter  50 value 0.189194\n",
      "iter  60 value 0.000306\n",
      "final  value 0.000081 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 84.076778\n",
      "iter  20 value 60.680093\n",
      "iter  30 value 57.027647\n",
      "iter  40 value 55.962250\n",
      "iter  50 value 55.744980\n",
      "iter  60 value 55.703810\n",
      "iter  70 value 55.701453\n",
      "final  value 55.701436 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 82.033490\n",
      "iter  20 value 49.946296\n",
      "iter  30 value 32.405999\n",
      "iter  40 value 10.107019\n",
      "iter  50 value 3.298217\n",
      "iter  60 value 3.030692\n",
      "iter  70 value 2.738218\n",
      "iter  80 value 2.515045\n",
      "iter  90 value 2.301007\n",
      "iter 100 value 2.157351\n",
      "final  value 2.157351 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 60.370565\n",
      "iter  20 value 34.851667\n",
      "iter  30 value 21.839400\n",
      "iter  40 value 6.289629\n",
      "iter  50 value 0.019014\n",
      "iter  60 value 0.000127\n",
      "iter  60 value 0.000075\n",
      "iter  60 value 0.000073\n",
      "final  value 0.000073 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 64.563819\n",
      "iter  20 value 47.825701\n",
      "iter  30 value 44.189057\n",
      "iter  40 value 43.529953\n",
      "iter  50 value 43.291821\n",
      "iter  60 value 43.276807\n",
      "iter  70 value 43.276336\n",
      "final  value 43.276316 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 60.375061\n",
      "iter  20 value 34.869721\n",
      "iter  30 value 21.954627\n",
      "iter  40 value 6.865705\n",
      "iter  50 value 1.565722\n",
      "iter  60 value 1.490182\n",
      "iter  70 value 1.420404\n",
      "iter  80 value 1.350846\n",
      "iter  90 value 1.300165\n",
      "iter 100 value 1.257574\n",
      "final  value 1.257574 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 142.937745\n",
      "iter  20 value 94.834627\n",
      "iter  30 value 84.686300\n",
      "iter  40 value 76.694518\n",
      "iter  50 value 71.189767\n",
      "iter  60 value 66.669625\n",
      "iter  70 value 61.884737\n",
      "iter  80 value 59.462631\n",
      "iter  90 value 59.174003\n",
      "iter 100 value 59.055817\n",
      "final  value 59.055817 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 67.192242\n",
      "iter  20 value 32.872219\n",
      "iter  30 value 14.046828\n",
      "iter  40 value 0.588252\n",
      "iter  50 value 0.006496\n",
      "final  value 0.000072 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.907659\n",
      "iter  20 value 46.482353\n",
      "iter  30 value 42.322894\n",
      "iter  40 value 40.447868\n",
      "iter  50 value 40.189630\n",
      "iter  60 value 40.153354\n",
      "iter  70 value 40.151041\n",
      "iter  80 value 40.150804\n",
      "iter  80 value 40.150804\n",
      "iter  80 value 40.150804\n",
      "final  value 40.150804 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 67.196302\n",
      "iter  20 value 32.892751\n",
      "iter  30 value 14.187015\n",
      "iter  40 value 1.537861\n",
      "iter  50 value 1.156364\n",
      "iter  60 value 1.078262\n",
      "iter  70 value 0.982975\n",
      "iter  80 value 0.919190\n",
      "iter  90 value 0.864060\n",
      "iter 100 value 0.817381\n",
      "final  value 0.817381 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 82.201032\n",
      "iter  20 value 51.758630\n",
      "iter  30 value 35.349724\n",
      "iter  40 value 18.451799\n",
      "iter  50 value 4.046084\n",
      "iter  60 value 0.011807\n",
      "final  value 0.000082 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 85.052166\n",
      "iter  20 value 62.739422\n",
      "iter  30 value 59.639578\n",
      "iter  40 value 59.011026\n",
      "iter  50 value 58.909685\n",
      "iter  60 value 58.894838\n",
      "iter  70 value 58.894109\n",
      "final  value 58.894092 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 82.204116\n",
      "iter  20 value 51.774538\n",
      "iter  30 value 35.438001\n",
      "iter  40 value 18.886920\n",
      "iter  50 value 9.392816\n",
      "iter  60 value 5.849358\n",
      "iter  70 value 5.362935\n",
      "iter  80 value 4.998204\n",
      "iter  90 value 4.740195\n",
      "iter 100 value 4.546968\n",
      "final  value 4.546968 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 71.086760\n",
      "iter  20 value 43.886189\n",
      "iter  30 value 20.718488\n",
      "iter  40 value 3.635909\n",
      "iter  50 value 0.024569\n",
      "iter  60 value 0.000305\n",
      "final  value 0.000070 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 74.422143\n",
      "iter  20 value 55.436699\n",
      "iter  30 value 50.650434\n",
      "iter  40 value 49.753769\n",
      "iter  50 value 49.404228\n",
      "iter  60 value 49.365319\n",
      "iter  70 value 49.361247\n",
      "final  value 49.361121 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 71.090369\n",
      "iter  20 value 43.903360\n",
      "iter  30 value 20.868315\n",
      "iter  40 value 4.350693\n",
      "iter  50 value 1.555316\n",
      "iter  60 value 1.451102\n",
      "iter  70 value 1.350139\n",
      "iter  80 value 1.280379\n",
      "iter  90 value 1.247323\n",
      "iter 100 value 1.220485\n",
      "final  value 1.220485 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 213.130784 \n",
      "iter  10 value 138.811430\n",
      "iter  20 value 97.878639\n",
      "iter  30 value 85.287326\n",
      "iter  40 value 77.010764\n",
      "iter  50 value 72.998203\n",
      "iter  60 value 71.385085\n",
      "iter  70 value 70.113507\n",
      "iter  80 value 65.757487\n",
      "iter  90 value 54.044445\n",
      "iter 100 value 46.868742\n",
      "final  value 46.868742 \n",
      "stopped after 100 iterations\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in metrics$Accuracy: $ operator is invalid for atomic vectors\n",
     "output_type": "error",
     "traceback": [
      "Error in metrics$Accuracy: $ operator is invalid for atomic vectors\nTraceback:\n",
      "1. evaluate_model(best_inner_model, outer_test_data, outer_test_data$y)"
     ]
    }
   ],
   "source": [
    "# Define outer and inner folds\n",
    "outer_folds <- 5\n",
    "inner_folds <- 3\n",
    "\n",
    "# Define classification-only methods\n",
    "classification_methods <- c(\"multinom\", \"naive_bayes\", \"qda\", \"lda\", \"rpart\", \"rf\")\n",
    "\n",
    "# Function to evaluate classification model\n",
    "evaluate_model <- function(model, test_data, true_labels) {\n",
    "  predictions <- predict(model, newdata = test_data)\n",
    "  \n",
    "  # Ensure levels are specified in multiClassSummary\n",
    "  levels <- levels(true_labels)\n",
    "  metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), lev = levels)\n",
    "  \n",
    "  return(list(\n",
    "    Accuracy = metrics$Accuracy,\n",
    "    Sensitivity = metrics$Recall,\n",
    "    Specificity = metrics$Specificity,\n",
    "    F1 = metrics$F1\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results <- data.frame(Model = character(), Variable_Set = character(), Fold = integer(),\n",
    "                      Accuracy = numeric(), Sensitivity = numeric(), Specificity = numeric(), F1 = numeric())\n",
    "\n",
    "# Loop through each classification model and both datasets\n",
    "for (method in classification_methods) {\n",
    "  for (variable_set in c(\"with_excluded\", \"without_excluded\")) {\n",
    "    \n",
    "    data_set <- if (variable_set == \"with_excluded\") data_with_excluded else data_without_excluded\n",
    "    \n",
    "    for (outer_fold in 1:outer_folds) {\n",
    "      outer_train_index <- createFolds(data_set$y, k = outer_folds, list = TRUE, returnTrain = TRUE)[[outer_fold]]\n",
    "      outer_train_data <- data_set[outer_train_index, ]\n",
    "      outer_test_data <- data_set[-outer_train_index, ]\n",
    "      \n",
    "      best_inner_model <- NULL\n",
    "      best_inner_accuracy <- 0\n",
    "      \n",
    "      for (inner_fold in 1:inner_folds) {\n",
    "        inner_train_index <- createFolds(outer_train_data$y, k = inner_folds, list = TRUE, returnTrain = TRUE)[[inner_fold]]\n",
    "        inner_train_data <- outer_train_data[inner_train_index, ]\n",
    "        inner_val_data <- outer_train_data[-inner_train_index, ]\n",
    "        \n",
    "        # Train the model\n",
    "        model <- train(y ~ ., data = inner_train_data, method = method, trControl = trainControl(method = \"cv\", number = inner_folds), metric = \"Accuracy\")\n",
    "        \n",
    "        # Get accuracy on validation set\n",
    "        val_pred <- predict(model, newdata = inner_val_data)\n",
    "        val_accuracy <- mean(val_pred == inner_val_data$y)\n",
    "        \n",
    "        # Update best model if necessary\n",
    "        if (val_accuracy > best_inner_accuracy) {\n",
    "          best_inner_model <- model\n",
    "          best_inner_accuracy <- val_accuracy\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      # Evaluate the best inner model on outer test set\n",
    "      outer_metrics <- evaluate_model(best_inner_model, outer_test_data, outer_test_data$y)\n",
    "      \n",
    "      # Store results\n",
    "      results <- rbind(results, data.frame(Model = method, Variable_Set = variable_set, Fold = outer_fold,\n",
    "                                           Accuracy = outer_metrics$Accuracy,\n",
    "                                           Sensitivity = outer_metrics$Sensitivity,\n",
    "                                           Specificity = outer_metrics$Specificity,\n",
    "                                           F1 = outer_metrics$F1))\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Print and Plot Final Results\n",
    "cat(\"\\nClassification Results:\\n\")\n",
    "print(results)\n",
    "\n",
    "# Plot results\n",
    "ggplot(results, aes(x = Model, y = Accuracy, fill = Variable_Set)) +\n",
    "  geom_boxplot() +\n",
    "  labs(title = \"Model Accuracy across Nested Cross-Validation Folds\",\n",
    "       x = \"Model\", y = \"Accuracy\")\n",
    "\n",
    "ggplot(results, aes(x = Model, y = Sensitivity, fill = Variable_Set)) +\n",
    "  geom_boxplot() +\n",
    "  labs(title = \"Model Sensitivity across Nested Cross-Validation Folds\",\n",
    "       x = \"Model\", y = \"Sensitivity\")\n",
    "\n",
    "ggplot(results, aes(x = Model, y = Specificity, fill = Variable_Set)) +\n",
    "  geom_boxplot() +\n",
    "  labs(title = \"Model Specificity across Nested Cross-Validation Folds\",\n",
    "       x = \"Model\", y = \"Specificity\")\n",
    "\n",
    "ggplot(results, aes(x = Model, y = F1, fill = Variable_Set)) +\n",
    "  geom_boxplot() +\n",
    "  labs(title = \"Model F1 across Nested Cross-Validation Folds\",\n",
    "       x = \"Model\", y = \"F1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running analysis without preprocessing...\n",
      "Training logistic model...\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in preprocess(X_train_processed): impossible de trouver la fonction \"preprocess\"\n",
     "output_type": "error",
     "traceback": [
      "Error in preprocess(X_train_processed): impossible de trouver la fonction \"preprocess\"\nTraceback:\n",
      "1. nested_cv(X, y, model_type = model, preprocess_params = list(scale = FALSE, \n .     remove_correlated = FALSE, handle_outliers = FALSE))",
      "2. predict(preprocess(X_train_processed), X_test)   # at line 123 of file <text>"
     ]
    }
   ],
   "source": [
    "# # Load required libraries\n",
    "# library(tidyverse)\n",
    "# library(ggplot2)\n",
    "# library(caret)\n",
    "# library(MASS)\n",
    "# library(rpart)\n",
    "# library(randomForest)\n",
    "# library(corrplot)\n",
    "# library(e1071)\n",
    "# library(pROC)\n",
    "# library(moments)\n",
    "# library(gridExtra)\n",
    "\n",
    "# # ---- 1. Data Loading and Initial Setup ----\n",
    "# data <- read.table(\"a24_clas_app.txt\", header = TRUE,sep = \" \")\n",
    "# X <- data[, 1:50]  # Features\n",
    "# y <- as.factor(data[, 51])  # Target variable\n",
    "\n",
    "# # ---- 2. Feature Analysis Functions ----\n",
    "# analyze_features <- function(X) {\n",
    "#   feature_stats <- data.frame(\n",
    "#     mean = colMeans(X),\n",
    "#     sd = apply(X, 2, sd),\n",
    "#     median = apply(X, 2, median),\n",
    "#     skewness = apply(X, 2, skewness),\n",
    "#     kurtosis = apply(X, 2, kurtosis),\n",
    "#     zeros = colSums(X == 0),\n",
    "#     unique_values = apply(X, 2, function(x) length(unique(x)))\n",
    "#   )\n",
    "#   return(feature_stats)\n",
    "# }\n",
    "\n",
    "# detect_outliers <- function(X, method = \"iqr\", threshold = 1.5) {\n",
    "#   outliers_summary <- list()\n",
    "#   for (col in colnames(X)) {\n",
    "#     x <- X[[col]]\n",
    "#     if (method == \"iqr\") {\n",
    "#       Q1 <- quantile(x, 0.25)\n",
    "#       Q3 <- quantile(x, 0.75)\n",
    "#       IQR <- Q3 - Q1\n",
    "#       lower_bound <- Q1 - threshold * IQR\n",
    "#       upper_bound <- Q3 + threshold * IQR\n",
    "#       outliers_summary[[col]] <- list(\n",
    "#         n_outliers = sum(x < lower_bound | x > upper_bound),\n",
    "#         lower_bound = lower_bound,\n",
    "#         upper_bound = upper_bound\n",
    "#       )\n",
    "#     }\n",
    "#   }\n",
    "#   return(outliers_summary)\n",
    "# }\n",
    "\n",
    "# # ---- 3. Preprocessing Function ----\n",
    "# preprocess_data <- function(X, scale = TRUE, remove_correlated = FALSE, \n",
    "#                           correlation_threshold = 0.8, handle_outliers = TRUE) {\n",
    "#   # Handle outliers if requested\n",
    "#   if (handle_outliers) {\n",
    "#     outliers <- detect_outliers(X)\n",
    "#     for (col in colnames(X)) {\n",
    "#       lower_bound <- outliers[[col]]$lower_bound\n",
    "#       upper_bound <- outliers[[col]]$upper_bound\n",
    "#       X[[col]][X[[col]] < lower_bound] <- lower_bound\n",
    "#       X[[col]][X[[col]] > upper_bound] <- upper_bound\n",
    "#     }\n",
    "#   }\n",
    "  \n",
    "#   # Remove highly correlated features if requested\n",
    "#   if (remove_correlated) {\n",
    "#     correlation_matrix <- cor(X)\n",
    "#     highly_correlated <- findCorrelation(correlation_matrix, \n",
    "#                                        cutoff = correlation_threshold)\n",
    "#     if (length(highly_correlated) > 0) {\n",
    "#       X <- X[, -highly_correlated]\n",
    "#     }\n",
    "#   }\n",
    "  \n",
    "#   # Scale features if requested\n",
    "#   if (scale) {\n",
    "#     X <- scale(X)\n",
    "#   }\n",
    "  \n",
    "#   return(X)\n",
    "# }\n",
    "\n",
    "# # ---- 4. Model Evaluation Functions ----\n",
    "# calculate_metrics <- function(pred, actual) {\n",
    "#   confusion_mat <- confusionMatrix(pred, actual)\n",
    "#   metrics <- list(\n",
    "#     accuracy = confusion_mat$overall[\"Accuracy\"],\n",
    "#     sensitivity = mean(confusion_mat$byClass[, \"Sensitivity\"]),\n",
    "#     specificity = mean(confusion_mat$byClass[, \"Specificity\"])\n",
    "#   )\n",
    "#   return(metrics)\n",
    "# }\n",
    "\n",
    "# # ---- 5. Nested Cross-Validation Function ----\n",
    "# nested_cv <- function(X, y, outer_folds = 5, inner_folds = 5, \n",
    "#                      model_type = c(\"logistic\", \"lda\", \"qda\", \"naive_bayes\", \"tree\", \"rf\"),\n",
    "#                      preprocess_params = list(scale = TRUE, \n",
    "#                                            remove_correlated = FALSE,\n",
    "#                                            handle_outliers = TRUE)) {\n",
    "#   outer_cv <- createFolds(y, k = outer_folds, list = TRUE)\n",
    "#   results <- list()\n",
    "#   predictions <- numeric(length(y))\n",
    "  \n",
    "#   for (fold in 1:outer_folds) {\n",
    "#     # Split data\n",
    "#     train_indices <- unlist(outer_cv[-fold])\n",
    "#     test_indices <- outer_cv[[fold]]\n",
    "    \n",
    "#     X_train <- X[train_indices, ]\n",
    "#     y_train <- y[train_indices]\n",
    "#     X_test <- X[test_indices, ]\n",
    "#     y_test <- y[test_indices]\n",
    "    \n",
    "#     # Preprocess data\n",
    "#     X_train_processed <- preprocess_data(X_train, \n",
    "#                                        scale = preprocess_params$scale,\n",
    "#                                        remove_correlated = preprocess_params$remove_correlated,\n",
    "#                                        handle_outliers = preprocess_params$handle_outliers)\n",
    "    \n",
    "#     # Apply same preprocessing to test data\n",
    "#     X_test_processed <- predict(preprocess(X_train_processed), X_test)\n",
    "    \n",
    "#     # Train model based on type\n",
    "#     if (model_type == \"logistic\") {\n",
    "#       model <- multinom(y_train ~ ., data = as.data.frame(X_train_processed))\n",
    "#       pred <- predict(model, newdata = as.data.frame(X_test_processed), type = \"class\")\n",
    "#     } else if (model_type == \"lda\") {\n",
    "#       model <- lda(X_train_processed, y_train)\n",
    "#       pred <- predict(model, X_test_processed)$class\n",
    "#     } else if (model_type == \"qda\") {\n",
    "#       model <- qda(X_train_processed, y_train)\n",
    "#       pred <- predict(model, X_test_processed)$class\n",
    "#     } else if (model_type == \"naive_bayes\") {\n",
    "#       model <- naiveBayes(X_train_processed, y_train)\n",
    "#       pred <- predict(model, X_test_processed)\n",
    "#     } else if (model_type == \"tree\") {\n",
    "#       model <- rpart(y_train ~ ., data = as.data.frame(X_train_processed))\n",
    "#       pred <- predict(model, as.data.frame(X_test_processed), type = \"class\")\n",
    "#     } else if (model_type == \"rf\") {\n",
    "#       model <- randomForest(X_train_processed, y_train)\n",
    "#       pred <- predict(model, X_test_processed)\n",
    "#     }\n",
    "    \n",
    "#     # Store predictions and calculate metrics\n",
    "#     predictions[test_indices] <- pred\n",
    "#     results[[fold]] <- calculate_metrics(pred, y_test)\n",
    "#   }\n",
    "  \n",
    "#   return(list(predictions = predictions, metrics = results))\n",
    "# }\n",
    "\n",
    "# # ---- 6. Enhanced Visualization Functions ----\n",
    "# prepare_metrics_data <- function(results_list) {\n",
    "#   plot_data <- data.frame()\n",
    "  \n",
    "#   for (model in names(results_list)) {\n",
    "#     metrics <- results_list[[model]]$metrics\n",
    "    \n",
    "#     # Extract metrics\n",
    "#     accuracies <- sapply(metrics, function(x) x$accuracy)\n",
    "#     sensitivities <- sapply(metrics, function(x) x$sensitivity)\n",
    "#     specificities <- sapply(metrics, function(x) x$specificity)\n",
    "    \n",
    "#     # Combine into data frame\n",
    "#     model_data <- data.frame(\n",
    "#       Model = rep(model, 3 * length(accuracies)),\n",
    "#       Metric = rep(c(\"Accuracy\", \"Sensitivity\", \"Specificity\"), each = length(accuracies)),\n",
    "#       Value = c(accuracies, sensitivities, specificities)\n",
    "#     )\n",
    "    \n",
    "#     plot_data <- rbind(plot_data, model_data)\n",
    "#   }\n",
    "  \n",
    "#   # Convert Model to factor with specific order\n",
    "#   plot_data$Model <- factor(plot_data$Model, \n",
    "#                            levels = c(\"logistic\", \"lda\", \"qda\", \"naive_bayes\", \"tree\", \"rf\"),\n",
    "#                            labels = c(\"Logistic\", \"LDA\", \"QDA\", \"Naive Bayes\", \"Decision Tree\", \"Random Forest\"))\n",
    "  \n",
    "#   return(plot_data)\n",
    "# }\n",
    "\n",
    "# create_metric_plot <- function(data, metric_name) {\n",
    "#   metric_data <- data[data$Metric == metric_name, ]\n",
    "  \n",
    "#   ggplot(metric_data, aes(x = Model, y = Value, fill = Model)) +\n",
    "#     geom_boxplot(alpha = 0.8) +\n",
    "#     scale_fill_brewer(palette = \"Set2\") +\n",
    "#     theme_minimal() +\n",
    "#     labs(title = paste(metric_name, \"by Model\"),\n",
    "#          y = metric_name,\n",
    "#          x = \"\") +\n",
    "#     theme(\n",
    "#       plot.title = element_text(size = 12, face = \"bold\", hjust = 0.5),\n",
    "#       axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "#       legend.position = \"none\",\n",
    "#       panel.grid.major.x = element_blank(),\n",
    "#       panel.border = element_rect(fill = NA, color = \"gray80\"),\n",
    "#       plot.margin = margin(5, 10, 5, 10)\n",
    "#     ) +\n",
    "#     scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1))\n",
    "# }\n",
    "\n",
    "# plot_classification_results <- function(results_list, title = \"Model Performance Comparison\") {\n",
    "#   # Prepare data\n",
    "#   plot_data <- prepare_metrics_data(results_list)\n",
    "  \n",
    "#   # Create individual plots\n",
    "#   accuracy_plot <- create_metric_plot(plot_data, \"Accuracy\")\n",
    "#   sensitivity_plot <- create_metric_plot(plot_data, \"Sensitivity\")\n",
    "#   specificity_plot <- create_metric_plot(plot_data, \"Specificity\")\n",
    "  \n",
    "#   # Combine plots\n",
    "#   combined_plot <- grid.arrange(\n",
    "#     accuracy_plot, sensitivity_plot, specificity_plot,\n",
    "#     ncol = 1,\n",
    "#     top = grid::textGrob(title, gp = grid::gpar(fontsize = 14, fontface = \"bold\"))\n",
    "#   )\n",
    "  \n",
    "#   return(combined_plot)\n",
    "# }\n",
    "\n",
    "# create_summary_table <- function(results_list) {\n",
    "#   summary_data <- data.frame()\n",
    "  \n",
    "#   for (model in names(results_list)) {\n",
    "#     metrics <- results_list[[model]]$metrics\n",
    "    \n",
    "#     # Calculate summary statistics\n",
    "#     model_summary <- data.frame(\n",
    "#       Model = model,\n",
    "#       Metric = c(\"Accuracy\", \"Sensitivity\", \"Specificity\"),\n",
    "#       Mean = c(\n",
    "#         mean(sapply(metrics, function(x) x$accuracy)),\n",
    "#         mean(sapply(metrics, function(x) x$sensitivity)),\n",
    "#         mean(sapply(metrics, function(x) x$specificity))\n",
    "#       ),\n",
    "#       SD = c(\n",
    "#         sd(sapply(metrics, function(x) x$accuracy)),\n",
    "#         sd(sapply(metrics, function(x) x$sensitivity)),\n",
    "#         sd(sapply(metrics, function(x) x$specificity))\n",
    "#       )\n",
    "#     )\n",
    "    \n",
    "#     summary_data <- rbind(summary_data, model_summary)\n",
    "#   }\n",
    "  \n",
    "#   # Create summary table plot\n",
    "#   summary_plot <- ggplot(summary_data, aes(x = Model, y = Metric)) +\n",
    "#     geom_tile(aes(fill = Mean), color = \"white\") +\n",
    "#     geom_text(aes(label = sprintf(\"%.3f\\n(±%.3f)\", Mean, SD)), size = 3) +\n",
    "#     scale_fill_gradient2(low = \"white\", high = \"#4CAF50\", midpoint = 0.5) +\n",
    "#     theme_minimal() +\n",
    "#     labs(title = \"Summary Statistics\",\n",
    "#          fill = \"Mean Value\") +\n",
    "#     theme(\n",
    "#       axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "#       plot.title = element_text(size = 12, face = \"bold\", hjust = 0.5)\n",
    "#     )\n",
    "  \n",
    "#   return(summary_plot)\n",
    "# }\n",
    "\n",
    "# # ---- 7. Statistical Comparison Function ----\n",
    "# perform_mcnemar_tests <- function(results_list) {\n",
    "#   models <- names(results_list)\n",
    "#   n_models <- length(models)\n",
    "#   mcnemar_results <- matrix(NA, n_models, n_models)\n",
    "#   rownames(mcnemar_results) <- models\n",
    "#   colnames(mcnemar_results) <- models\n",
    "  \n",
    "#   for (i in 1:(n_models-1)) {\n",
    "#     for (j in (i+1):n_models) {\n",
    "#       pred_i <- results_list[[models[i]]]$predictions\n",
    "#       pred_j <- results_list[[models[j]]]$predictions\n",
    "      \n",
    "#       # Create contingency table\n",
    "#       table_ij <- table(pred_i == y, pred_j == y)\n",
    "      \n",
    "#       # Perform McNemar's test\n",
    "#       test_result <- mcnemar.test(table_ij)\n",
    "#       mcnemar_results[i,j] <- test_result$p.value\n",
    "#       mcnemar_results[j,i] <- test_result$p.value\n",
    "#     }\n",
    "#   }\n",
    "  \n",
    "#   diag(mcnemar_results) <- 1\n",
    "#   return(mcnemar_results)\n",
    "# }\n",
    "\n",
    "# # ---- 8. Run Complete Analysis ----\n",
    "# # Define models to test\n",
    "# model_types <- c(\"logistic\", \"lda\", \"qda\", \"naive_bayes\", \"tree\", \"rf\")\n",
    "\n",
    "# # Run analysis without preprocessing\n",
    "# cat(\"\\nRunning analysis without preprocessing...\\n\")\n",
    "# results_original <- list()\n",
    "# for (model in model_types) {\n",
    "#   cat(sprintf(\"Training %s model...\\n\", model))\n",
    "#   results_original[[model]] <- nested_cv(X, y, model_type = model, \n",
    "#                                        preprocess_params = list(scale = FALSE, \n",
    "#                                                              remove_correlated = FALSE,\n",
    "#                                                              handle_outliers = FALSE))\n",
    "# }\n",
    "\n",
    "# # Run analysis with preprocessing\n",
    "# cat(\"\\nRunning analysis with preprocessing...\\n\")\n",
    "# results_preprocessed <- list()\n",
    "# for (model in model_types) {\n",
    "#   cat(sprintf(\"Training %s model...\\n\", model))\n",
    "#   results_preprocessed[[model]] <- nested_cv(X, y, model_type = model, \n",
    "#                                            preprocess_params = list(scale = TRUE, \n",
    "#                                                                  remove_correlated = TRUE,\n",
    "#                                                                  handle_outliers = TRUE))\n",
    "# }\n",
    "\n",
    "# # ---- 9. Generate and Save Results ----\n",
    "# # Create output directory if it doesn't exist\n",
    "# dir.create(\"analysis_results\", showWarnings = FALSE)\n",
    "\n",
    "# # Save plots to PDF\n",
    "# pdf(\"analysis_results/classification_results.pdf\", height = 12, width = 10)\n",
    "\n",
    "# # Plot results without preprocessing\n",
    "# plots_original <- plot_classification_results(results_original, \n",
    "#     \"Model Performance Comparison (Without Preprocessing)\")\n",
    "# summary_original <- create_summary_table(results_original)\n",
    "# grid.arrange(plots_original, summary_original, ncol = 1, heights = c(3, 1))\n",
    "\n",
    "# # Plot results with preprocessing\n",
    "# plots_preprocessed <- plot_classification_results(results_preprocessed, \n",
    "#     \"Model Performance Comparison (With Preprocessing)\")\n",
    "# summary_preprocessed <- create_summary_table(results_preprocessed)\n",
    "# grid.arrange(plots_preprocessed, summary_preprocessed, ncol = 1, heights = c(3, 1))\n",
    "\n",
    "# dev.off()\n",
    "\n",
    "# # Perform statistical comparisons\n",
    "# mcnemar_results_original <- perform_mcnemar_tests(results_original)\n",
    "# mcnemar_results_preprocessed <- perform_mcnemar_tests(results_preprocessed)\n",
    "\n",
    "# # Save statistical results\n",
    "# sink(\"analysis_results/statistical_results.txt\")\n",
    "\n",
    "# cat(\"\\nMcNemar's Test Results (Original Data):\\n\")\n",
    "# print(round(mcnemar_results_original, 4))\n",
    "\n",
    "# cat(\"\\nMcNemar's Test Results (Preprocessed Data):\\n\")\n",
    "# print(round(mcnemar_results_preprocessed, 4))\n",
    "\n",
    "# # Print detailed metrics\n",
    "# print_model_metrics <- function(results_list, title) {\n",
    "#   cat(\"\\n\", title, \"\\n\", sep=\"\")\n",
    "#   cat(paste(rep(\"-\", nchar(title)), collapse=\"\"), \"\\n\")\n",
    "  \n",
    "#   for (model in names(results_list)) {\n",
    "#     metrics <- results_list[[model]]$metrics\n",
    "#     avg_accuracy <- mean(sapply(metrics, function(x) x$accuracy))\n",
    "#     avg_sensitivity <- mean(sapply(metrics, function(x) x$sensitivity))\n",
    "#     avg_specificity <- mean(sapply(metrics, function(x) x$specificity))\n",
    "    \n",
    "#     sd_accuracy <- sd(sapply(metrics, function(x) x$accuracy))\n",
    "#     sd_sensitivity <- sd(sapply(metrics, function(x) x$sensitivity))\n",
    "#     sd_specificity <- sd(sapply(metrics, function(x) x$specificity))\n",
    "    \n",
    "#     cat(sprintf(\"\\n%s:\\n\", model))\n",
    "#     cat(sprintf(\"Accuracy: %.4f (±%.4f)\\n\", avg_accuracy, sd_accuracy))\n",
    "#     cat(sprintf(\"Sensitivity: %.4f (±%.4f)\\n\", avg_sensitivity, sd_sensitivity))\n",
    "#     cat(sprintf(\"Specificity: %.4f (±%.4f)\\n\", avg_specificity, sd_specificity))\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# # Print detailed metrics for both analyses\n",
    "# cat(\"\\nDetailed Model Metrics:\\n\")\n",
    "# cat(\"=====================\\n\")\n",
    "# print_model_metrics(results_original, \"Results without Preprocessing\")\n",
    "# print_model_metrics(results_preprocessed, \"Results with Preprocessing\")\n",
    "\n",
    "# # Close the output file\n",
    "# sink()\n",
    "\n",
    "# # Create comparison plots of preprocessed vs non-preprocessed results\n",
    "# pdf(\"analysis_results/preprocessing_comparison.pdf\", height = 8, width = 12)\n",
    "\n",
    "# # Prepare combined data for comparison\n",
    "# prepare_comparison_data <- function(original_results, preprocessed_results) {\n",
    "#   original_data <- prepare_metrics_data(original_results)\n",
    "#   original_data$Preprocessing <- \"Without Preprocessing\"\n",
    "  \n",
    "#   preprocessed_data <- prepare_metrics_data(preprocessed_results)\n",
    "#   preprocessed_data$Preprocessing <- \"With Preprocessing\"\n",
    "  \n",
    "#   rbind(original_data, preprocessed_data)\n",
    "# }\n",
    "\n",
    "# comparison_data <- prepare_comparison_data(results_original, results_preprocessed)\n",
    "\n",
    "# # Create comparison plots\n",
    "# for (metric in c(\"Accuracy\", \"Sensitivity\", \"Specificity\")) {\n",
    "#   metric_data <- comparison_data[comparison_data$Metric == metric, ]\n",
    "  \n",
    "#   p <- ggplot(metric_data, aes(x = Model, y = Value, fill = Preprocessing)) +\n",
    "#     geom_boxplot(position = position_dodge(width = 0.8), alpha = 0.8) +\n",
    "#     scale_fill_brewer(palette = \"Set2\") +\n",
    "#     theme_minimal() +\n",
    "#     labs(title = paste(metric, \"Comparison: Preprocessing Effect\"),\n",
    "#          y = metric,\n",
    "#          x = \"\") +\n",
    "#     theme(\n",
    "#       plot.title = element_text(size = 12, face = \"bold\", hjust = 0.5),\n",
    "#       axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "#       legend.position = \"top\",\n",
    "#       panel.grid.major.x = element_blank(),\n",
    "#       panel.border = element_rect(fill = NA, color = \"gray80\"),\n",
    "#       plot.margin = margin(5, 10, 5, 10)\n",
    "#     ) +\n",
    "#     scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1))\n",
    "  \n",
    "#   print(p)\n",
    "# }\n",
    "\n",
    "# dev.off()\n",
    "\n",
    "# # Print completion message\n",
    "# cat(\"\\nAnalysis complete! Results have been saved to the 'analysis_results' directory.\\n\")\n",
    "# cat(\"Generated files:\\n\")\n",
    "# cat(\"1. classification_results.pdf - Contains performance plots and summary tables\\n\")\n",
    "# cat(\"2. preprocessing_comparison.pdf - Shows the effect of preprocessing\\n\")\n",
    "# cat(\"3. statistical_results.txt - Contains detailed metrics and statistical tests\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
