{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking and installing required packages...\n",
      "Package 'caret' is already installed and loaded\n",
      "Package 'MASS' is already installed and loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.7-1.2\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n",
      "Attachement du package : 'randomForest'\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package 'randomForest' is already installed and loaded\n",
      "Package 'e1071' is already installed and loaded\n",
      "Package 'ggplot2' is already installed and loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attachement du package : 'dplyr'\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:randomForest':\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:MASS':\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package 'dplyr' is already installed and loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrplot 0.95 loaded\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package 'corrplot' is already installed and loaded\n",
      "Package 'nnet' is already installed and loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "naivebayes 1.0.0 loaded\n",
      "\n",
      "For more information please visit: \n",
      "\n",
      "https://majkamichal.github.io/naivebayes/\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package 'naivebayes' is already installed and loaded\n",
      "Package 'MVN' is already installed and loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attachement du package : 'nlme'\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:dplyr':\n",
      "\n",
      "    collapse\n",
      "\n",
      "\n",
      "This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n",
      "\n",
      "\n",
      "Attachement du package : 'mgcv'\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:MVN':\n",
      "\n",
      "    mvn\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:nnet':\n",
      "\n",
      "    multinom\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package 'mgcv' is already installed and loaded\n",
      "Package 'devtools' is already installed and loaded\n",
      "\n",
      "All required packages are installed and loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "required_packages <- c(\n",
    "\"caret\",\n",
    "\"MASS\",\n",
    "\"randomForest\",\n",
    "\"e1071\",\n",
    "\"ggplot2\",\n",
    "\"dplyr\",\n",
    "\"corrplot\",\n",
    "\"nnet\",\n",
    "\"naivebayes\",\n",
    "\"MVN\",\n",
    "\"mgcv\",\n",
    "\"devtools\"\n",
    ")\n",
    "\n",
    "# Function to install and load packages\n",
    "install_and_load_packages <- function(packages) {\n",
    "  cat(\"Checking and installing required packages...\\n\")\n",
    "  \n",
    "  for (package in packages) {\n",
    "    if (!require(package, character.only = TRUE, quietly = TRUE)) {\n",
    "      cat(sprintf(\"Installing package: %s\\n\", package))\n",
    "      install.packages(package, dependencies = TRUE)\n",
    "      if (!require(package, character.only = TRUE, quietly = TRUE)) {\n",
    "        stop(sprintf(\"Package '%s' installation failed\", package))\n",
    "      }\n",
    "    } else {\n",
    "      cat(sprintf(\"Package '%s' is already installed and loaded\\n\", package))\n",
    "    }\n",
    "  }\n",
    "  cat(\"\\nAll required packages are installed and loaded!\\n\\n\")\n",
    "}\n",
    "\n",
    "# Install and load all required packages\n",
    "install_and_load_packages(required_packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package 'UBL' is already installed.\n"
     ]
    }
   ],
   "source": [
    "if (!requireNamespace(\"UBL\", quietly = TRUE)) {\n",
    "    devtools::install_github(\"paobranco/UBL\")\n",
    "} else {\n",
    "    cat(\"Package 'UBL' is already installed.\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Le chargement a nécessité le package : grid\n",
      "\n",
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "Le chargement a nécessité le package : MBA\n",
      "\n",
      "Le chargement a nécessité le package : gstat\n",
      "\n",
      "Le chargement a nécessité le package : automap\n",
      "\n",
      "Le chargement a nécessité le package : sp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "library(MASS)\n",
    "library(randomForest)\n",
    "library(naivebayes)\n",
    "library(e1071)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(corrplot)\n",
    "library(nnet)\n",
    "library(MVN)\n",
    "library(mgcv)\n",
    "library(DMwR)\n",
    "library(UBL)\n",
    "library(devtools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows deleted due to outliers: 27.6 %\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "data <- read.table(\"a24_clas_app.txt\", header = TRUE, sep=\" \")\n",
    "\n",
    "# Convert y to a factor\n",
    "data$y <- as.factor(data$y)\n",
    "\n",
    "# Make a copy of the original data for processing\n",
    "data_cleaned <- data\n",
    "data_cleaned_2 <- data\n",
    "\n",
    "# Identify excluded variables (0-13 values)\n",
    "excluded_vars <- c(\"X46\", \"X47\", \"X48\", \"X49\", \"X50\") \n",
    "numeric_vars <- names(data_cleaned)[sapply(data_cleaned, is.numeric) & !(names(data_cleaned) %in% excluded_vars) & names(data_cleaned) != \"y\"]\n",
    "\n",
    "# Outlier Removal\n",
    "# ------------------\n",
    "# Calculate skewness and IQR filtering for outliers on selected numeric variables only\n",
    "for (var in numeric_vars) {\n",
    "  Q1 <- quantile(data_cleaned[[var]], 0.25, na.rm = TRUE)\n",
    "  Q3 <- quantile(data_cleaned[[var]], 0.75, na.rm = TRUE)\n",
    "  IQR_val <- Q3 - Q1\n",
    "  \n",
    "  lower_bound <- Q1 - 1.5 * IQR_val\n",
    "  upper_bound <- Q3 + 1.5 * IQR_val\n",
    "  \n",
    "  # Remove rows with outliers in any numeric variable\n",
    "  data_cleaned <- data_cleaned[!(data_cleaned[[var]] < lower_bound | data_cleaned[[var]] > upper_bound), ]\n",
    "}\n",
    "\n",
    "# Calculate the ratio of rows deleted\n",
    "cat(\"Rows deleted due to outliers:\", (1 - nrow(data_cleaned) / nrow(data)) * 100, \"%\\n\")\n",
    "\n",
    "# Scaling\n",
    "# ----------\n",
    "# Apply scaling to numeric variables only\n",
    "preprocess_params <- preProcess(data_cleaned[, numeric_vars], method = c(\"center\", \"scale\"))\n",
    "data_scaled <- data_cleaned\n",
    "data_scaled[, numeric_vars] <- predict(preprocess_params, data_cleaned[, numeric_vars])\n",
    "\n",
    "preprocess_params_2 <- preProcess(data_cleaned_2[, numeric_vars], method = c(\"center\", \"scale\"))\n",
    "data_scaled_2 <- data_cleaned_2\n",
    "data_scaled_2[, numeric_vars] <- predict(preprocess_params_2, data_cleaned_2[, numeric_vars])\n",
    "\n",
    "# Separate datasets with and without excluded variables\n",
    "data_outlier <- data_scaled\n",
    "data_outlier_excluded <- data_scaled %>% select(-all_of(excluded_vars))\n",
    "data <- data_scaled_2\n",
    "data_excluded <- data_scaled_2 %>% select(-all_of(excluded_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 119.832922\n",
      "iter  20 value 79.908327\n",
      "iter  30 value 64.491048\n",
      "iter  40 value 53.409731\n",
      "iter  50 value 35.952488\n",
      "iter  60 value 7.173754\n",
      "iter  70 value 0.052159\n",
      "iter  80 value 0.000139\n",
      "iter  80 value 0.000077\n",
      "iter  80 value 0.000077\n",
      "final  value 0.000077 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 121.148420\n",
      "iter  20 value 91.851161\n",
      "iter  30 value 86.718561\n",
      "iter  40 value 85.935817\n",
      "iter  50 value 85.836564\n",
      "iter  60 value 85.819418\n",
      "iter  70 value 85.816095\n",
      "iter  80 value 85.815778\n",
      "final  value 85.815774 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 119.834280\n",
      "iter  20 value 79.924738\n",
      "iter  30 value 64.542157\n",
      "iter  40 value 53.564976\n",
      "iter  50 value 37.514849\n",
      "iter  60 value 21.980925\n",
      "iter  70 value 19.294295\n",
      "iter  80 value 17.860829\n",
      "iter  90 value 16.964477\n",
      "iter 100 value 16.586706\n",
      "final  value 16.586706 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 127.833776\n",
      "iter  20 value 88.344122\n",
      "iter  30 value 74.471439\n",
      "iter  40 value 63.642761\n",
      "iter  50 value 57.777288\n",
      "iter  60 value 54.667373\n",
      "iter  70 value 50.464334\n",
      "iter  80 value 48.137977\n",
      "iter  90 value 47.787593\n",
      "iter 100 value 47.784906\n",
      "final  value 47.784906 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 129.563222\n",
      "iter  20 value 98.340729\n",
      "iter  30 value 92.298907\n",
      "iter  40 value 91.454761\n",
      "iter  50 value 91.337659\n",
      "iter  60 value 91.329932\n",
      "iter  70 value 91.328876\n",
      "iter  80 value 91.328278\n",
      "iter  90 value 91.327943\n",
      "iter 100 value 91.327843\n",
      "final  value 91.327843 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 127.835614\n",
      "iter  20 value 88.357546\n",
      "iter  30 value 74.505630\n",
      "iter  40 value 63.758175\n",
      "iter  50 value 58.014644\n",
      "iter  60 value 55.054716\n",
      "iter  70 value 51.196558\n",
      "iter  80 value 49.792851\n",
      "iter  90 value 49.543471\n",
      "iter 100 value 49.471390\n",
      "final  value 49.471390 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.965843\n",
      "iter  20 value 96.542716\n",
      "iter  30 value 80.480334\n",
      "iter  40 value 71.986166\n",
      "iter  50 value 68.918696\n",
      "iter  60 value 67.319826\n",
      "iter  70 value 64.039234\n",
      "iter  80 value 56.289314\n",
      "iter  90 value 44.421876\n",
      "iter 100 value 42.482027\n",
      "final  value 42.482027 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 131.053743\n",
      "iter  20 value 106.229475\n",
      "iter  30 value 98.522473\n",
      "iter  40 value 97.438732\n",
      "iter  50 value 97.324233\n",
      "iter  60 value 97.317124\n",
      "iter  70 value 97.316720\n",
      "final  value 97.316688 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.966966\n",
      "iter  20 value 96.554558\n",
      "iter  30 value 80.515582\n",
      "iter  40 value 72.074724\n",
      "iter  50 value 69.091451\n",
      "iter  60 value 67.574241\n",
      "iter  70 value 64.638566\n",
      "iter  80 value 57.614858\n",
      "iter  90 value 52.689092\n",
      "iter 100 value 51.530249\n",
      "final  value 51.530249 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 194.832952\n",
      "iter  20 value 162.838137\n",
      "iter  30 value 141.472905\n",
      "iter  40 value 135.437666\n",
      "iter  50 value 133.044968\n",
      "iter  60 value 132.378673\n",
      "iter  70 value 132.209572\n",
      "iter  80 value 132.096692\n",
      "iter  90 value 132.053397\n",
      "final  value 132.053182 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 127.267267\n",
      "iter  20 value 95.182565\n",
      "iter  30 value 77.959532\n",
      "iter  40 value 69.472362\n",
      "iter  50 value 64.173560\n",
      "iter  60 value 61.433658\n",
      "iter  70 value 58.658331\n",
      "iter  80 value 55.464663\n",
      "iter  90 value 46.777542\n",
      "iter 100 value 38.614866\n",
      "final  value 38.614866 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 128.042512\n",
      "iter  20 value 107.672751\n",
      "iter  30 value 95.292052\n",
      "iter  40 value 94.202214\n",
      "iter  50 value 94.059005\n",
      "iter  60 value 94.049161\n",
      "iter  70 value 94.047616\n",
      "final  value 94.047523 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 127.270939\n",
      "iter  20 value 95.198007\n",
      "iter  30 value 77.988714\n",
      "iter  40 value 69.542745\n",
      "iter  50 value 64.331561\n",
      "iter  60 value 61.678654\n",
      "iter  70 value 59.075533\n",
      "iter  80 value 56.318516\n",
      "iter  90 value 49.634665\n",
      "iter 100 value 46.088972\n",
      "final  value 46.088972 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 129.805426\n",
      "iter  20 value 82.816488\n",
      "iter  30 value 67.846809\n",
      "iter  40 value 57.134369\n",
      "iter  50 value 50.063105\n",
      "iter  60 value 47.919651\n",
      "iter  70 value 46.422084\n",
      "iter  80 value 44.009901\n",
      "iter  90 value 43.597820\n",
      "iter 100 value 43.593895\n",
      "final  value 43.593895 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 131.932326\n",
      "iter  20 value 95.964241\n",
      "iter  30 value 89.632717\n",
      "iter  40 value 88.478371\n",
      "iter  50 value 88.304600\n",
      "iter  60 value 88.287792\n",
      "iter  70 value 88.284431\n",
      "iter  80 value 88.284005\n",
      "final  value 88.283985 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 129.807651\n",
      "iter  20 value 82.833784\n",
      "iter  30 value 67.889872\n",
      "iter  40 value 57.255704\n",
      "iter  50 value 50.340062\n",
      "iter  60 value 48.275441\n",
      "iter  70 value 46.910099\n",
      "iter  80 value 45.128053\n",
      "iter  90 value 44.923866\n",
      "iter 100 value 44.863359\n",
      "final  value 44.863359 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 119.525587\n",
      "iter  20 value 82.518032\n",
      "iter  30 value 67.273450\n",
      "iter  40 value 58.389190\n",
      "iter  50 value 53.264241\n",
      "iter  60 value 50.537163\n",
      "iter  70 value 47.545234\n",
      "iter  80 value 45.542594\n",
      "iter  90 value 44.395663\n",
      "iter 100 value 44.341801\n",
      "final  value 44.341801 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 121.089590\n",
      "iter  20 value 93.165692\n",
      "iter  30 value 87.017691\n",
      "iter  40 value 86.278247\n",
      "iter  50 value 86.206698\n",
      "iter  60 value 86.201639\n",
      "iter  70 value 86.200925\n",
      "final  value 86.200872 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 119.527218\n",
      "iter  20 value 82.532146\n",
      "iter  30 value 67.313556\n",
      "iter  40 value 58.493305\n",
      "iter  50 value 53.516437\n",
      "iter  60 value 50.922622\n",
      "iter  70 value 48.055239\n",
      "iter  80 value 46.643564\n",
      "iter  90 value 46.281933\n",
      "iter 100 value 46.168654\n",
      "final  value 46.168654 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 294.428093 \n",
      "iter  10 value 196.519969\n",
      "iter  20 value 171.167307\n",
      "iter  30 value 157.239609\n",
      "iter  40 value 154.387927\n",
      "iter  50 value 154.106963\n",
      "iter  60 value 154.073610\n",
      "iter  70 value 154.069986\n",
      "iter  80 value 154.069615\n",
      "final  value 154.069550 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 122.789795\n",
      "iter  20 value 88.060025\n",
      "iter  30 value 73.415979\n",
      "iter  40 value 64.191142\n",
      "iter  50 value 59.237775\n",
      "iter  60 value 56.645798\n",
      "iter  70 value 53.131402\n",
      "iter  80 value 52.291556\n",
      "iter  90 value 52.239598\n",
      "iter 100 value 52.238569\n",
      "final  value 52.238569 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.743021\n",
      "iter  20 value 99.464100\n",
      "iter  30 value 93.059769\n",
      "iter  40 value 92.031990\n",
      "iter  50 value 91.842678\n",
      "iter  60 value 91.814975\n",
      "iter  70 value 91.806775\n",
      "iter  80 value 91.806060\n",
      "final  value 91.806051 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 122.794091\n",
      "iter  20 value 88.075371\n",
      "iter  30 value 73.453370\n",
      "iter  40 value 64.283467\n",
      "iter  50 value 59.415902\n",
      "iter  60 value 56.916497\n",
      "iter  70 value 53.845825\n",
      "iter  80 value 53.415841\n",
      "iter  90 value 53.310420\n",
      "iter 100 value 53.261578\n",
      "final  value 53.261578 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 138.558631\n",
      "iter  20 value 94.897618\n",
      "iter  30 value 80.436224\n",
      "iter  40 value 72.213888\n",
      "iter  50 value 67.678067\n",
      "iter  60 value 65.256786\n",
      "iter  70 value 61.932502\n",
      "iter  80 value 60.665456\n",
      "iter  90 value 60.548178\n",
      "final  value 60.547665 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 136.133530\n",
      "iter  20 value 109.175884\n",
      "iter  30 value 99.089229\n",
      "iter  40 value 97.941612\n",
      "iter  50 value 97.665365\n",
      "iter  60 value 97.633657\n",
      "iter  70 value 97.624603\n",
      "iter  80 value 97.623637\n",
      "final  value 97.623619 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 138.560470\n",
      "iter  20 value 94.912996\n",
      "iter  30 value 80.471344\n",
      "iter  40 value 72.295142\n",
      "iter  50 value 67.821446\n",
      "iter  60 value 65.469431\n",
      "iter  70 value 62.399182\n",
      "iter  80 value 61.538783\n",
      "iter  90 value 61.456962\n",
      "iter 100 value 61.411680\n",
      "final  value 61.411680 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 120.027672\n",
      "iter  20 value 83.211336\n",
      "iter  30 value 69.417978\n",
      "iter  40 value 58.060490\n",
      "iter  50 value 49.752574\n",
      "iter  60 value 45.939041\n",
      "iter  70 value 44.071235\n",
      "iter  80 value 43.083853\n",
      "iter  90 value 40.702734\n",
      "iter 100 value 37.314924\n",
      "final  value 37.314924 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 121.905883\n",
      "iter  20 value 93.774596\n",
      "iter  30 value 87.570953\n",
      "iter  40 value 86.588565\n",
      "iter  50 value 86.474893\n",
      "iter  60 value 86.466040\n",
      "iter  70 value 86.465032\n",
      "iter  80 value 86.464830\n",
      "iter  90 value 86.464728\n",
      "iter 100 value 86.464675\n",
      "final  value 86.464675 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 120.029634\n",
      "iter  20 value 83.225234\n",
      "iter  30 value 69.452083\n",
      "iter  40 value 58.191454\n",
      "iter  50 value 50.233413\n",
      "iter  60 value 47.027379\n",
      "iter  70 value 45.851368\n",
      "iter  80 value 45.008342\n",
      "iter  90 value 42.297783\n",
      "iter 100 value 41.351258\n",
      "final  value 41.351258 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 208.925453\n",
      "iter  20 value 161.955991\n",
      "iter  30 value 142.553147\n",
      "iter  40 value 134.605408\n",
      "iter  50 value 130.473299\n",
      "iter  60 value 128.057149\n",
      "iter  70 value 126.680507\n",
      "iter  80 value 124.205762\n",
      "iter  90 value 122.924918\n",
      "iter 100 value 122.775603\n",
      "final  value 122.775603 \n",
      "stopped after 100 iterations\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 142.882455\n",
      "iter  20 value 100.777282\n",
      "iter  30 value 86.235700\n",
      "iter  40 value 76.396421\n",
      "iter  50 value 70.714764\n",
      "iter  60 value 67.313562\n",
      "iter  70 value 62.552706\n",
      "iter  80 value 60.415450\n",
      "iter  90 value 60.155001\n",
      "iter 100 value 60.151892\n",
      "final  value 60.151892 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 144.868635\n",
      "iter  20 value 112.000209\n",
      "iter  30 value 105.980420\n",
      "iter  40 value 105.082392\n",
      "iter  50 value 104.929585\n",
      "iter  60 value 104.914555\n",
      "iter  70 value 104.911383\n",
      "iter  80 value 104.911167\n",
      "final  value 104.911166 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 142.884539\n",
      "iter  20 value 100.792630\n",
      "iter  30 value 86.273892\n",
      "iter  40 value 76.493153\n",
      "iter  50 value 70.943977\n",
      "iter  60 value 67.666138\n",
      "iter  70 value 63.402774\n",
      "iter  80 value 62.162561\n",
      "iter  90 value 61.971089\n",
      "iter 100 value 61.884506\n",
      "final  value 61.884506 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 121.029799\n",
      "iter  20 value 81.239888\n",
      "iter  30 value 65.034630\n",
      "iter  40 value 52.200517\n",
      "iter  50 value 43.817856\n",
      "iter  60 value 41.388753\n",
      "iter  70 value 40.787649\n",
      "iter  80 value 40.157372\n",
      "iter  90 value 39.381236\n",
      "iter 100 value 39.328006\n",
      "final  value 39.328006 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 123.130533\n",
      "iter  20 value 92.635196\n",
      "iter  30 value 87.179338\n",
      "iter  40 value 86.027826\n",
      "iter  50 value 85.888955\n",
      "iter  60 value 85.876219\n",
      "iter  70 value 85.874173\n",
      "iter  80 value 85.873975\n",
      "final  value 85.873964 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 121.032026\n",
      "iter  20 value 81.255303\n",
      "iter  30 value 65.079862\n",
      "iter  40 value 52.358155\n",
      "iter  50 value 44.240763\n",
      "iter  60 value 42.053434\n",
      "iter  70 value 41.455389\n",
      "iter  80 value 40.970133\n",
      "iter  90 value 40.621413\n",
      "iter 100 value 40.568334\n",
      "final  value 40.568334 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 122.400596\n",
      "iter  20 value 81.096832\n",
      "iter  30 value 64.731082\n",
      "iter  40 value 52.766472\n",
      "iter  50 value 47.310673\n",
      "iter  60 value 45.464163\n",
      "iter  70 value 43.027717\n",
      "iter  80 value 39.592106\n",
      "iter  90 value 38.122912\n",
      "iter 100 value 38.045022\n",
      "final  value 38.045022 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 123.960927\n",
      "iter  20 value 91.531778\n",
      "iter  30 value 83.034011\n",
      "iter  40 value 81.994996\n",
      "iter  50 value 81.865436\n",
      "iter  60 value 81.845413\n",
      "iter  70 value 81.842706\n",
      "iter  80 value 81.842556\n",
      "final  value 81.842554 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 122.402215\n",
      "iter  20 value 81.110497\n",
      "iter  30 value 64.764864\n",
      "iter  40 value 52.913398\n",
      "iter  50 value 47.588137\n",
      "iter  60 value 45.872054\n",
      "iter  70 value 43.737090\n",
      "iter  80 value 40.669476\n",
      "iter  90 value 40.026759\n",
      "iter 100 value 39.924621\n",
      "final  value 39.924621 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 199.138010\n",
      "iter  20 value 160.359909\n",
      "iter  30 value 140.612574\n",
      "iter  40 value 133.088718\n",
      "iter  50 value 129.546153\n",
      "iter  60 value 127.490607\n",
      "iter  70 value 126.566001\n",
      "iter  80 value 125.422954\n",
      "iter  90 value 125.034413\n",
      "iter 100 value 125.004194\n",
      "final  value 125.004194 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 117.686224\n",
      "iter  20 value 76.870467\n",
      "iter  30 value 62.428754\n",
      "iter  40 value 52.507209\n",
      "iter  50 value 46.945556\n",
      "iter  60 value 45.563946\n",
      "iter  70 value 44.712101\n",
      "iter  80 value 41.772810\n",
      "iter  90 value 39.031477\n",
      "iter 100 value 38.873920\n",
      "final  value 38.873920 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 117.793851\n",
      "iter  20 value 89.351936\n",
      "iter  30 value 84.087519\n",
      "iter  40 value 83.245529\n",
      "iter  50 value 83.163747\n",
      "iter  60 value 83.159210\n",
      "iter  70 value 83.158348\n",
      "final  value 83.158332 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 117.689117\n",
      "iter  20 value 76.886028\n",
      "iter  30 value 62.474384\n",
      "iter  40 value 52.663974\n",
      "iter  50 value 47.282410\n",
      "iter  60 value 46.022865\n",
      "iter  70 value 45.249665\n",
      "iter  80 value 43.027244\n",
      "iter  90 value 41.923392\n",
      "iter 100 value 41.737791\n",
      "final  value 41.737791 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 123.022412\n",
      "iter  20 value 86.202720\n",
      "iter  30 value 77.680829\n",
      "iter  40 value 70.371821\n",
      "iter  50 value 63.812892\n",
      "iter  60 value 60.804082\n",
      "iter  70 value 57.269255\n",
      "iter  80 value 56.365628\n",
      "iter  90 value 56.275626\n",
      "iter 100 value 56.274961\n",
      "final  value 56.274961 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 125.715177\n",
      "iter  20 value 96.867797\n",
      "iter  30 value 93.342214\n",
      "iter  40 value 93.002707\n",
      "iter  50 value 92.934722\n",
      "iter  60 value 92.928090\n",
      "iter  70 value 92.927574\n",
      "final  value 92.927534 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 123.025240\n",
      "iter  20 value 86.217329\n",
      "iter  30 value 77.709193\n",
      "iter  40 value 70.450821\n",
      "iter  50 value 64.063037\n",
      "iter  60 value 61.313364\n",
      "iter  70 value 58.556566\n",
      "iter  80 value 58.219539\n",
      "iter  90 value 58.066958\n",
      "iter 100 value 58.005967\n",
      "final  value 58.005967 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 110.716538\n",
      "iter  20 value 68.969722\n",
      "iter  30 value 54.736059\n",
      "iter  40 value 40.311918\n",
      "iter  50 value 31.142802\n",
      "iter  60 value 28.407287\n",
      "iter  70 value 28.032333\n",
      "iter  80 value 27.777588\n",
      "iter  90 value 27.625261\n",
      "iter 100 value 27.369916\n",
      "final  value 27.369916 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 112.431638\n",
      "iter  20 value 80.225065\n",
      "iter  30 value 75.613582\n",
      "iter  40 value 74.359314\n",
      "iter  50 value 74.205000\n",
      "iter  60 value 74.147186\n",
      "iter  70 value 74.136846\n",
      "iter  80 value 74.136316\n",
      "final  value 74.136307 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 110.718328\n",
      "iter  20 value 68.985032\n",
      "iter  30 value 54.781703\n",
      "iter  40 value 40.602525\n",
      "iter  50 value 31.754117\n",
      "iter  60 value 29.491279\n",
      "iter  70 value 29.166816\n",
      "iter  80 value 29.000239\n",
      "iter  90 value 28.907959\n",
      "iter 100 value 28.809599\n",
      "final  value 28.809599 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 187.501516\n",
      "iter  20 value 144.933139\n",
      "iter  30 value 123.854085\n",
      "iter  40 value 115.970992\n",
      "iter  50 value 111.274239\n",
      "iter  60 value 109.424260\n",
      "iter  70 value 108.336575\n",
      "iter  80 value 107.421418\n",
      "iter  90 value 107.174257\n",
      "iter 100 value 107.153540\n",
      "final  value 107.153540 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 124.912928\n",
      "iter  20 value 82.773493\n",
      "iter  30 value 67.016853\n",
      "iter  40 value 53.791513\n",
      "iter  50 value 47.016738\n",
      "iter  60 value 45.438065\n",
      "iter  70 value 44.539606\n",
      "iter  80 value 43.260883\n",
      "iter  90 value 40.600241\n",
      "iter 100 value 40.386051\n",
      "final  value 40.386051 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 127.341556\n",
      "iter  20 value 93.303091\n",
      "iter  30 value 87.384351\n",
      "iter  40 value 86.257221\n",
      "iter  50 value 86.126688\n",
      "iter  60 value 86.114786\n",
      "iter  70 value 86.112490\n",
      "iter  80 value 86.112211\n",
      "final  value 86.112201 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 124.915543\n",
      "iter  20 value 82.787395\n",
      "iter  30 value 67.056738\n",
      "iter  40 value 54.202858\n",
      "iter  50 value 47.005781\n",
      "iter  60 value 45.950137\n",
      "iter  70 value 45.112287\n",
      "iter  80 value 44.051944\n",
      "iter  90 value 42.380322\n",
      "iter 100 value 42.196493\n",
      "final  value 42.196493 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 124.894206\n",
      "iter  20 value 85.158594\n",
      "iter  30 value 67.731296\n",
      "iter  40 value 57.390131\n",
      "iter  50 value 49.319347\n",
      "iter  60 value 47.968231\n",
      "iter  70 value 47.117759\n",
      "iter  80 value 45.916667\n",
      "iter  90 value 45.647436\n",
      "iter 100 value 45.645163\n",
      "final  value 45.645163 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 126.918507\n",
      "iter  20 value 95.523041\n",
      "iter  30 value 87.338887\n",
      "iter  40 value 85.946965\n",
      "iter  50 value 85.654449\n",
      "iter  60 value 85.612384\n",
      "iter  70 value 85.607349\n",
      "iter  80 value 85.606685\n",
      "final  value 85.606657 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 124.896333\n",
      "iter  20 value 85.172229\n",
      "iter  30 value 67.768588\n",
      "iter  40 value 57.508886\n",
      "iter  50 value 49.595789\n",
      "iter  60 value 48.347283\n",
      "iter  70 value 47.557289\n",
      "iter  80 value 46.738312\n",
      "iter  90 value 46.592943\n",
      "iter 100 value 46.559986\n",
      "final  value 46.559986 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 130.302186\n",
      "iter  20 value 93.017680\n",
      "iter  30 value 78.257233\n",
      "iter  40 value 65.663418\n",
      "iter  50 value 58.857961\n",
      "iter  60 value 55.629847\n",
      "iter  70 value 54.072994\n",
      "iter  80 value 51.000109\n",
      "iter  90 value 45.326244\n",
      "iter 100 value 44.634973\n",
      "final  value 44.634973 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 130.450948\n",
      "iter  20 value 102.543920\n",
      "iter  30 value 96.282890\n",
      "iter  40 value 95.223090\n",
      "iter  50 value 95.085361\n",
      "iter  60 value 95.074843\n",
      "iter  70 value 95.072098\n",
      "iter  80 value 95.071646\n",
      "final  value 95.071636 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 130.304490\n",
      "iter  20 value 93.029634\n",
      "iter  30 value 78.291125\n",
      "iter  40 value 65.777808\n",
      "iter  50 value 59.181732\n",
      "iter  60 value 56.141604\n",
      "iter  70 value 54.697444\n",
      "iter  80 value 52.286109\n",
      "iter  90 value 48.695804\n",
      "iter 100 value 48.417718\n",
      "final  value 48.417718 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 292.230869 \n",
      "iter  10 value 211.513633\n",
      "iter  20 value 163.776850\n",
      "iter  30 value 136.797716\n",
      "iter  40 value 128.930092\n",
      "iter  50 value 124.024246\n",
      "iter  60 value 121.596349\n",
      "iter  70 value 120.972690\n",
      "iter  80 value 120.396874\n",
      "iter  90 value 119.884610\n",
      "iter 100 value 119.867362\n",
      "final  value 119.867362 \n",
      "stopped after 100 iterations\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 123.860743\n",
      "iter  20 value 82.041692\n",
      "iter  30 value 67.250368\n",
      "iter  40 value 56.380462\n",
      "iter  50 value 52.670809\n",
      "iter  60 value 50.722421\n",
      "iter  70 value 48.153982\n",
      "iter  80 value 42.514381\n",
      "iter  90 value 40.690206\n",
      "iter 100 value 40.565479\n",
      "final  value 40.565479 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 122.318670\n",
      "iter  20 value 92.851958\n",
      "iter  30 value 87.056388\n",
      "iter  40 value 85.863149\n",
      "iter  50 value 85.737200\n",
      "iter  60 value 85.718492\n",
      "iter  70 value 85.715615\n",
      "iter  80 value 85.715155\n",
      "final  value 85.715150 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 123.862043\n",
      "iter  20 value 82.054959\n",
      "iter  30 value 67.290176\n",
      "iter  40 value 56.509189\n",
      "iter  50 value 52.884784\n",
      "iter  60 value 51.022141\n",
      "iter  70 value 48.037998\n",
      "iter  80 value 44.479567\n",
      "iter  90 value 43.458981\n",
      "iter 100 value 43.281075\n",
      "final  value 43.281075 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 124.475805\n",
      "iter  20 value 85.923413\n",
      "iter  30 value 70.272341\n",
      "iter  40 value 54.875287\n",
      "iter  50 value 44.295806\n",
      "iter  60 value 40.781679\n",
      "iter  70 value 39.712539\n",
      "iter  80 value 38.023547\n",
      "iter  90 value 34.786258\n",
      "iter 100 value 34.557279\n",
      "final  value 34.557279 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 126.129359\n",
      "iter  20 value 96.958208\n",
      "iter  30 value 91.650941\n",
      "iter  40 value 90.681222\n",
      "iter  50 value 90.604749\n",
      "iter  60 value 90.599201\n",
      "iter  70 value 90.598538\n",
      "iter  80 value 90.598442\n",
      "final  value 90.598440 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 124.477531\n",
      "iter  20 value 85.938119\n",
      "iter  30 value 70.318575\n",
      "iter  40 value 55.067292\n",
      "iter  50 value 45.127815\n",
      "iter  60 value 41.920872\n",
      "iter  70 value 40.951836\n",
      "iter  80 value 39.223347\n",
      "iter  90 value 37.519982\n",
      "iter 100 value 37.384055\n",
      "final  value 37.384055 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.409967\n",
      "iter  20 value 90.445626\n",
      "iter  30 value 79.824051\n",
      "iter  40 value 69.749756\n",
      "iter  50 value 62.491734\n",
      "iter  60 value 59.464350\n",
      "iter  70 value 57.276418\n",
      "iter  80 value 53.237037\n",
      "iter  90 value 46.979263\n",
      "iter 100 value 44.622795\n",
      "final  value 44.622795 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 131.721412\n",
      "iter  20 value 99.372175\n",
      "iter  30 value 94.172034\n",
      "iter  40 value 93.146646\n",
      "iter  50 value 92.999340\n",
      "iter  60 value 92.985185\n",
      "iter  70 value 92.982264\n",
      "iter  80 value 92.981951\n",
      "final  value 92.981948 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.412439\n",
      "iter  20 value 90.457083\n",
      "iter  30 value 79.848125\n",
      "iter  40 value 69.836036\n",
      "iter  50 value 62.739736\n",
      "iter  60 value 59.906009\n",
      "iter  70 value 57.896917\n",
      "iter  80 value 54.486072\n",
      "iter  90 value 51.033991\n",
      "iter 100 value 49.735087\n",
      "final  value 49.735087 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 291.132256 \n",
      "iter  10 value 194.618955\n",
      "iter  20 value 161.554169\n",
      "iter  30 value 146.573774\n",
      "iter  40 value 141.877759\n",
      "iter  50 value 140.670929\n",
      "iter  60 value 140.445842\n",
      "iter  70 value 140.394628\n",
      "iter  80 value 140.377978\n",
      "iter  90 value 140.375583\n",
      "final  value 140.375564 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 119.617273\n",
      "iter  20 value 80.470856\n",
      "iter  30 value 68.737161\n",
      "iter  40 value 58.455054\n",
      "iter  50 value 52.403973\n",
      "iter  60 value 49.655454\n",
      "iter  70 value 46.720691\n",
      "iter  80 value 45.763520\n",
      "iter  90 value 45.561720\n",
      "iter 100 value 45.560029\n",
      "final  value 45.560029 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 120.818031\n",
      "iter  20 value 90.748753\n",
      "iter  30 value 86.122655\n",
      "iter  40 value 85.369329\n",
      "iter  50 value 85.271124\n",
      "iter  60 value 85.264647\n",
      "iter  70 value 85.264282\n",
      "final  value 85.264261 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 119.618506\n",
      "iter  20 value 80.484354\n",
      "iter  30 value 68.771091\n",
      "iter  40 value 58.598323\n",
      "iter  50 value 52.709286\n",
      "iter  60 value 50.128899\n",
      "iter  70 value 47.785828\n",
      "iter  80 value 47.120763\n",
      "iter  90 value 47.027782\n",
      "iter 100 value 46.986384\n",
      "final  value 46.986384 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 132.367273\n",
      "iter  20 value 93.685946\n",
      "iter  30 value 81.004968\n",
      "iter  40 value 70.939732\n",
      "iter  50 value 63.899086\n",
      "iter  60 value 60.620307\n",
      "iter  70 value 58.351641\n",
      "iter  80 value 57.920955\n",
      "iter  90 value 57.870623\n",
      "final  value 57.870307 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 134.348028\n",
      "iter  20 value 104.251880\n",
      "iter  30 value 98.176002\n",
      "iter  40 value 97.764220\n",
      "iter  50 value 97.685986\n",
      "iter  60 value 97.679845\n",
      "iter  70 value 97.679493\n",
      "final  value 97.679481 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 132.369376\n",
      "iter  20 value 93.699452\n",
      "iter  30 value 81.036284\n",
      "iter  40 value 71.051881\n",
      "iter  50 value 64.224498\n",
      "iter  60 value 61.239287\n",
      "iter  70 value 59.404044\n",
      "iter  80 value 59.285704\n",
      "iter  90 value 59.232827\n",
      "iter 100 value 59.203922\n",
      "final  value 59.203922 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 116.216693\n",
      "iter  20 value 85.720392\n",
      "iter  30 value 73.099138\n",
      "iter  40 value 63.657575\n",
      "iter  50 value 58.127262\n",
      "iter  60 value 55.133142\n",
      "iter  70 value 53.157845\n",
      "iter  80 value 49.222021\n",
      "iter  90 value 45.402969\n",
      "iter 100 value 44.049727\n",
      "final  value 44.049727 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 119.089522\n",
      "iter  20 value 95.792405\n",
      "iter  30 value 90.995661\n",
      "iter  40 value 90.095573\n",
      "iter  50 value 89.976874\n",
      "iter  60 value 89.965727\n",
      "iter  70 value 89.963033\n",
      "iter  80 value 89.962907\n",
      "final  value 89.962902 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 116.219762\n",
      "iter  20 value 85.733502\n",
      "iter  30 value 73.135125\n",
      "iter  40 value 63.775177\n",
      "iter  50 value 57.964296\n",
      "iter  60 value 55.357897\n",
      "iter  70 value 53.114283\n",
      "iter  80 value 50.187663\n",
      "iter  90 value 48.259757\n",
      "iter 100 value 47.933202\n",
      "final  value 47.933202 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 292.230869 \n",
      "iter  10 value 201.900780\n",
      "iter  20 value 170.276304\n",
      "iter  30 value 149.657067\n",
      "iter  40 value 142.876645\n",
      "iter  50 value 140.414206\n",
      "iter  60 value 139.221832\n",
      "iter  70 value 138.734566\n",
      "iter  80 value 138.479544\n",
      "iter  90 value 138.425498\n",
      "iter 100 value 138.425082\n",
      "final  value 138.425082 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 128.238834\n",
      "iter  20 value 90.844423\n",
      "iter  30 value 79.402619\n",
      "iter  40 value 70.662630\n",
      "iter  50 value 66.143920\n",
      "iter  60 value 61.498610\n",
      "iter  70 value 55.501816\n",
      "iter  80 value 53.369921\n",
      "iter  90 value 53.162191\n",
      "iter 100 value 53.157655\n",
      "final  value 53.157655 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 130.606364\n",
      "iter  20 value 99.681131\n",
      "iter  30 value 94.684014\n",
      "iter  40 value 93.723488\n",
      "iter  50 value 93.598615\n",
      "iter  60 value 93.582845\n",
      "iter  70 value 93.580228\n",
      "iter  80 value 93.580041\n",
      "final  value 93.580038 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 128.241335\n",
      "iter  20 value 90.855698\n",
      "iter  30 value 79.430449\n",
      "iter  40 value 70.738898\n",
      "iter  50 value 66.334552\n",
      "iter  60 value 61.836995\n",
      "iter  70 value 56.542263\n",
      "iter  80 value 55.348138\n",
      "iter  90 value 55.140028\n",
      "iter 100 value 55.070828\n",
      "final  value 55.070828 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 122.952984\n",
      "iter  20 value 96.419663\n",
      "iter  30 value 86.565127\n",
      "iter  40 value 81.325593\n",
      "iter  50 value 79.218387\n",
      "iter  60 value 78.130352\n",
      "iter  70 value 77.106755\n",
      "iter  80 value 76.267601\n",
      "iter  90 value 76.025150\n",
      "iter 100 value 76.003710\n",
      "final  value 76.003710 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 124.897164\n",
      "iter  20 value 103.414278\n",
      "iter  30 value 98.792329\n",
      "iter  40 value 98.215858\n",
      "iter  50 value 98.146054\n",
      "iter  60 value 98.138291\n",
      "iter  70 value 98.135469\n",
      "iter  80 value 98.135097\n",
      "final  value 98.135092 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 122.955044\n",
      "iter  20 value 96.428756\n",
      "iter  30 value 86.586361\n",
      "iter  40 value 81.373234\n",
      "iter  50 value 79.293847\n",
      "iter  60 value 78.235547\n",
      "iter  70 value 77.259077\n",
      "iter  80 value 76.500152\n",
      "iter  90 value 76.298134\n",
      "iter 100 value 76.281838\n",
      "final  value 76.281838 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 126.673256\n",
      "iter  20 value 82.245381\n",
      "iter  30 value 70.854443\n",
      "iter  40 value 61.557433\n",
      "iter  50 value 57.821321\n",
      "iter  60 value 54.909160\n",
      "iter  70 value 52.240998\n",
      "iter  80 value 51.121126\n",
      "iter  90 value 50.409987\n",
      "iter 100 value 48.500610\n",
      "final  value 48.500610 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 129.763179\n",
      "iter  20 value 92.917757\n",
      "iter  30 value 88.094155\n",
      "iter  40 value 87.292337\n",
      "iter  50 value 87.197940\n",
      "iter  60 value 87.190977\n",
      "iter  70 value 87.190104\n",
      "final  value 87.190048 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 193.355763 \n",
      "iter  10 value 126.676589\n",
      "iter  20 value 82.260017\n",
      "iter  30 value 70.884904\n",
      "iter  40 value 61.641251\n",
      "iter  50 value 58.004870\n",
      "iter  60 value 55.220608\n",
      "iter  70 value 52.745919\n",
      "iter  80 value 51.753054\n",
      "iter  90 value 51.124521\n",
      "iter 100 value 49.664304\n",
      "final  value 49.664304 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 291.132256 \n",
      "iter  10 value 203.144309\n",
      "iter  20 value 177.893333\n",
      "iter  30 value 167.197718\n",
      "iter  40 value 165.323820\n",
      "iter  50 value 165.169258\n",
      "iter  60 value 165.152130\n",
      "iter  70 value 165.151123\n",
      "final  value 165.151083 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 135.080502\n",
      "iter  20 value 101.231150\n",
      "iter  30 value 88.856147\n",
      "iter  40 value 81.418461\n",
      "iter  50 value 75.301839\n",
      "iter  60 value 71.123293\n",
      "iter  70 value 65.392498\n",
      "iter  80 value 61.105440\n",
      "iter  90 value 60.348443\n",
      "iter 100 value 60.331510\n",
      "final  value 60.331510 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 136.819048\n",
      "iter  20 value 110.527925\n",
      "iter  30 value 104.809896\n",
      "iter  40 value 104.252442\n",
      "iter  50 value 104.146076\n",
      "iter  60 value 104.138018\n",
      "iter  70 value 104.137414\n",
      "final  value 104.137342 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 135.082342\n",
      "iter  20 value 101.243229\n",
      "iter  30 value 88.884415\n",
      "iter  40 value 81.484986\n",
      "iter  50 value 75.468448\n",
      "iter  60 value 71.496788\n",
      "iter  70 value 66.384971\n",
      "iter  80 value 63.573693\n",
      "iter  90 value 63.235237\n",
      "iter 100 value 63.141818\n",
      "final  value 63.141818 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 114.490280\n",
      "iter  20 value 79.468010\n",
      "iter  30 value 66.544683\n",
      "iter  40 value 55.044856\n",
      "iter  50 value 49.808003\n",
      "iter  60 value 48.112497\n",
      "iter  70 value 46.376349\n",
      "iter  80 value 45.745967\n",
      "iter  90 value 45.639666\n",
      "iter 100 value 45.638585\n",
      "final  value 45.638585 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 116.777317\n",
      "iter  20 value 89.608242\n",
      "iter  30 value 84.188595\n",
      "iter  40 value 82.971793\n",
      "iter  50 value 82.837165\n",
      "iter  60 value 82.822049\n",
      "iter  70 value 82.820376\n",
      "iter  80 value 82.820273\n",
      "final  value 82.820271 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 114.492689\n",
      "iter  20 value 79.480382\n",
      "iter  30 value 66.578008\n",
      "iter  40 value 55.154303\n",
      "iter  50 value 50.045255\n",
      "iter  60 value 48.426523\n",
      "iter  70 value 47.023633\n",
      "iter  80 value 46.733358\n",
      "iter  90 value 46.634326\n",
      "iter 100 value 46.600782\n",
      "final  value 46.600782 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 120.756956\n",
      "iter  20 value 87.339023\n",
      "iter  30 value 78.016795\n",
      "iter  40 value 71.323947\n",
      "iter  50 value 67.769444\n",
      "iter  60 value 64.944520\n",
      "iter  70 value 58.090199\n",
      "iter  80 value 51.603923\n",
      "iter  90 value 50.776900\n",
      "iter 100 value 50.710077\n",
      "final  value 50.710077 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 123.798608\n",
      "iter  20 value 96.334857\n",
      "iter  30 value 91.877429\n",
      "iter  40 value 91.045114\n",
      "iter  50 value 90.914336\n",
      "iter  60 value 90.900239\n",
      "iter  70 value 90.898709\n",
      "iter  80 value 90.898569\n",
      "final  value 90.898566 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 120.760191\n",
      "iter  20 value 87.350276\n",
      "iter  30 value 78.040788\n",
      "iter  40 value 71.383423\n",
      "iter  50 value 67.913777\n",
      "iter  60 value 65.188414\n",
      "iter  70 value 59.118796\n",
      "iter  80 value 55.535903\n",
      "iter  90 value 55.211667\n",
      "iter 100 value 55.056321\n",
      "final  value 55.056321 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 294.428093 \n",
      "iter  10 value 200.845302\n",
      "iter  20 value 177.541486\n",
      "iter  30 value 165.662525\n",
      "iter  40 value 162.837520\n",
      "iter  50 value 162.553862\n",
      "iter  60 value 162.522469\n",
      "iter  70 value 162.518333\n",
      "iter  80 value 162.518051\n",
      "iter  80 value 162.518050\n",
      "iter  80 value 162.518050\n",
      "final  value 162.518050 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 125.546999\n",
      "iter  20 value 89.532855\n",
      "iter  30 value 76.535239\n",
      "iter  40 value 66.961488\n",
      "iter  50 value 62.400249\n",
      "iter  60 value 58.838484\n",
      "iter  70 value 54.169423\n",
      "iter  80 value 53.121746\n",
      "iter  90 value 53.011609\n",
      "iter 100 value 53.010659\n",
      "final  value 53.010659 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.726533\n",
      "iter  20 value 97.867573\n",
      "iter  30 value 92.110762\n",
      "iter  40 value 90.729031\n",
      "iter  50 value 90.554261\n",
      "iter  60 value 90.517109\n",
      "iter  70 value 90.507953\n",
      "iter  80 value 90.507282\n",
      "final  value 90.507273 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 125.548224\n",
      "iter  20 value 89.543600\n",
      "iter  30 value 76.564247\n",
      "iter  40 value 67.039333\n",
      "iter  50 value 62.567331\n",
      "iter  60 value 59.128415\n",
      "iter  70 value 55.000631\n",
      "iter  80 value 54.498101\n",
      "iter  90 value 54.348669\n",
      "iter 100 value 54.285149\n",
      "final  value 54.285149 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 132.107570\n",
      "iter  20 value 94.768932\n",
      "iter  30 value 84.128718\n",
      "iter  40 value 78.012243\n",
      "iter  50 value 74.746997\n",
      "iter  60 value 72.045937\n",
      "iter  70 value 65.701033\n",
      "iter  80 value 55.681589\n",
      "iter  90 value 54.896402\n",
      "iter 100 value 54.867792\n",
      "final  value 54.867792 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 133.553502\n",
      "iter  20 value 104.205506\n",
      "iter  30 value 100.171031\n",
      "iter  40 value 99.509665\n",
      "iter  50 value 99.455667\n",
      "iter  60 value 99.450739\n",
      "iter  70 value 99.450248\n",
      "final  value 99.450210 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 132.109098\n",
      "iter  20 value 94.781272\n",
      "iter  30 value 84.159232\n",
      "iter  40 value 78.089613\n",
      "iter  50 value 74.887798\n",
      "iter  60 value 72.336684\n",
      "iter  70 value 67.413857\n",
      "iter  80 value 63.291380\n",
      "iter  90 value 62.903592\n",
      "iter 100 value 62.293076\n",
      "final  value 62.293076 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 127.590558\n",
      "iter  20 value 96.520268\n",
      "iter  30 value 88.423466\n",
      "iter  40 value 84.113495\n",
      "iter  50 value 82.071022\n",
      "iter  60 value 80.077726\n",
      "iter  70 value 77.156347\n",
      "iter  80 value 69.861788\n",
      "iter  90 value 61.618351\n",
      "iter 100 value 61.198093\n",
      "final  value 61.198093 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 128.879669\n",
      "iter  20 value 105.763533\n",
      "iter  30 value 102.678812\n",
      "iter  40 value 102.175609\n",
      "iter  50 value 102.110847\n",
      "iter  60 value 102.105747\n",
      "iter  70 value 102.104985\n",
      "final  value 102.104913 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 127.591894\n",
      "iter  20 value 96.533027\n",
      "iter  30 value 88.451258\n",
      "iter  40 value 84.166832\n",
      "iter  50 value 82.161509\n",
      "iter  60 value 80.270240\n",
      "iter  70 value 77.867400\n",
      "iter  80 value 75.927530\n",
      "iter  90 value 75.275056\n",
      "iter 100 value 75.085628\n",
      "final  value 75.085628 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 208.412540\n",
      "iter  20 value 178.213232\n",
      "iter  30 value 163.039354\n",
      "iter  40 value 158.665314\n",
      "iter  50 value 157.457791\n",
      "iter  60 value 157.065051\n",
      "iter  70 value 156.989443\n",
      "iter  80 value 156.971304\n",
      "iter  90 value 156.969770\n",
      "final  value 156.969754 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 119.602758\n",
      "iter  20 value 86.554414\n",
      "iter  30 value 77.407092\n",
      "iter  40 value 70.800948\n",
      "iter  50 value 65.977324\n",
      "iter  60 value 63.744538\n",
      "iter  70 value 55.384084\n",
      "iter  80 value 50.695784\n",
      "iter  90 value 50.242011\n",
      "iter 100 value 50.222329\n",
      "final  value 50.222329 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 121.443596\n",
      "iter  20 value 96.083121\n",
      "iter  30 value 93.204900\n",
      "iter  40 value 92.784302\n",
      "iter  50 value 92.737975\n",
      "iter  60 value 92.734421\n",
      "iter  70 value 92.733939\n",
      "final  value 92.733920 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 119.604678\n",
      "iter  20 value 86.569543\n",
      "iter  30 value 77.435098\n",
      "iter  40 value 70.895304\n",
      "iter  50 value 66.198764\n",
      "iter  60 value 64.119640\n",
      "iter  70 value 57.941298\n",
      "iter  80 value 55.962892\n",
      "iter  90 value 55.670949\n",
      "iter 100 value 55.460744\n",
      "final  value 55.460744 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.768464\n",
      "iter  20 value 83.835544\n",
      "iter  30 value 70.620873\n",
      "iter  40 value 61.340964\n",
      "iter  50 value 56.675606\n",
      "iter  60 value 54.119097\n",
      "iter  70 value 51.054860\n",
      "iter  80 value 49.866724\n",
      "iter  90 value 49.797317\n",
      "iter 100 value 49.796702\n",
      "final  value 49.796702 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 124.159938\n",
      "iter  20 value 95.021311\n",
      "iter  30 value 89.594485\n",
      "iter  40 value 88.397281\n",
      "iter  50 value 88.276697\n",
      "iter  60 value 88.265937\n",
      "iter  70 value 88.264742\n",
      "final  value 88.264710 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.769952\n",
      "iter  20 value 83.850227\n",
      "iter  30 value 70.659286\n",
      "iter  40 value 61.449815\n",
      "iter  50 value 56.917606\n",
      "iter  60 value 54.452930\n",
      "iter  70 value 51.921030\n",
      "iter  80 value 51.196308\n",
      "iter  90 value 51.072636\n",
      "iter 100 value 51.004393\n",
      "final  value 51.004393 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.569554\n",
      "iter  20 value 83.448236\n",
      "iter  30 value 69.056215\n",
      "iter  40 value 60.546012\n",
      "iter  50 value 54.554207\n",
      "iter  60 value 52.469868\n",
      "iter  70 value 49.460833\n",
      "iter  80 value 48.346110\n",
      "iter  90 value 48.285028\n",
      "final  value 48.284744 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.885047\n",
      "iter  20 value 93.573773\n",
      "iter  30 value 88.884398\n",
      "iter  40 value 87.755505\n",
      "iter  50 value 87.618274\n",
      "iter  60 value 87.596685\n",
      "iter  70 value 87.592146\n",
      "iter  80 value 87.591643\n",
      "final  value 87.591639 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.572340\n",
      "iter  20 value 83.462163\n",
      "iter  30 value 69.096174\n",
      "iter  40 value 60.651221\n",
      "iter  50 value 54.763579\n",
      "iter  60 value 52.768944\n",
      "iter  70 value 50.082726\n",
      "iter  80 value 49.470242\n",
      "iter  90 value 49.344702\n",
      "iter 100 value 49.300696\n",
      "final  value 49.300696 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 200.142403\n",
      "iter  20 value 161.086789\n",
      "iter  30 value 144.164612\n",
      "iter  40 value 138.501803\n",
      "iter  50 value 136.383364\n",
      "iter  60 value 135.465394\n",
      "iter  70 value 135.182783\n",
      "iter  80 value 135.097663\n",
      "iter  90 value 135.084707\n",
      "final  value 135.084477 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.784001\n",
      "iter  20 value 87.153051\n",
      "iter  30 value 74.920804\n",
      "iter  40 value 62.584046\n",
      "iter  50 value 54.797137\n",
      "iter  60 value 50.095201\n",
      "iter  70 value 46.927627\n",
      "iter  80 value 42.791259\n",
      "iter  90 value 42.088624\n",
      "iter 100 value 42.057839\n",
      "final  value 42.057839 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 128.488622\n",
      "iter  20 value 96.671546\n",
      "iter  30 value 91.971303\n",
      "iter  40 value 91.181914\n",
      "iter  50 value 91.101630\n",
      "iter  60 value 91.093436\n",
      "iter  70 value 91.092673\n",
      "final  value 91.092636 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.785804\n",
      "iter  20 value 87.165564\n",
      "iter  30 value 74.955659\n",
      "iter  40 value 62.737156\n",
      "iter  50 value 55.268595\n",
      "iter  60 value 50.843721\n",
      "iter  70 value 47.860442\n",
      "iter  80 value 45.033724\n",
      "iter  90 value 44.669005\n",
      "iter 100 value 44.582111\n",
      "final  value 44.582111 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 129.886221\n",
      "iter  20 value 93.742750\n",
      "iter  30 value 81.100951\n",
      "iter  40 value 71.186376\n",
      "iter  50 value 64.969212\n",
      "iter  60 value 62.000473\n",
      "iter  70 value 58.491659\n",
      "iter  80 value 52.862696\n",
      "iter  90 value 51.036363\n",
      "iter 100 value 51.020880\n",
      "final  value 51.020880 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 131.016330\n",
      "iter  20 value 103.298666\n",
      "iter  30 value 98.524548\n",
      "iter  40 value 97.691722\n",
      "iter  50 value 97.610415\n",
      "iter  60 value 97.603731\n",
      "iter  70 value 97.602702\n",
      "final  value 97.602665 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 129.887387\n",
      "iter  20 value 93.755275\n",
      "iter  30 value 81.135332\n",
      "iter  40 value 71.291641\n",
      "iter  50 value 65.225065\n",
      "iter  60 value 62.397821\n",
      "iter  70 value 58.977516\n",
      "iter  80 value 55.347728\n",
      "iter  90 value 54.663519\n",
      "iter 100 value 54.352773\n",
      "final  value 54.352773 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 137.209826\n",
      "iter  20 value 94.483369\n",
      "iter  30 value 83.839265\n",
      "iter  40 value 73.977802\n",
      "iter  50 value 66.248180\n",
      "iter  60 value 61.219984\n",
      "iter  70 value 57.500184\n",
      "iter  80 value 56.341720\n",
      "iter  90 value 56.184130\n",
      "iter 100 value 56.183298\n",
      "final  value 56.183298 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 136.158071\n",
      "iter  20 value 106.365879\n",
      "iter  30 value 100.722009\n",
      "iter  40 value 100.264973\n",
      "iter  50 value 100.158990\n",
      "iter  60 value 100.149886\n",
      "iter  70 value 100.149113\n",
      "final  value 100.149061 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 137.211979\n",
      "iter  20 value 94.497142\n",
      "iter  30 value 83.870767\n",
      "iter  40 value 74.079308\n",
      "iter  50 value 66.608379\n",
      "iter  60 value 61.891696\n",
      "iter  70 value 58.788377\n",
      "iter  80 value 58.250879\n",
      "iter  90 value 58.172282\n",
      "iter 100 value 58.129894\n",
      "final  value 58.129894 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 292.230869 \n",
      "iter  10 value 204.574766\n",
      "iter  20 value 167.161483\n",
      "iter  30 value 151.846395\n",
      "iter  40 value 146.953112\n",
      "iter  50 value 144.264166\n",
      "iter  60 value 143.242230\n",
      "iter  70 value 142.835378\n",
      "iter  80 value 142.696195\n",
      "iter  90 value 142.663004\n",
      "final  value 142.662451 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 111.764049\n",
      "iter  20 value 79.126306\n",
      "iter  30 value 67.279011\n",
      "iter  40 value 53.653053\n",
      "iter  50 value 48.975305\n",
      "iter  60 value 47.137499\n",
      "iter  70 value 44.665078\n",
      "iter  80 value 42.628877\n",
      "iter  90 value 42.467891\n",
      "iter 100 value 42.465593\n",
      "final  value 42.465593 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 114.393254\n",
      "iter  20 value 90.098114\n",
      "iter  30 value 85.713967\n",
      "iter  40 value 84.860135\n",
      "iter  50 value 84.734475\n",
      "iter  60 value 84.725494\n",
      "iter  70 value 84.723966\n",
      "final  value 84.723857 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 111.766839\n",
      "iter  20 value 79.140871\n",
      "iter  30 value 67.313277\n",
      "iter  40 value 53.790370\n",
      "iter  50 value 49.241506\n",
      "iter  60 value 47.460336\n",
      "iter  70 value 45.232470\n",
      "iter  80 value 43.928256\n",
      "iter  90 value 43.784413\n",
      "iter 100 value 43.688924\n",
      "final  value 43.688924 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 121.669057\n",
      "iter  20 value 79.548819\n",
      "iter  30 value 62.467026\n",
      "iter  40 value 49.561341\n",
      "iter  50 value 43.577591\n",
      "iter  60 value 42.062090\n",
      "iter  70 value 41.289359\n",
      "iter  80 value 40.081551\n",
      "iter  90 value 39.600770\n",
      "iter 100 value 39.590860\n",
      "final  value 39.590860 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 124.297617\n",
      "iter  20 value 91.040071\n",
      "iter  30 value 83.254435\n",
      "iter  40 value 81.888449\n",
      "iter  50 value 81.656002\n",
      "iter  60 value 81.633136\n",
      "iter  70 value 81.627859\n",
      "iter  80 value 81.627499\n",
      "final  value 81.627477 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 121.671817\n",
      "iter  20 value 79.564048\n",
      "iter  30 value 62.505983\n",
      "iter  40 value 49.689152\n",
      "iter  50 value 43.848362\n",
      "iter  60 value 42.405050\n",
      "iter  70 value 41.722904\n",
      "iter  80 value 40.830198\n",
      "iter  90 value 40.639155\n",
      "iter 100 value 40.556893\n",
      "final  value 40.556893 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 125.699559\n",
      "iter  20 value 87.119068\n",
      "iter  30 value 75.624826\n",
      "iter  40 value 66.932079\n",
      "iter  50 value 59.585447\n",
      "iter  60 value 54.950803\n",
      "iter  70 value 51.872300\n",
      "iter  80 value 47.461642\n",
      "iter  90 value 46.503508\n",
      "iter 100 value 46.447226\n",
      "final  value 46.447226 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 128.463065\n",
      "iter  20 value 95.858162\n",
      "iter  30 value 91.486189\n",
      "iter  40 value 90.468145\n",
      "iter  50 value 90.333832\n",
      "iter  60 value 90.317697\n",
      "iter  70 value 90.312967\n",
      "iter  80 value 90.312551\n",
      "final  value 90.312535 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 125.702455\n",
      "iter  20 value 87.130097\n",
      "iter  30 value 75.653057\n",
      "iter  40 value 67.012536\n",
      "iter  50 value 59.790184\n",
      "iter  60 value 55.370683\n",
      "iter  70 value 52.531749\n",
      "iter  80 value 49.526938\n",
      "iter  90 value 48.872970\n",
      "iter 100 value 48.675690\n",
      "final  value 48.675690 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 292.230869 \n",
      "iter  10 value 197.485296\n",
      "iter  20 value 159.873858\n",
      "iter  30 value 139.907585\n",
      "iter  40 value 133.130389\n",
      "iter  50 value 129.893411\n",
      "iter  60 value 128.336555\n",
      "iter  70 value 127.897291\n",
      "iter  80 value 127.473080\n",
      "iter  90 value 127.332204\n",
      "iter 100 value 127.330582\n",
      "final  value 127.330582 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 118.943814\n",
      "iter  20 value 83.140265\n",
      "iter  30 value 69.462385\n",
      "iter  40 value 60.092172\n",
      "iter  50 value 55.838655\n",
      "iter  60 value 53.849468\n",
      "iter  70 value 49.964762\n",
      "iter  80 value 48.342357\n",
      "iter  90 value 48.095767\n",
      "iter 100 value 48.089057\n",
      "final  value 48.089057 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 120.512594\n",
      "iter  20 value 93.722997\n",
      "iter  30 value 88.739273\n",
      "iter  40 value 87.831272\n",
      "iter  50 value 87.762342\n",
      "iter  60 value 87.757188\n",
      "iter  70 value 87.756185\n",
      "final  value 87.756120 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 118.945446\n",
      "iter  20 value 83.154263\n",
      "iter  30 value 69.502141\n",
      "iter  40 value 60.233550\n",
      "iter  50 value 56.046356\n",
      "iter  60 value 54.148250\n",
      "iter  70 value 50.761470\n",
      "iter  80 value 49.805309\n",
      "iter  90 value 49.603817\n",
      "iter 100 value 49.520908\n",
      "final  value 49.520908 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.357742\n",
      "iter  20 value 79.994206\n",
      "iter  30 value 67.059313\n",
      "iter  40 value 54.525414\n",
      "iter  50 value 42.818766\n",
      "iter  60 value 35.248877\n",
      "iter  70 value 31.440258\n",
      "iter  80 value 30.203705\n",
      "iter  90 value 29.524867\n",
      "iter 100 value 29.305208\n",
      "final  value 29.305208 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 128.723940\n",
      "iter  20 value 91.583002\n",
      "iter  30 value 87.141152\n",
      "iter  40 value 86.344055\n",
      "iter  50 value 86.210557\n",
      "iter  60 value 86.200463\n",
      "iter  70 value 86.198542\n",
      "iter  80 value 86.198401\n",
      "final  value 86.198398 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.360311\n",
      "iter  20 value 80.010345\n",
      "iter  30 value 67.100678\n",
      "iter  40 value 54.729478\n",
      "iter  50 value 43.581103\n",
      "iter  60 value 37.134935\n",
      "iter  70 value 34.867495\n",
      "iter  80 value 34.068367\n",
      "iter  90 value 33.416522\n",
      "iter 100 value 32.836802\n",
      "final  value 32.836802 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 131.705783\n",
      "iter  20 value 83.311587\n",
      "iter  30 value 68.974894\n",
      "iter  40 value 58.007989\n",
      "iter  50 value 49.432022\n",
      "iter  60 value 47.240418\n",
      "iter  70 value 46.197480\n",
      "iter  80 value 45.095097\n",
      "iter  90 value 44.792958\n",
      "iter 100 value 44.784742\n",
      "final  value 44.784742 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 129.283564\n",
      "iter  20 value 97.568713\n",
      "iter  30 value 91.278443\n",
      "iter  40 value 90.573335\n",
      "iter  50 value 90.419163\n",
      "iter  60 value 90.407948\n",
      "iter  70 value 90.407135\n",
      "final  value 90.407046 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 131.707493\n",
      "iter  20 value 83.330518\n",
      "iter  30 value 69.018123\n",
      "iter  40 value 58.241094\n",
      "iter  50 value 49.812098\n",
      "iter  60 value 47.698772\n",
      "iter  70 value 46.806117\n",
      "iter  80 value 46.085321\n",
      "iter  90 value 45.933097\n",
      "iter 100 value 45.909881\n",
      "final  value 45.909881 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 199.262358\n",
      "iter  20 value 162.593344\n",
      "iter  30 value 144.666137\n",
      "iter  40 value 137.782011\n",
      "iter  50 value 134.388783\n",
      "iter  60 value 132.594384\n",
      "iter  70 value 131.851785\n",
      "iter  80 value 131.615904\n",
      "iter  90 value 131.568772\n",
      "final  value 131.568094 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 120.789503\n",
      "iter  20 value 114.150415\n",
      "iter  30 value 113.827615\n",
      "iter  40 value 113.807264\n",
      "iter  50 value 113.801590\n",
      "iter  60 value 113.799527\n",
      "final  value 113.799417 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 124.860663\n",
      "iter  20 value 119.190533\n",
      "iter  30 value 118.548118\n",
      "iter  40 value 118.375178\n",
      "iter  50 value 118.360111\n",
      "iter  60 value 118.359279\n",
      "final  value 118.359224 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 120.793887\n",
      "iter  20 value 114.156743\n",
      "iter  30 value 113.833829\n",
      "iter  40 value 113.813587\n",
      "iter  50 value 113.808030\n",
      "iter  60 value 113.806334\n",
      "iter  70 value 113.806103\n",
      "iter  80 value 113.805960\n",
      "iter  90 value 113.805889\n",
      "iter  90 value 113.805888\n",
      "iter  90 value 113.805888\n",
      "final  value 113.805888 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 123.763409\n",
      "iter  20 value 117.966340\n",
      "iter  30 value 117.661640\n",
      "iter  40 value 117.612401\n",
      "iter  50 value 117.590434\n",
      "iter  60 value 117.589193\n",
      "final  value 117.589128 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 127.551199\n",
      "iter  20 value 121.866423\n",
      "iter  30 value 121.018954\n",
      "iter  40 value 120.811647\n",
      "iter  50 value 120.806609\n",
      "final  value 120.806493 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 123.767475\n",
      "iter  20 value 117.971116\n",
      "iter  30 value 117.666267\n",
      "iter  40 value 117.616681\n",
      "iter  50 value 117.594671\n",
      "iter  60 value 117.593433\n",
      "final  value 117.593369 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 142.512529\n",
      "iter  20 value 131.183082\n",
      "iter  30 value 129.155245\n",
      "iter  40 value 128.890865\n",
      "iter  50 value 128.849803\n",
      "iter  60 value 128.847125\n",
      "iter  70 value 128.846910\n",
      "iter  70 value 128.846909\n",
      "iter  70 value 128.846909\n",
      "final  value 128.846909 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 143.458499\n",
      "iter  20 value 132.860329\n",
      "iter  30 value 131.189137\n",
      "iter  40 value 131.067043\n",
      "iter  50 value 131.050584\n",
      "iter  60 value 131.049870\n",
      "iter  60 value 131.049869\n",
      "iter  60 value 131.049869\n",
      "final  value 131.049869 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 142.513532\n",
      "iter  20 value 131.184901\n",
      "iter  30 value 129.157553\n",
      "iter  40 value 128.893385\n",
      "iter  50 value 128.852372\n",
      "iter  60 value 128.849699\n",
      "iter  70 value 128.849484\n",
      "iter  70 value 128.849483\n",
      "iter  70 value 128.849483\n",
      "final  value 128.849483 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 231.421410\n",
      "iter  20 value 221.922615\n",
      "iter  30 value 220.227971\n",
      "iter  40 value 219.892736\n",
      "iter  50 value 219.871440\n",
      "iter  60 value 219.870334\n",
      "final  value 219.870307 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 132.161317\n",
      "iter  20 value 129.112634\n",
      "iter  30 value 128.738731\n",
      "iter  40 value 128.692005\n",
      "iter  50 value 128.683950\n",
      "iter  60 value 128.683648\n",
      "final  value 128.683611 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 134.853846\n",
      "iter  20 value 131.942094\n",
      "iter  30 value 131.315401\n",
      "iter  40 value 131.228233\n",
      "iter  50 value 131.224239\n",
      "final  value 131.224124 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 132.164212\n",
      "iter  20 value 129.115935\n",
      "iter  30 value 128.741905\n",
      "iter  40 value 128.695066\n",
      "iter  50 value 128.687012\n",
      "iter  60 value 128.686710\n",
      "final  value 128.686673 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 124.903475\n",
      "iter  20 value 120.680869\n",
      "iter  30 value 119.502783\n",
      "iter  40 value 119.262321\n",
      "iter  50 value 119.254415\n",
      "iter  60 value 119.254155\n",
      "final  value 119.254143 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 128.364706\n",
      "iter  20 value 123.323861\n",
      "iter  30 value 121.603205\n",
      "iter  40 value 121.518990\n",
      "iter  50 value 121.515998\n",
      "iter  60 value 121.515897\n",
      "final  value 121.515894 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 124.907132\n",
      "iter  20 value 120.684379\n",
      "iter  30 value 119.505202\n",
      "iter  40 value 119.264960\n",
      "iter  50 value 119.257072\n",
      "iter  60 value 119.256813\n",
      "final  value 119.256801 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 143.898279\n",
      "iter  20 value 136.107983\n",
      "iter  30 value 134.820160\n",
      "iter  40 value 134.481714\n",
      "iter  50 value 134.400276\n",
      "iter  60 value 134.397677\n",
      "final  value 134.397585 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 146.783026\n",
      "iter  20 value 138.812160\n",
      "iter  30 value 136.817626\n",
      "iter  40 value 136.355579\n",
      "iter  50 value 136.330827\n",
      "iter  60 value 136.330256\n",
      "final  value 136.330238 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 143.901354\n",
      "iter  20 value 136.111269\n",
      "iter  30 value 134.822778\n",
      "iter  40 value 134.483912\n",
      "iter  50 value 134.402565\n",
      "iter  60 value 134.399971\n",
      "iter  70 value 134.399873\n",
      "final  value 134.399871 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 292.230869 \n",
      "iter  10 value 233.279044\n",
      "iter  20 value 224.162042\n",
      "iter  30 value 220.344004\n",
      "iter  40 value 219.706728\n",
      "iter  50 value 219.653701\n",
      "iter  60 value 219.650665\n",
      "iter  70 value 219.650520\n",
      "final  value 219.650516 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 153.953455\n",
      "iter  20 value 141.322836\n",
      "iter  30 value 140.165054\n",
      "iter  40 value 139.919968\n",
      "iter  50 value 139.894814\n",
      "iter  60 value 139.893835\n",
      "final  value 139.893692 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 154.530703\n",
      "iter  20 value 142.958901\n",
      "iter  30 value 142.127275\n",
      "iter  40 value 142.024546\n",
      "iter  50 value 142.015728\n",
      "iter  60 value 142.015393\n",
      "final  value 142.015377 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 153.954058\n",
      "iter  20 value 141.324645\n",
      "iter  30 value 140.167356\n",
      "iter  40 value 139.922512\n",
      "iter  50 value 139.897391\n",
      "iter  60 value 139.896414\n",
      "final  value 139.896271 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 152.221616\n",
      "iter  20 value 140.181183\n",
      "iter  30 value 139.092870\n",
      "iter  40 value 139.062730\n",
      "iter  50 value 139.060224\n",
      "iter  60 value 139.059746\n",
      "final  value 139.059727 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 153.532290\n",
      "iter  20 value 141.621325\n",
      "iter  30 value 140.620803\n",
      "iter  40 value 140.598905\n",
      "iter  50 value 140.598216\n",
      "final  value 140.598156 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 152.223000\n",
      "iter  20 value 140.182755\n",
      "iter  30 value 139.094575\n",
      "iter  40 value 139.064454\n",
      "iter  50 value 139.061957\n",
      "iter  60 value 139.061480\n",
      "final  value 139.061461 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.131591\n",
      "iter  20 value 124.627817\n",
      "iter  30 value 122.960345\n",
      "iter  40 value 122.794902\n",
      "iter  50 value 122.791411\n",
      "iter  60 value 122.791271\n",
      "final  value 122.791262 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 131.979772\n",
      "iter  20 value 126.246195\n",
      "iter  30 value 124.453324\n",
      "iter  40 value 124.410302\n",
      "iter  50 value 124.409467\n",
      "final  value 124.409442 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.134634\n",
      "iter  20 value 124.629995\n",
      "iter  30 value 122.961921\n",
      "iter  40 value 122.796708\n",
      "iter  50 value 122.793221\n",
      "iter  60 value 122.793082\n",
      "final  value 122.793072 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 242.197579\n",
      "iter  20 value 235.647759\n",
      "iter  30 value 234.420829\n",
      "iter  40 value 234.133820\n",
      "iter  50 value 234.093848\n",
      "iter  60 value 234.091747\n",
      "final  value 234.091717 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 130.028029\n",
      "iter  20 value 122.674341\n",
      "iter  30 value 122.256650\n",
      "iter  40 value 122.244113\n",
      "iter  50 value 122.243476\n",
      "iter  60 value 122.243129\n",
      "final  value 122.243069 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 133.562092\n",
      "iter  20 value 127.419771\n",
      "iter  30 value 126.539625\n",
      "iter  40 value 126.274216\n",
      "iter  50 value 126.265162\n",
      "iter  60 value 126.264895\n",
      "final  value 126.264887 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 130.031787\n",
      "iter  20 value 122.680282\n",
      "iter  30 value 122.262786\n",
      "iter  40 value 122.250226\n",
      "iter  50 value 122.249542\n",
      "iter  60 value 122.249173\n",
      "final  value 122.249111 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 136.645002\n",
      "iter  20 value 129.523347\n",
      "iter  30 value 127.517994\n",
      "iter  40 value 127.192458\n",
      "iter  50 value 127.183819\n",
      "iter  60 value 127.183547\n",
      "final  value 127.183526 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 139.314687\n",
      "iter  20 value 131.159988\n",
      "iter  30 value 128.862914\n",
      "iter  40 value 128.728749\n",
      "iter  50 value 128.726163\n",
      "iter  60 value 128.726068\n",
      "final  value 128.726064 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 136.647851\n",
      "iter  20 value 129.525682\n",
      "iter  30 value 127.519422\n",
      "iter  40 value 127.194181\n",
      "iter  50 value 127.185557\n",
      "iter  60 value 127.185286\n",
      "final  value 127.185264 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 148.498547\n",
      "iter  20 value 138.659168\n",
      "iter  30 value 137.809823\n",
      "iter  40 value 137.705280\n",
      "iter  50 value 137.694017\n",
      "iter  60 value 137.693586\n",
      "final  value 137.693569 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 149.072897\n",
      "iter  20 value 139.778912\n",
      "iter  30 value 139.086789\n",
      "iter  40 value 139.031242\n",
      "iter  50 value 139.025926\n",
      "iter  60 value 139.025751\n",
      "final  value 139.025741 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 148.499147\n",
      "iter  20 value 138.660366\n",
      "iter  30 value 137.811228\n",
      "iter  40 value 137.706760\n",
      "iter  50 value 137.695507\n",
      "iter  60 value 137.695075\n",
      "final  value 137.695059 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 235.067681\n",
      "iter  20 value 228.314173\n",
      "iter  30 value 225.911344\n",
      "iter  40 value 225.561433\n",
      "iter  50 value 225.524070\n",
      "iter  60 value 225.522880\n",
      "final  value 225.522861 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 143.877609\n",
      "iter  20 value 134.309547\n",
      "iter  30 value 133.681965\n",
      "iter  40 value 133.619444\n",
      "iter  50 value 133.613949\n",
      "iter  60 value 133.613738\n",
      "final  value 133.613731 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 144.573881\n",
      "iter  20 value 135.406868\n",
      "iter  30 value 134.885299\n",
      "iter  40 value 134.848072\n",
      "iter  50 value 134.845206\n",
      "final  value 134.845104 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 143.878345\n",
      "iter  20 value 134.310720\n",
      "iter  30 value 133.683274\n",
      "iter  40 value 133.620789\n",
      "iter  50 value 133.615298\n",
      "iter  60 value 133.615087\n",
      "final  value 133.615081 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 149.621962\n",
      "iter  20 value 136.403056\n",
      "iter  30 value 135.207486\n",
      "iter  40 value 135.105097\n",
      "iter  50 value 135.073458\n",
      "iter  60 value 135.071770\n",
      "iter  70 value 135.071715\n",
      "iter  80 value 135.071686\n",
      "iter  90 value 135.071658\n",
      "iter  90 value 135.071657\n",
      "iter  90 value 135.071656\n",
      "final  value 135.071656 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 151.120590\n",
      "iter  20 value 138.378696\n",
      "iter  30 value 137.417258\n",
      "iter  40 value 137.386895\n",
      "iter  50 value 137.383444\n",
      "iter  60 value 137.383062\n",
      "final  value 137.383045 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 149.623570\n",
      "iter  20 value 136.405290\n",
      "iter  30 value 135.210074\n",
      "iter  40 value 135.107851\n",
      "iter  50 value 135.076279\n",
      "iter  60 value 135.074595\n",
      "iter  70 value 135.074540\n",
      "iter  80 value 135.074510\n",
      "iter  90 value 135.074482\n",
      "iter  90 value 135.074481\n",
      "iter  90 value 135.074481\n",
      "final  value 135.074481 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 136.541361\n",
      "iter  20 value 129.275030\n",
      "iter  30 value 128.656170\n",
      "iter  40 value 128.424690\n",
      "iter  50 value 128.391486\n",
      "iter  60 value 128.390443\n",
      "final  value 128.390380 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 140.120596\n",
      "iter  20 value 133.192067\n",
      "iter  30 value 131.513221\n",
      "iter  40 value 131.240563\n",
      "iter  50 value 131.231244\n",
      "iter  60 value 131.231022\n",
      "final  value 131.231000 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 136.545206\n",
      "iter  20 value 129.280067\n",
      "iter  30 value 128.660458\n",
      "iter  40 value 128.428462\n",
      "iter  50 value 128.395287\n",
      "iter  60 value 128.394327\n",
      "iter  70 value 128.394271\n",
      "iter  80 value 128.394254\n",
      "iter  90 value 128.394201\n",
      "final  value 128.394187 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 238.554433\n",
      "iter  20 value 231.703090\n",
      "iter  30 value 229.665792\n",
      "iter  40 value 229.306170\n",
      "iter  50 value 229.249209\n",
      "iter  60 value 229.247444\n",
      "final  value 229.247397 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 144.508530\n",
      "iter  20 value 130.479107\n",
      "iter  30 value 128.965393\n",
      "iter  40 value 128.656877\n",
      "iter  50 value 128.605818\n",
      "iter  60 value 128.603277\n",
      "iter  70 value 128.602862\n",
      "final  value 128.602856 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 145.143927\n",
      "iter  20 value 132.172219\n",
      "iter  30 value 130.996900\n",
      "iter  40 value 130.861668\n",
      "iter  50 value 130.843958\n",
      "iter  60 value 130.843174\n",
      "final  value 130.843163 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 144.509197\n",
      "iter  20 value 130.480966\n",
      "iter  30 value 128.967720\n",
      "iter  40 value 128.659508\n",
      "iter  50 value 128.608519\n",
      "iter  60 value 128.605982\n",
      "iter  70 value 128.605567\n",
      "final  value 128.605562 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 142.553828\n",
      "iter  20 value 137.174422\n",
      "iter  30 value 136.195843\n",
      "iter  40 value 135.925944\n",
      "iter  50 value 135.911714\n",
      "iter  60 value 135.911290\n",
      "final  value 135.911287 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 144.976835\n",
      "iter  20 value 139.281199\n",
      "iter  30 value 137.905774\n",
      "iter  40 value 137.751431\n",
      "iter  50 value 137.746911\n",
      "iter  60 value 137.746784\n",
      "final  value 137.746781 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 142.556394\n",
      "iter  20 value 137.176994\n",
      "iter  30 value 136.197884\n",
      "iter  40 value 135.928030\n",
      "iter  50 value 135.913820\n",
      "iter  60 value 135.913397\n",
      "final  value 135.913394 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 142.519843\n",
      "iter  20 value 129.922867\n",
      "iter  30 value 128.695852\n",
      "iter  40 value 128.506821\n",
      "iter  50 value 128.479470\n",
      "iter  60 value 128.478505\n",
      "iter  70 value 128.478388\n",
      "iter  70 value 128.478388\n",
      "iter  70 value 128.478388\n",
      "final  value 128.478388 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 143.361531\n",
      "iter  20 value 131.456094\n",
      "iter  30 value 130.470802\n",
      "iter  40 value 130.383611\n",
      "iter  50 value 130.372026\n",
      "final  value 130.371671 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 142.520739\n",
      "iter  20 value 129.924544\n",
      "iter  30 value 128.697861\n",
      "iter  40 value 128.509005\n",
      "iter  50 value 128.481686\n",
      "iter  60 value 128.480720\n",
      "iter  70 value 128.480605\n",
      "iter  70 value 128.480605\n",
      "iter  70 value 128.480605\n",
      "final  value 128.480605 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 294.428093 \n",
      "iter  10 value 239.057113\n",
      "iter  20 value 231.825881\n",
      "iter  30 value 229.096654\n",
      "iter  40 value 228.753021\n",
      "iter  50 value 228.697542\n",
      "iter  60 value 228.695858\n",
      "final  value 228.695815 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 142.947548\n",
      "iter  20 value 135.045397\n",
      "iter  30 value 133.293025\n",
      "iter  40 value 132.654075\n",
      "iter  50 value 132.623639\n",
      "iter  60 value 132.622729\n",
      "final  value 132.622665 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 145.392243\n",
      "iter  20 value 137.208128\n",
      "iter  30 value 134.599209\n",
      "iter  40 value 134.216000\n",
      "iter  50 value 134.205198\n",
      "iter  60 value 134.204932\n",
      "final  value 134.204928 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 142.950070\n",
      "iter  20 value 135.048050\n",
      "iter  30 value 133.294698\n",
      "iter  40 value 132.655814\n",
      "iter  50 value 132.625437\n",
      "iter  60 value 132.624530\n",
      "final  value 132.624465 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 136.315368\n",
      "iter  20 value 130.841523\n",
      "iter  30 value 129.798279\n",
      "iter  40 value 129.581314\n",
      "iter  50 value 129.573627\n",
      "iter  60 value 129.573385\n",
      "final  value 129.573373 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 138.905088\n",
      "iter  20 value 132.880066\n",
      "iter  30 value 131.408381\n",
      "iter  40 value 131.300133\n",
      "iter  50 value 131.297734\n",
      "final  value 131.297638 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 136.318139\n",
      "iter  20 value 130.844051\n",
      "iter  30 value 129.800100\n",
      "iter  40 value 129.583278\n",
      "iter  50 value 129.575601\n",
      "iter  60 value 129.575360\n",
      "final  value 129.575348 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 139.743224\n",
      "iter  20 value 131.745570\n",
      "iter  30 value 129.779840\n",
      "iter  40 value 129.165708\n",
      "iter  50 value 129.144610\n",
      "iter  60 value 129.143890\n",
      "final  value 129.143855 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 142.950668\n",
      "iter  20 value 133.884797\n",
      "iter  30 value 131.004922\n",
      "iter  40 value 130.750580\n",
      "iter  50 value 130.742530\n",
      "iter  60 value 130.742333\n",
      "final  value 130.742317 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 139.746592\n",
      "iter  20 value 131.748480\n",
      "iter  30 value 129.781140\n",
      "iter  40 value 129.167475\n",
      "iter  50 value 129.146410\n",
      "iter  60 value 129.145690\n",
      "final  value 129.145655 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 234.862626\n",
      "iter  20 value 227.605998\n",
      "iter  30 value 224.251809\n",
      "iter  40 value 223.552988\n",
      "iter  50 value 223.492294\n",
      "iter  60 value 223.490536\n",
      "final  value 223.490498 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 151.424086\n",
      "iter  20 value 144.255187\n",
      "iter  30 value 142.716653\n",
      "iter  40 value 142.386770\n",
      "iter  50 value 142.357005\n",
      "iter  60 value 142.356485\n",
      "final  value 142.356469 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 153.758781\n",
      "iter  20 value 145.904944\n",
      "iter  30 value 144.075166\n",
      "iter  40 value 143.826298\n",
      "iter  50 value 143.812757\n",
      "final  value 143.812503 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 151.426603\n",
      "iter  20 value 144.257136\n",
      "iter  30 value 142.718190\n",
      "iter  40 value 142.388369\n",
      "iter  50 value 142.358625\n",
      "iter  60 value 142.358106\n",
      "final  value 142.358089 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 149.648916\n",
      "iter  20 value 136.680334\n",
      "iter  30 value 134.937805\n",
      "iter  40 value 134.673595\n",
      "iter  50 value 134.631376\n",
      "iter  60 value 134.629277\n",
      "final  value 134.629208 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 150.311896\n",
      "iter  20 value 138.214827\n",
      "iter  30 value 136.697087\n",
      "iter  40 value 136.549322\n",
      "iter  50 value 136.532214\n",
      "iter  60 value 136.531365\n",
      "final  value 136.531331 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 149.649614\n",
      "iter  20 value 136.681993\n",
      "iter  30 value 134.939771\n",
      "iter  40 value 134.675719\n",
      "iter  50 value 134.633540\n",
      "iter  60 value 134.631447\n",
      "final  value 134.631378 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.817755\n",
      "iter  20 value 124.265562\n",
      "iter  30 value 123.273603\n",
      "iter  40 value 122.923148\n",
      "iter  50 value 122.886787\n",
      "iter  60 value 122.885672\n",
      "final  value 122.885580 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 133.328205\n",
      "iter  20 value 127.514402\n",
      "iter  30 value 125.799341\n",
      "iter  40 value 125.485900\n",
      "iter  50 value 125.476677\n",
      "iter  60 value 125.476382\n",
      "final  value 125.476347 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.821507\n",
      "iter  20 value 124.269572\n",
      "iter  30 value 123.276968\n",
      "iter  40 value 122.926192\n",
      "iter  50 value 122.889894\n",
      "iter  60 value 122.888783\n",
      "final  value 122.888690 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 242.156803\n",
      "iter  20 value 234.983334\n",
      "iter  30 value 232.057972\n",
      "iter  40 value 231.101821\n",
      "iter  50 value 230.979884\n",
      "iter  60 value 230.974788\n",
      "final  value 230.974591 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 132.770926\n",
      "iter  20 value 125.535372\n",
      "iter  30 value 124.765100\n",
      "iter  40 value 124.688701\n",
      "iter  50 value 124.642803\n",
      "iter  60 value 124.639046\n",
      "final  value 124.638939 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 135.986572\n",
      "iter  20 value 128.835887\n",
      "iter  30 value 127.744159\n",
      "iter  40 value 127.421538\n",
      "iter  50 value 127.396831\n",
      "iter  60 value 127.396160\n",
      "final  value 127.396131 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 132.774352\n",
      "iter  20 value 125.539332\n",
      "iter  30 value 124.768996\n",
      "iter  40 value 124.692330\n",
      "iter  50 value 124.646308\n",
      "iter  60 value 124.642556\n",
      "final  value 124.642449 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 139.990128\n",
      "iter  20 value 131.509434\n",
      "iter  30 value 130.587772\n",
      "iter  40 value 130.494592\n",
      "iter  50 value 130.458630\n",
      "iter  60 value 130.456798\n",
      "final  value 130.456728 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 142.770883\n",
      "iter  20 value 134.666290\n",
      "iter  30 value 133.429928\n",
      "iter  40 value 133.188149\n",
      "iter  50 value 133.172878\n",
      "iter  60 value 133.172499\n",
      "final  value 133.172479 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 139.993145\n",
      "iter  20 value 131.513303\n",
      "iter  30 value 130.591495\n",
      "iter  40 value 130.498036\n",
      "iter  50 value 130.462047\n",
      "iter  60 value 130.460218\n",
      "final  value 130.460149 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 129.026726\n",
      "iter  20 value 123.528805\n",
      "iter  30 value 122.706117\n",
      "iter  40 value 122.404233\n",
      "iter  50 value 122.375747\n",
      "iter  60 value 122.374422\n",
      "iter  70 value 122.374246\n",
      "iter  70 value 122.374245\n",
      "iter  70 value 122.374245\n",
      "final  value 122.374245 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 132.259375\n",
      "iter  20 value 126.534347\n",
      "iter  30 value 124.941530\n",
      "iter  40 value 124.746014\n",
      "iter  50 value 124.741286\n",
      "iter  60 value 124.741119\n",
      "final  value 124.741113 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 129.030175\n",
      "iter  20 value 123.532484\n",
      "iter  30 value 122.709071\n",
      "iter  40 value 122.406981\n",
      "iter  50 value 122.378560\n",
      "iter  60 value 122.377239\n",
      "iter  70 value 122.377062\n",
      "iter  70 value 122.377062\n",
      "iter  70 value 122.377062\n",
      "final  value 122.377062 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 236.176374\n",
      "iter  20 value 225.104241\n",
      "iter  30 value 223.242296\n",
      "iter  40 value 222.670712\n",
      "iter  50 value 222.591083\n",
      "iter  60 value 222.588837\n",
      "final  value 222.588760 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.352393\n",
      "iter  20 value 119.551372\n",
      "iter  30 value 118.632899\n",
      "iter  40 value 118.339159\n",
      "iter  50 value 118.117073\n",
      "iter  60 value 118.095763\n",
      "iter  70 value 118.094932\n",
      "final  value 118.094929 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.312637\n",
      "iter  20 value 124.244095\n",
      "iter  30 value 123.654097\n",
      "iter  40 value 123.566121\n",
      "iter  50 value 123.544267\n",
      "iter  60 value 123.543410\n",
      "final  value 123.543383 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 126.355624\n",
      "iter  20 value 119.557019\n",
      "iter  30 value 118.639651\n",
      "iter  40 value 118.347802\n",
      "iter  50 value 118.127268\n",
      "iter  60 value 118.106124\n",
      "iter  70 value 118.105298\n",
      "final  value 118.105295 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 126.523629\n",
      "iter  20 value 120.843918\n",
      "iter  30 value 120.315022\n",
      "iter  40 value 120.294274\n",
      "iter  50 value 120.291958\n",
      "iter  60 value 120.290120\n",
      "iter  70 value 120.289832\n",
      "final  value 120.289829 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 130.837510\n",
      "iter  20 value 125.578772\n",
      "iter  30 value 124.558860\n",
      "iter  40 value 124.263306\n",
      "iter  50 value 124.249763\n",
      "iter  60 value 124.249416\n",
      "final  value 124.249399 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 196.651600 \n",
      "iter  10 value 126.528286\n",
      "iter  20 value 120.849794\n",
      "iter  30 value 120.321096\n",
      "iter  40 value 120.300303\n",
      "iter  50 value 120.297894\n",
      "iter  60 value 120.296243\n",
      "iter  70 value 120.295935\n",
      "iter  80 value 120.295796\n",
      "iter  90 value 120.295735\n",
      "iter 100 value 120.295712\n",
      "final  value 120.295712 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 138.271378\n",
      "iter  20 value 117.317002\n",
      "iter  30 value 113.482824\n",
      "iter  40 value 111.128885\n",
      "iter  50 value 110.366277\n",
      "iter  60 value 110.279976\n",
      "iter  70 value 110.270616\n",
      "final  value 110.270542 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 139.887041\n",
      "iter  20 value 120.596293\n",
      "iter  30 value 118.043261\n",
      "iter  40 value 117.420125\n",
      "iter  50 value 117.310388\n",
      "iter  60 value 117.305130\n",
      "iter  70 value 117.304928\n",
      "final  value 117.304923 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 138.273123\n",
      "iter  20 value 117.320773\n",
      "iter  30 value 113.488633\n",
      "iter  40 value 111.139268\n",
      "iter  50 value 110.379948\n",
      "iter  60 value 110.294415\n",
      "iter  70 value 110.285151\n",
      "final  value 110.285078 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 231.370090\n",
      "iter  20 value 215.014406\n",
      "iter  30 value 210.709763\n",
      "iter  40 value 209.367068\n",
      "iter  50 value 209.215886\n",
      "iter  60 value 209.197277\n",
      "iter  70 value 209.193958\n",
      "final  value 209.193806 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 125.154488\n",
      "iter  20 value 118.985631\n",
      "iter  30 value 118.699605\n",
      "iter  40 value 118.684634\n",
      "iter  50 value 118.679154\n",
      "iter  60 value 118.678321\n",
      "final  value 118.678305 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 128.320186\n",
      "iter  20 value 122.916898\n",
      "iter  30 value 122.302915\n",
      "iter  40 value 122.173885\n",
      "iter  50 value 122.168315\n",
      "iter  60 value 122.168103\n",
      "final  value 122.168095 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 125.157879\n",
      "iter  20 value 118.990464\n",
      "iter  30 value 118.704405\n",
      "iter  40 value 118.689314\n",
      "iter  50 value 118.683786\n",
      "iter  60 value 118.682949\n",
      "final  value 118.682932 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 129.811382\n",
      "iter  20 value 123.096687\n",
      "iter  30 value 121.507033\n",
      "iter  40 value 121.276697\n",
      "iter  50 value 121.269365\n",
      "final  value 121.269014 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 132.570883\n",
      "iter  20 value 125.140109\n",
      "iter  30 value 123.399414\n",
      "iter  40 value 123.296274\n",
      "iter  50 value 123.293879\n",
      "final  value 123.293802 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 129.814296\n",
      "iter  20 value 123.099464\n",
      "iter  30 value 121.509150\n",
      "iter  40 value 121.278998\n",
      "iter  50 value 121.271676\n",
      "final  value 121.271325 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 143.636150\n",
      "iter  20 value 138.340832\n",
      "iter  30 value 136.832635\n",
      "iter  40 value 136.321575\n",
      "iter  50 value 136.292303\n",
      "iter  60 value 136.291523\n",
      "final  value 136.291491 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 145.939997\n",
      "iter  20 value 140.109216\n",
      "iter  30 value 138.011302\n",
      "iter  40 value 137.685324\n",
      "iter  50 value 137.677095\n",
      "final  value 137.676919 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 194.454375 \n",
      "iter  10 value 143.638582\n",
      "iter  20 value 138.342617\n",
      "iter  30 value 136.834002\n",
      "iter  40 value 136.323069\n",
      "iter  50 value 136.293857\n",
      "iter  60 value 136.293079\n",
      "final  value 136.293047 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 292.230869 \n",
      "iter  10 value 236.191063\n",
      "iter  20 value 227.737160\n",
      "iter  30 value 225.266671\n",
      "iter  40 value 224.967536\n",
      "iter  50 value 224.937130\n",
      "iter  60 value 224.935724\n",
      "final  value 224.935648 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 130.626232\n",
      "iter  20 value 124.555663\n",
      "iter  30 value 123.835031\n",
      "iter  40 value 123.473481\n",
      "iter  50 value 123.447336\n",
      "iter  60 value 123.446546\n",
      "final  value 123.446481 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 133.815782\n",
      "iter  20 value 127.589470\n",
      "iter  30 value 125.857108\n",
      "iter  40 value 125.658280\n",
      "iter  50 value 125.651621\n",
      "iter  60 value 125.651458\n",
      "final  value 125.651444 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 130.629623\n",
      "iter  20 value 124.559538\n",
      "iter  30 value 123.837683\n",
      "iter  40 value 123.476064\n",
      "iter  50 value 123.449982\n",
      "iter  60 value 123.449194\n",
      "final  value 123.449129 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.736127\n",
      "iter  20 value 123.959072\n",
      "iter  30 value 122.688766\n",
      "iter  40 value 122.235252\n",
      "iter  50 value 122.181353\n",
      "iter  60 value 122.179371\n",
      "iter  60 value 122.179370\n",
      "iter  70 value 122.179273\n",
      "iter  70 value 122.179273\n",
      "final  value 122.179264 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 133.144704\n",
      "iter  20 value 126.732274\n",
      "iter  30 value 124.713179\n",
      "iter  40 value 124.371284\n",
      "iter  50 value 124.362812\n",
      "final  value 124.362595 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 129.739795\n",
      "iter  20 value 123.962520\n",
      "iter  30 value 122.691404\n",
      "iter  40 value 122.237697\n",
      "iter  50 value 122.183900\n",
      "iter  60 value 122.181922\n",
      "iter  60 value 122.181921\n",
      "iter  70 value 122.181825\n",
      "iter  70 value 122.181825\n",
      "final  value 122.181816 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 130.625914\n",
      "iter  20 value 126.729923\n",
      "iter  30 value 126.397636\n",
      "iter  40 value 126.256419\n",
      "iter  50 value 126.237083\n",
      "iter  60 value 126.236558\n",
      "final  value 126.236492 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 133.255938\n",
      "iter  20 value 129.475250\n",
      "iter  30 value 128.589265\n",
      "iter  40 value 128.412389\n",
      "iter  50 value 128.406466\n",
      "iter  60 value 128.406321\n",
      "final  value 128.406316 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 130.628711\n",
      "iter  20 value 126.733214\n",
      "iter  30 value 126.400559\n",
      "iter  40 value 126.259049\n",
      "iter  50 value 126.239737\n",
      "iter  60 value 126.239213\n",
      "final  value 126.239147 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 294.428093 \n",
      "iter  10 value 230.418476\n",
      "iter  20 value 221.482025\n",
      "iter  30 value 219.345775\n",
      "iter  40 value 219.020521\n",
      "iter  50 value 218.986260\n",
      "iter  60 value 218.984443\n",
      "final  value 218.984365 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 147.683728\n",
      "iter  20 value 133.241135\n",
      "iter  30 value 131.222616\n",
      "iter  40 value 130.739723\n",
      "iter  50 value 130.659829\n",
      "iter  60 value 130.656384\n",
      "final  value 130.656136 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 148.369712\n",
      "iter  20 value 134.916874\n",
      "iter  30 value 133.394825\n",
      "iter  40 value 133.190862\n",
      "iter  50 value 133.167421\n",
      "iter  60 value 133.166423\n",
      "final  value 133.166386 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 147.684456\n",
      "iter  20 value 133.242963\n",
      "iter  30 value 131.225096\n",
      "iter  40 value 130.742693\n",
      "iter  50 value 130.662922\n",
      "iter  60 value 130.659484\n",
      "final  value 130.659236 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 124.207218\n",
      "iter  20 value 120.711734\n",
      "iter  30 value 120.331833\n",
      "iter  40 value 120.227043\n",
      "iter  50 value 120.204995\n",
      "iter  60 value 120.203960\n",
      "final  value 120.203863 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 127.948305\n",
      "iter  20 value 124.459858\n",
      "iter  30 value 123.452920\n",
      "iter  40 value 123.313210\n",
      "iter  50 value 123.308708\n",
      "iter  60 value 123.308568\n",
      "final  value 123.308559 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 124.211264\n",
      "iter  20 value 120.716349\n",
      "iter  30 value 120.336123\n",
      "iter  40 value 120.230991\n",
      "iter  50 value 120.208962\n",
      "iter  60 value 120.207930\n",
      "final  value 120.207832 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 132.396045\n",
      "iter  20 value 127.068932\n",
      "iter  30 value 126.127691\n",
      "iter  40 value 125.829788\n",
      "iter  50 value 125.810369\n",
      "iter  60 value 125.809629\n",
      "final  value 125.809588 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 135.008633\n",
      "iter  20 value 129.430559\n",
      "iter  30 value 127.979324\n",
      "iter  40 value 127.849123\n",
      "iter  50 value 127.846329\n",
      "iter  60 value 127.846230\n",
      "final  value 127.846228 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 132.398825\n",
      "iter  20 value 127.072267\n",
      "iter  30 value 126.130091\n",
      "iter  40 value 125.832174\n",
      "iter  50 value 125.812789\n",
      "iter  60 value 125.812050\n",
      "final  value 125.812010 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 230.412399\n",
      "iter  20 value 221.327597\n",
      "iter  30 value 218.010129\n",
      "iter  40 value 217.095560\n",
      "iter  50 value 217.022001\n",
      "iter  60 value 217.020619\n",
      "final  value 217.020594 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 131.126310\n",
      "iter  20 value 126.681031\n",
      "iter  30 value 125.792608\n",
      "iter  40 value 125.584767\n",
      "iter  50 value 125.576160\n",
      "final  value 125.575847 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 133.749652\n",
      "iter  20 value 128.907135\n",
      "iter  30 value 127.481330\n",
      "iter  40 value 127.406194\n",
      "iter  50 value 127.404378\n",
      "final  value 127.404320 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 131.129094\n",
      "iter  20 value 126.683791\n",
      "iter  30 value 125.794523\n",
      "iter  40 value 125.586854\n",
      "iter  50 value 125.578264\n",
      "final  value 125.577951 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 131.915016\n",
      "iter  20 value 128.024602\n",
      "iter  30 value 127.181010\n",
      "iter  40 value 127.049727\n",
      "iter  50 value 127.046075\n",
      "iter  60 value 127.045936\n",
      "final  value 127.045932 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 134.242697\n",
      "iter  20 value 129.958132\n",
      "iter  30 value 128.806447\n",
      "iter  40 value 128.760469\n",
      "iter  50 value 128.759598\n",
      "final  value 128.759576 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 131.917489\n",
      "iter  20 value 128.027054\n",
      "iter  30 value 127.182821\n",
      "iter  40 value 127.051676\n",
      "iter  50 value 127.048029\n",
      "iter  60 value 127.047891\n",
      "final  value 127.047887 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 140.237831\n",
      "iter  20 value 131.281199\n",
      "iter  30 value 130.661628\n",
      "iter  40 value 130.611460\n",
      "iter  50 value 130.608216\n",
      "iter  60 value 130.607922\n",
      "iter  70 value 130.607769\n",
      "final  value 130.607713 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 140.893312\n",
      "iter  20 value 132.251363\n",
      "iter  30 value 131.669023\n",
      "iter  40 value 131.634636\n",
      "iter  50 value 131.632545\n",
      "final  value 131.632408 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 140.238522\n",
      "iter  20 value 131.282218\n",
      "iter  30 value 130.662697\n",
      "iter  40 value 130.612549\n",
      "iter  50 value 130.609307\n",
      "iter  60 value 130.609013\n",
      "iter  70 value 130.608861\n",
      "final  value 130.608804 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 293.329481 \n",
      "iter  10 value 230.676072\n",
      "iter  20 value 223.395019\n",
      "iter  30 value 221.607013\n",
      "iter  40 value 221.260259\n",
      "iter  50 value 221.242493\n",
      "iter  60 value 221.241769\n",
      "final  value 221.241751 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 119.733412\n",
      "iter  20 value 116.498838\n",
      "iter  30 value 116.098066\n",
      "iter  40 value 115.862367\n",
      "iter  50 value 115.789636\n",
      "iter  60 value 115.786212\n",
      "final  value 115.785949 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 124.402328\n",
      "iter  20 value 121.867238\n",
      "iter  30 value 121.595778\n",
      "iter  40 value 121.519336\n",
      "iter  50 value 121.514456\n",
      "iter  60 value 121.514278\n",
      "final  value 121.514269 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 119.738549\n",
      "iter  20 value 116.505599\n",
      "iter  30 value 116.105853\n",
      "iter  40 value 115.871912\n",
      "iter  50 value 115.799624\n",
      "iter  60 value 115.796221\n",
      "final  value 115.795959 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 139.030354\n",
      "iter  20 value 131.468636\n",
      "iter  30 value 130.695312\n",
      "iter  40 value 130.666817\n",
      "iter  50 value 130.666132\n",
      "final  value 130.666114 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 141.681355\n",
      "iter  20 value 135.183209\n",
      "iter  30 value 134.282990\n",
      "iter  40 value 134.071880\n",
      "iter  50 value 134.053932\n",
      "iter  60 value 134.053271\n",
      "final  value 134.053223 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 195.552987 \n",
      "iter  10 value 139.033152\n",
      "iter  20 value 131.473138\n",
      "iter  30 value 130.700088\n",
      "iter  40 value 130.671605\n",
      "iter  50 value 130.670917\n",
      "final  value 130.670896 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 118.392464\n",
      "iter  20 value 110.154002\n",
      "iter  30 value 109.874997\n",
      "iter  40 value 109.860838\n",
      "iter  50 value 109.858564\n",
      "iter  60 value 109.857542\n",
      "final  value 109.857453 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 121.573289\n",
      "iter  20 value 114.292008\n",
      "iter  30 value 113.665186\n",
      "iter  40 value 113.440823\n",
      "iter  50 value 113.430769\n",
      "iter  60 value 113.430280\n",
      "final  value 113.430255 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 197.750212 \n",
      "iter  10 value 118.395795\n",
      "iter  20 value 110.158916\n",
      "iter  30 value 109.880028\n",
      "iter  40 value 109.865828\n",
      "iter  50 value 109.863491\n",
      "iter  60 value 109.862448\n",
      "final  value 109.862358 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 294.428093 \n",
      "iter  10 value 231.510188\n",
      "iter  20 value 217.388862\n",
      "iter  30 value 213.938308\n",
      "iter  40 value 213.204432\n",
      "iter  50 value 213.122140\n",
      "iter  60 value 213.112559\n",
      "iter  70 value 213.111693\n",
      "final  value 213.111665 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  92 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 24 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 30 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 63.085228\n",
      "iter  20 value 35.440361\n",
      "iter  30 value 16.130251\n",
      "iter  40 value 1.941198\n",
      "iter  50 value 0.007542\n",
      "final  value 0.000076 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 67.013357\n",
      "iter  20 value 46.869932\n",
      "iter  30 value 43.323735\n",
      "iter  40 value 42.398566\n",
      "iter  50 value 42.071395\n",
      "iter  60 value 42.038889\n",
      "iter  70 value 42.036891\n",
      "iter  80 value 42.036771\n",
      "final  value 42.036768 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 63.089476\n",
      "iter  20 value 35.459199\n",
      "iter  30 value 16.340127\n",
      "iter  40 value 2.611695\n",
      "iter  50 value 1.108479\n",
      "iter  60 value 1.061695\n",
      "iter  70 value 0.996894\n",
      "iter  80 value 0.947039\n",
      "iter  90 value 0.917388\n",
      "iter 100 value 0.891653\n",
      "final  value 0.891653 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.182535\n",
      "iter  20 value 49.657236\n",
      "iter  30 value 36.376625\n",
      "iter  40 value 19.594253\n",
      "iter  50 value 6.891826\n",
      "iter  60 value 0.024053\n",
      "final  value 0.000074 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 81.159165\n",
      "iter  20 value 59.838775\n",
      "iter  30 value 57.228114\n",
      "iter  40 value 56.868452\n",
      "iter  50 value 56.781359\n",
      "iter  60 value 56.764234\n",
      "iter  70 value 56.763282\n",
      "final  value 56.763269 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.185755\n",
      "iter  20 value 49.671841\n",
      "iter  30 value 36.458070\n",
      "iter  40 value 20.012447\n",
      "iter  50 value 9.881558\n",
      "iter  60 value 6.664144\n",
      "iter  70 value 5.938947\n",
      "iter  80 value 5.285995\n",
      "iter  90 value 4.937884\n",
      "iter 100 value 4.740058\n",
      "final  value 4.740058 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 62.205667\n",
      "iter  20 value 38.055351\n",
      "iter  30 value 23.369514\n",
      "iter  40 value 9.596101\n",
      "iter  50 value 0.062569\n",
      "final  value 0.000094 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 65.200840\n",
      "iter  20 value 49.269367\n",
      "iter  30 value 46.370554\n",
      "iter  40 value 45.688238\n",
      "iter  50 value 45.603935\n",
      "iter  60 value 45.600322\n",
      "iter  70 value 45.600212\n",
      "final  value 45.600207 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 62.208866\n",
      "iter  20 value 38.071331\n",
      "iter  30 value 23.448464\n",
      "iter  40 value 9.646669\n",
      "iter  50 value 2.950650\n",
      "iter  60 value 2.670634\n",
      "iter  70 value 2.337976\n",
      "iter  80 value 2.148603\n",
      "iter  90 value 2.029944\n",
      "iter 100 value 1.904782\n",
      "final  value 1.904782 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 131.399109\n",
      "iter  20 value 86.995759\n",
      "iter  30 value 74.458277\n",
      "iter  40 value 64.837245\n",
      "iter  50 value 59.391925\n",
      "iter  60 value 55.100351\n",
      "iter  70 value 51.233019\n",
      "iter  80 value 48.617930\n",
      "iter  90 value 42.529071\n",
      "iter 100 value 41.270919\n",
      "final  value 41.270919 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 61 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 54.715886\n",
      "iter  20 value 30.351934\n",
      "iter  30 value 7.947966\n",
      "iter  40 value 0.137864\n",
      "iter  50 value 0.000287\n",
      "final  value 0.000083 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 59.037515\n",
      "iter  20 value 43.951118\n",
      "iter  30 value 41.929516\n",
      "iter  40 value 41.012517\n",
      "iter  50 value 40.889384\n",
      "iter  60 value 40.876478\n",
      "iter  70 value 40.875113\n",
      "final  value 40.875068 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 54.720590\n",
      "iter  20 value 30.372444\n",
      "iter  30 value 8.181222\n",
      "iter  40 value 1.139737\n",
      "iter  50 value 1.062184\n",
      "iter  60 value 0.981450\n",
      "iter  70 value 0.900240\n",
      "iter  80 value 0.844801\n",
      "iter  90 value 0.812320\n",
      "iter 100 value 0.795157\n",
      "final  value 0.795157 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.176264\n",
      "iter  20 value 47.718794\n",
      "iter  30 value 26.105905\n",
      "iter  40 value 6.812214\n",
      "iter  50 value 0.104871\n",
      "iter  60 value 0.000806\n",
      "final  value 0.000088 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 79.415737\n",
      "iter  20 value 57.638626\n",
      "iter  30 value 53.131042\n",
      "iter  40 value 52.059780\n",
      "iter  50 value 51.849908\n",
      "iter  60 value 51.808637\n",
      "iter  70 value 51.807704\n",
      "final  value 51.807658 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.177545\n",
      "iter  20 value 47.733201\n",
      "iter  30 value 26.234771\n",
      "iter  40 value 7.604649\n",
      "iter  50 value 3.297822\n",
      "iter  60 value 2.849266\n",
      "iter  70 value 2.556727\n",
      "iter  80 value 2.298912\n",
      "iter  90 value 2.136790\n",
      "iter 100 value 2.018018\n",
      "final  value 2.018018 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 69.623053\n",
      "iter  20 value 37.489319\n",
      "iter  30 value 19.763400\n",
      "iter  40 value 4.658520\n",
      "iter  50 value 0.025783\n",
      "final  value 0.000097 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.284308\n",
      "iter  20 value 51.558138\n",
      "iter  30 value 48.607077\n",
      "iter  40 value 47.764177\n",
      "iter  50 value 47.484996\n",
      "iter  60 value 47.444806\n",
      "iter  70 value 47.438511\n",
      "iter  80 value 47.438433\n",
      "final  value 47.438432 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 69.626996\n",
      "iter  20 value 37.510565\n",
      "iter  30 value 19.876452\n",
      "iter  40 value 5.300577\n",
      "iter  50 value 2.140386\n",
      "iter  60 value 1.908794\n",
      "iter  70 value 1.741734\n",
      "iter  80 value 1.579501\n",
      "iter  90 value 1.434038\n",
      "iter 100 value 1.333727\n",
      "final  value 1.333727 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 210.933559 \n",
      "iter  10 value 124.629971\n",
      "iter  20 value 88.109505\n",
      "iter  30 value 73.161550\n",
      "iter  40 value 62.858607\n",
      "iter  50 value 56.625441\n",
      "iter  60 value 52.559571\n",
      "iter  70 value 49.796097\n",
      "iter  80 value 46.984574\n",
      "iter  90 value 46.357481\n",
      "iter 100 value 46.181488\n",
      "final  value 46.181488 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 30 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 82.398248\n",
      "iter  20 value 50.784786\n",
      "iter  30 value 40.242954\n",
      "iter  40 value 34.972799\n",
      "iter  50 value 33.817951\n",
      "iter  60 value 33.088953\n",
      "iter  70 value 32.719264\n",
      "iter  80 value 32.599807\n",
      "iter  90 value 32.594384\n",
      "final  value 32.594364 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 83.847526\n",
      "iter  20 value 60.562987\n",
      "iter  30 value 57.981480\n",
      "iter  40 value 57.511085\n",
      "iter  50 value 57.428264\n",
      "iter  60 value 57.419125\n",
      "iter  70 value 57.418841\n",
      "final  value 57.418831 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 82.399766\n",
      "iter  20 value 50.798579\n",
      "iter  30 value 40.302055\n",
      "iter  40 value 35.104605\n",
      "iter  50 value 33.980817\n",
      "iter  60 value 33.306454\n",
      "iter  70 value 33.044744\n",
      "iter  80 value 33.009007\n",
      "iter  90 value 32.994516\n",
      "iter 100 value 32.984623\n",
      "final  value 32.984623 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 74.157140\n",
      "iter  20 value 42.255133\n",
      "iter  30 value 22.948539\n",
      "iter  40 value 4.772320\n",
      "iter  50 value 0.042415\n",
      "iter  60 value 0.000619\n",
      "final  value 0.000066 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 76.230488\n",
      "iter  20 value 54.097531\n",
      "iter  30 value 50.725766\n",
      "iter  40 value 49.612464\n",
      "iter  50 value 49.338742\n",
      "iter  60 value 49.283176\n",
      "iter  70 value 49.275863\n",
      "iter  80 value 49.275686\n",
      "final  value 49.275685 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 74.159344\n",
      "iter  20 value 42.274298\n",
      "iter  30 value 23.101747\n",
      "iter  40 value 5.332447\n",
      "iter  50 value 1.818576\n",
      "iter  60 value 1.704038\n",
      "iter  70 value 1.583989\n",
      "iter  80 value 1.501030\n",
      "iter  90 value 1.440177\n",
      "iter 100 value 1.408994\n",
      "final  value 1.408994 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 139.523761 \n",
      "iter  10 value 76.658277\n",
      "iter  20 value 40.819107\n",
      "iter  30 value 21.381858\n",
      "iter  40 value 9.042301\n",
      "iter  50 value 0.086500\n",
      "iter  60 value 0.000722\n",
      "final  value 0.000090 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 139.523761 \n",
      "iter  10 value 79.181174\n",
      "iter  20 value 52.690250\n",
      "iter  30 value 49.399848\n",
      "iter  40 value 48.617299\n",
      "iter  50 value 48.463173\n",
      "iter  60 value 48.446627\n",
      "iter  70 value 48.445485\n",
      "final  value 48.445472 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 139.523761 \n",
      "iter  10 value 76.660983\n",
      "iter  20 value 40.836319\n",
      "iter  30 value 21.525314\n",
      "iter  40 value 9.563341\n",
      "iter  50 value 2.727902\n",
      "iter  60 value 2.406026\n",
      "iter  70 value 2.187537\n",
      "iter  80 value 2.057345\n",
      "iter  90 value 1.965385\n",
      "iter 100 value 1.851874\n",
      "final  value 1.851874 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 210.933559 \n",
      "iter  10 value 133.768641\n",
      "iter  20 value 98.946538\n",
      "iter  30 value 84.990507\n",
      "iter  40 value 76.969582\n",
      "iter  50 value 72.698813\n",
      "iter  60 value 67.195308\n",
      "iter  70 value 61.548414\n",
      "iter  80 value 56.289294\n",
      "iter  90 value 55.805705\n",
      "iter 100 value 55.781581\n",
      "final  value 55.781581 \n",
      "stopped after 100 iterations\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.835910\n",
      "iter  20 value 39.575710\n",
      "iter  30 value 26.639230\n",
      "iter  40 value 17.129053\n",
      "iter  50 value 4.551060\n",
      "iter  60 value 0.038341\n",
      "iter  70 value 0.000473\n",
      "final  value 0.000092 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 81.302098\n",
      "iter  20 value 52.617546\n",
      "iter  30 value 49.672885\n",
      "iter  40 value 49.163900\n",
      "iter  50 value 49.095128\n",
      "iter  60 value 49.089560\n",
      "iter  70 value 49.089490\n",
      "final  value 49.089489 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.839674\n",
      "iter  20 value 39.594846\n",
      "iter  30 value 26.717169\n",
      "iter  40 value 17.389710\n",
      "iter  50 value 9.123293\n",
      "iter  60 value 5.565545\n",
      "iter  70 value 5.123381\n",
      "iter  80 value 4.751844\n",
      "iter  90 value 4.315518\n",
      "iter 100 value 4.041916\n",
      "final  value 4.041916 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 86.797169\n",
      "iter  20 value 56.078204\n",
      "iter  30 value 42.048119\n",
      "iter  40 value 27.678279\n",
      "iter  50 value 19.847914\n",
      "iter  60 value 8.817837\n",
      "iter  70 value 0.019107\n",
      "final  value 0.000059 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 88.558610\n",
      "iter  20 value 66.590834\n",
      "iter  30 value 64.185370\n",
      "iter  40 value 63.868061\n",
      "iter  50 value 63.814281\n",
      "iter  60 value 63.801942\n",
      "iter  70 value 63.801224\n",
      "final  value 63.801217 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 86.799021\n",
      "iter  20 value 56.092915\n",
      "iter  30 value 42.147171\n",
      "iter  40 value 28.085696\n",
      "iter  50 value 21.351330\n",
      "iter  60 value 18.021733\n",
      "iter  70 value 16.279450\n",
      "iter  80 value 15.170612\n",
      "iter  90 value 14.182853\n",
      "iter 100 value 13.289765\n",
      "final  value 13.289765 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 65.143957\n",
      "iter  20 value 33.827890\n",
      "iter  30 value 19.814023\n",
      "iter  40 value 4.329581\n",
      "iter  50 value 0.017237\n",
      "final  value 0.000095 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.021052\n",
      "iter  20 value 45.481177\n",
      "iter  30 value 42.645655\n",
      "iter  40 value 41.958324\n",
      "iter  50 value 41.682851\n",
      "iter  60 value 41.642156\n",
      "iter  70 value 41.640813\n",
      "final  value 41.640795 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 65.149233\n",
      "iter  20 value 33.844537\n",
      "iter  30 value 19.927099\n",
      "iter  40 value 4.793598\n",
      "iter  50 value 1.429055\n",
      "iter  60 value 1.257812\n",
      "iter  70 value 1.148940\n",
      "iter  80 value 1.106105\n",
      "iter  90 value 1.069317\n",
      "iter 100 value 1.030247\n",
      "final  value 1.030247 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 138.517441\n",
      "iter  20 value 94.769481\n",
      "iter  30 value 81.506292\n",
      "iter  40 value 71.398499\n",
      "iter  50 value 66.044841\n",
      "iter  60 value 58.987674\n",
      "iter  70 value 54.449937\n",
      "iter  80 value 51.793515\n",
      "iter  90 value 51.453820\n",
      "iter 100 value 51.440366\n",
      "final  value 51.440366 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 72.672717\n",
      "iter  20 value 40.394333\n",
      "iter  30 value 26.154897\n",
      "iter  40 value 5.042734\n",
      "iter  50 value 0.026559\n",
      "final  value 0.000092 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.724329\n",
      "iter  20 value 53.240574\n",
      "iter  30 value 49.533887\n",
      "iter  40 value 48.478704\n",
      "iter  50 value 48.232586\n",
      "iter  60 value 48.206954\n",
      "iter  70 value 48.205015\n",
      "final  value 48.204996 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 72.676681\n",
      "iter  20 value 40.410739\n",
      "iter  30 value 26.261732\n",
      "iter  40 value 6.188624\n",
      "iter  50 value 2.053225\n",
      "iter  60 value 1.843635\n",
      "iter  70 value 1.730728\n",
      "iter  80 value 1.644066\n",
      "iter  90 value 1.569234\n",
      "iter 100 value 1.533267\n",
      "final  value 1.533267 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 74.434189\n",
      "iter  20 value 39.519408\n",
      "iter  30 value 18.874978\n",
      "iter  40 value 2.732334\n",
      "iter  50 value 0.007181\n",
      "final  value 0.000080 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 76.998294\n",
      "iter  20 value 50.839155\n",
      "iter  30 value 45.553826\n",
      "iter  40 value 44.053203\n",
      "iter  50 value 43.599857\n",
      "iter  60 value 43.514059\n",
      "iter  70 value 43.505911\n",
      "iter  80 value 43.505393\n",
      "final  value 43.505390 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 74.436936\n",
      "iter  20 value 39.535653\n",
      "iter  30 value 18.992142\n",
      "iter  40 value 3.366548\n",
      "iter  50 value 1.394630\n",
      "iter  60 value 1.263067\n",
      "iter  70 value 1.154090\n",
      "iter  80 value 1.056398\n",
      "iter  90 value 0.996340\n",
      "iter 100 value 0.951573\n",
      "final  value 0.951573 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 75.991972\n",
      "iter  20 value 39.307636\n",
      "iter  30 value 21.712651\n",
      "iter  40 value 1.140791\n",
      "iter  50 value 0.005936\n",
      "final  value 0.000053 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 75.983031\n",
      "iter  20 value 53.020882\n",
      "iter  30 value 50.830973\n",
      "iter  40 value 50.365113\n",
      "iter  50 value 50.265838\n",
      "iter  60 value 50.249504\n",
      "iter  70 value 50.247920\n",
      "final  value 50.247906 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 75.996751\n",
      "iter  20 value 39.327795\n",
      "iter  30 value 21.844028\n",
      "iter  40 value 2.777634\n",
      "iter  50 value 1.708810\n",
      "iter  60 value 1.604183\n",
      "iter  70 value 1.517955\n",
      "iter  80 value 1.461453\n",
      "iter  90 value 1.425474\n",
      "iter 100 value 1.407400\n",
      "final  value 1.407400 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 130.148866\n",
      "iter  20 value 83.600470\n",
      "iter  30 value 69.352287\n",
      "iter  40 value 57.877254\n",
      "iter  50 value 52.150278\n",
      "iter  60 value 48.093483\n",
      "iter  70 value 44.311778\n",
      "iter  80 value 42.866397\n",
      "iter  90 value 40.453473\n",
      "iter 100 value 37.635376\n",
      "final  value 37.635376 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 83.006640\n",
      "iter  20 value 45.378561\n",
      "iter  30 value 26.635710\n",
      "iter  40 value 4.945834\n",
      "iter  50 value 0.033069\n",
      "final  value 0.000078 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 83.747365\n",
      "iter  20 value 58.826418\n",
      "iter  30 value 54.634435\n",
      "iter  40 value 53.901721\n",
      "iter  50 value 53.653367\n",
      "iter  60 value 53.630657\n",
      "iter  70 value 53.628884\n",
      "final  value 53.628872 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 83.009588\n",
      "iter  20 value 45.397734\n",
      "iter  30 value 26.749779\n",
      "iter  40 value 5.739976\n",
      "iter  50 value 2.410585\n",
      "iter  60 value 2.173567\n",
      "iter  70 value 2.030511\n",
      "iter  80 value 1.935083\n",
      "iter  90 value 1.881244\n",
      "iter 100 value 1.834505\n",
      "final  value 1.834505 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 71.197834\n",
      "iter  20 value 41.068828\n",
      "iter  30 value 22.158740\n",
      "iter  40 value 5.722818\n",
      "iter  50 value 0.032101\n",
      "final  value 0.000098 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 74.179371\n",
      "iter  20 value 52.248637\n",
      "iter  30 value 48.354765\n",
      "iter  40 value 47.379858\n",
      "iter  50 value 47.171068\n",
      "iter  60 value 47.141442\n",
      "iter  70 value 47.140501\n",
      "final  value 47.140469 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 71.201031\n",
      "iter  20 value 41.091039\n",
      "iter  30 value 22.293813\n",
      "iter  40 value 6.203587\n",
      "iter  50 value 1.867382\n",
      "iter  60 value 1.750707\n",
      "iter  70 value 1.647314\n",
      "iter  80 value 1.564053\n",
      "iter  90 value 1.479530\n",
      "iter 100 value 1.422375\n",
      "final  value 1.422375 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.988673\n",
      "iter  20 value 48.842797\n",
      "iter  30 value 37.933271\n",
      "iter  40 value 19.148352\n",
      "iter  50 value 4.239002\n",
      "iter  60 value 0.027165\n",
      "final  value 0.000077 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 81.018826\n",
      "iter  20 value 59.280426\n",
      "iter  30 value 56.644271\n",
      "iter  40 value 56.073306\n",
      "iter  50 value 55.957200\n",
      "iter  60 value 55.941910\n",
      "iter  70 value 55.940891\n",
      "final  value 55.940869 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.990832\n",
      "iter  20 value 48.857485\n",
      "iter  30 value 38.035038\n",
      "iter  40 value 19.580391\n",
      "iter  50 value 10.046852\n",
      "iter  60 value 7.493983\n",
      "iter  70 value 6.610611\n",
      "iter  80 value 5.943530\n",
      "iter  90 value 5.340412\n",
      "iter 100 value 4.992786\n",
      "final  value 4.992786 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 129.141944\n",
      "iter  20 value 93.956284\n",
      "iter  30 value 80.378824\n",
      "iter  40 value 72.063365\n",
      "iter  50 value 68.805079\n",
      "iter  60 value 67.208518\n",
      "iter  70 value 65.755061\n",
      "iter  80 value 63.857020\n",
      "iter  90 value 61.818721\n",
      "iter 100 value 55.563722\n",
      "final  value 55.563722 \n",
      "stopped after 100 iterations\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  92 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 24 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 61 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.000270\n",
      "iter  20 value 42.909756\n",
      "iter  30 value 26.912124\n",
      "iter  40 value 8.845982\n",
      "iter  50 value 0.122650\n",
      "iter  60 value 0.000308\n",
      "final  value 0.000098 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.711811\n",
      "iter  20 value 53.602654\n",
      "iter  30 value 50.532090\n",
      "iter  40 value 49.734119\n",
      "iter  50 value 49.557700\n",
      "iter  60 value 49.549774\n",
      "iter  70 value 49.549527\n",
      "final  value 49.549521 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.003174\n",
      "iter  20 value 42.925037\n",
      "iter  30 value 26.991136\n",
      "iter  40 value 9.476709\n",
      "iter  50 value 3.277247\n",
      "iter  60 value 2.895792\n",
      "iter  70 value 2.597262\n",
      "iter  80 value 2.368586\n",
      "iter  90 value 2.208098\n",
      "iter 100 value 2.106155\n",
      "final  value 2.106155 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 70.265083\n",
      "iter  20 value 43.548583\n",
      "iter  30 value 29.434703\n",
      "iter  40 value 8.317283\n",
      "iter  50 value 0.064540\n",
      "iter  60 value 0.000232\n",
      "final  value 0.000063 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.633608\n",
      "iter  20 value 53.545473\n",
      "iter  30 value 50.182601\n",
      "iter  40 value 49.426555\n",
      "iter  50 value 49.231521\n",
      "iter  60 value 49.215798\n",
      "iter  70 value 49.215187\n",
      "final  value 49.215171 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 70.268702\n",
      "iter  20 value 43.562402\n",
      "iter  30 value 29.533787\n",
      "iter  40 value 8.810087\n",
      "iter  50 value 2.232528\n",
      "iter  60 value 2.055750\n",
      "iter  70 value 1.960610\n",
      "iter  80 value 1.880032\n",
      "iter  90 value 1.817197\n",
      "iter 100 value 1.777345\n",
      "final  value 1.777345 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 65.062596\n",
      "iter  20 value 37.320465\n",
      "iter  30 value 17.941518\n",
      "iter  40 value 4.287165\n",
      "iter  50 value 0.017028\n",
      "iter  60 value 0.000145\n",
      "iter  60 value 0.000073\n",
      "iter  60 value 0.000071\n",
      "final  value 0.000071 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 69.594183\n",
      "iter  20 value 48.751766\n",
      "iter  30 value 45.856219\n",
      "iter  40 value 45.132234\n",
      "iter  50 value 44.955256\n",
      "iter  60 value 44.941216\n",
      "iter  70 value 44.940346\n",
      "final  value 44.940333 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 65.067521\n",
      "iter  20 value 37.336676\n",
      "iter  30 value 18.086205\n",
      "iter  40 value 4.804212\n",
      "iter  50 value 1.822592\n",
      "iter  60 value 1.686810\n",
      "iter  70 value 1.576399\n",
      "iter  80 value 1.506858\n",
      "iter  90 value 1.427169\n",
      "iter 100 value 1.388563\n",
      "final  value 1.388563 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 210.933559 \n",
      "iter  10 value 125.811436\n",
      "iter  20 value 92.601107\n",
      "iter  30 value 83.051848\n",
      "iter  40 value 75.264618\n",
      "iter  50 value 71.575395\n",
      "iter  60 value 68.333903\n",
      "iter  70 value 64.392338\n",
      "iter  80 value 58.496806\n",
      "iter  90 value 49.677102\n",
      "iter 100 value 45.401979\n",
      "final  value 45.401979 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 61 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 59.433860\n",
      "iter  20 value 28.368678\n",
      "iter  30 value 13.409257\n",
      "iter  40 value 0.852192\n",
      "iter  50 value 0.003593\n",
      "final  value 0.000065 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 64.072403\n",
      "iter  20 value 41.030287\n",
      "iter  30 value 38.234381\n",
      "iter  40 value 37.204394\n",
      "iter  50 value 37.094638\n",
      "iter  60 value 37.087000\n",
      "iter  70 value 37.086822\n",
      "final  value 37.086812 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 59.438930\n",
      "iter  20 value 28.386906\n",
      "iter  30 value 13.514479\n",
      "iter  40 value 1.593698\n",
      "iter  50 value 1.022307\n",
      "iter  60 value 0.971031\n",
      "iter  70 value 0.915733\n",
      "iter  80 value 0.866214\n",
      "iter  90 value 0.808950\n",
      "iter 100 value 0.766596\n",
      "final  value 0.766596 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 64.140462\n",
      "iter  20 value 39.103023\n",
      "iter  30 value 23.756008\n",
      "iter  40 value 6.001017\n",
      "iter  50 value 0.048911\n",
      "iter  60 value 0.001139\n",
      "final  value 0.000075 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 67.052571\n",
      "iter  20 value 48.563884\n",
      "iter  30 value 45.123294\n",
      "iter  40 value 43.932403\n",
      "iter  50 value 43.610946\n",
      "iter  60 value 43.585462\n",
      "iter  70 value 43.585016\n",
      "final  value 43.585002 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 64.143607\n",
      "iter  20 value 39.121371\n",
      "iter  30 value 23.844357\n",
      "iter  40 value 7.455907\n",
      "iter  50 value 1.489713\n",
      "iter  60 value 1.336449\n",
      "iter  70 value 1.284154\n",
      "iter  80 value 1.229304\n",
      "iter  90 value 1.174296\n",
      "iter 100 value 1.125914\n",
      "final  value 1.125914 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 62.409638\n",
      "iter  20 value 35.232885\n",
      "iter  30 value 15.782018\n",
      "iter  40 value 1.275602\n",
      "iter  50 value 0.004992\n",
      "final  value 0.000064 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 66.045914\n",
      "iter  20 value 46.727434\n",
      "iter  30 value 43.356812\n",
      "iter  40 value 42.485647\n",
      "iter  50 value 42.191428\n",
      "iter  60 value 42.159133\n",
      "iter  70 value 42.157353\n",
      "final  value 42.157334 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 62.413570\n",
      "iter  20 value 35.249531\n",
      "iter  30 value 15.972343\n",
      "iter  40 value 2.402442\n",
      "iter  50 value 1.434966\n",
      "iter  60 value 1.285616\n",
      "iter  70 value 1.178410\n",
      "iter  80 value 1.109029\n",
      "iter  90 value 1.019536\n",
      "iter 100 value 0.977741\n",
      "final  value 0.977741 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 210.933559 \n",
      "iter  10 value 126.906738\n",
      "iter  20 value 84.838994\n",
      "iter  30 value 74.981116\n",
      "iter  40 value 65.758091\n",
      "iter  50 value 58.267627\n",
      "iter  60 value 53.227387\n",
      "iter  70 value 49.865705\n",
      "iter  80 value 47.045063\n",
      "iter  90 value 43.765516\n",
      "iter 100 value 43.430100\n",
      "final  value 43.430100 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 61 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.297919\n",
      "iter  20 value 39.850366\n",
      "iter  30 value 18.415799\n",
      "iter  40 value 0.417505\n",
      "iter  50 value 0.001297\n",
      "final  value 0.000058 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 72.690597\n",
      "iter  20 value 49.829366\n",
      "iter  30 value 44.877343\n",
      "iter  40 value 42.934090\n",
      "iter  50 value 42.672291\n",
      "iter  60 value 42.636387\n",
      "iter  70 value 42.635417\n",
      "iter  80 value 42.635358\n",
      "iter  80 value 42.635358\n",
      "iter  80 value 42.635358\n",
      "final  value 42.635358 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.300473\n",
      "iter  20 value 39.864111\n",
      "iter  30 value 18.520818\n",
      "iter  40 value 1.412878\n",
      "iter  50 value 1.219242\n",
      "iter  60 value 1.144955\n",
      "iter  70 value 1.075059\n",
      "iter  80 value 1.017148\n",
      "iter  90 value 0.981881\n",
      "iter 100 value 0.946572\n",
      "final  value 0.946572 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 76.258399\n",
      "iter  20 value 43.834459\n",
      "iter  30 value 27.425752\n",
      "iter  40 value 10.571828\n",
      "iter  50 value 0.286128\n",
      "iter  60 value 0.001075\n",
      "final  value 0.000059 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.714979\n",
      "iter  20 value 53.783230\n",
      "iter  30 value 49.576147\n",
      "iter  40 value 48.357089\n",
      "iter  50 value 48.048390\n",
      "iter  60 value 48.021556\n",
      "iter  70 value 48.020562\n",
      "final  value 48.020508 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 76.261020\n",
      "iter  20 value 43.848137\n",
      "iter  30 value 27.498970\n",
      "iter  40 value 10.335110\n",
      "iter  50 value 3.200308\n",
      "iter  60 value 2.861886\n",
      "iter  70 value 2.616264\n",
      "iter  80 value 2.395247\n",
      "iter  90 value 2.176514\n",
      "iter 100 value 2.041304\n",
      "final  value 2.041304 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 76.427837\n",
      "iter  20 value 49.104450\n",
      "iter  30 value 28.388856\n",
      "iter  40 value 8.900682\n",
      "iter  50 value 0.239449\n",
      "iter  60 value 0.002985\n",
      "final  value 0.000070 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 79.432160\n",
      "iter  20 value 61.762944\n",
      "iter  30 value 58.738752\n",
      "iter  40 value 58.253404\n",
      "iter  50 value 58.186990\n",
      "iter  60 value 58.172734\n",
      "iter  70 value 58.172109\n",
      "final  value 58.172107 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 76.431095\n",
      "iter  20 value 49.124020\n",
      "iter  30 value 28.522213\n",
      "iter  40 value 9.733605\n",
      "iter  50 value 3.480922\n",
      "iter  60 value 2.985335\n",
      "iter  70 value 2.763462\n",
      "iter  80 value 2.615157\n",
      "iter  90 value 2.528429\n",
      "iter 100 value 2.475506\n",
      "final  value 2.475506 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 141.513944\n",
      "iter  20 value 102.306296\n",
      "iter  30 value 91.534258\n",
      "iter  40 value 84.632078\n",
      "iter  50 value 81.785558\n",
      "iter  60 value 80.288977\n",
      "iter  70 value 78.734299\n",
      "iter  80 value 77.271715\n",
      "iter  90 value 76.711841\n",
      "iter 100 value 76.457024\n",
      "final  value 76.457024 \n",
      "stopped after 100 iterations\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.836295\n",
      "iter  20 value 48.632568\n",
      "iter  30 value 39.541746\n",
      "iter  40 value 16.984082\n",
      "iter  50 value 0.824071\n",
      "iter  60 value 0.001481\n",
      "final  value 0.000053 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 82.380834\n",
      "iter  20 value 59.818100\n",
      "iter  30 value 58.409011\n",
      "iter  40 value 58.247729\n",
      "iter  50 value 58.226042\n",
      "iter  60 value 58.222282\n",
      "iter  70 value 58.222228\n",
      "final  value 58.222225 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.840083\n",
      "iter  20 value 48.648492\n",
      "iter  30 value 39.605690\n",
      "iter  40 value 17.611459\n",
      "iter  50 value 5.227906\n",
      "iter  60 value 4.459096\n",
      "iter  70 value 3.990092\n",
      "iter  80 value 3.735505\n",
      "iter  90 value 3.624150\n",
      "iter 100 value 3.559500\n",
      "final  value 3.559500 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 73.138916\n",
      "iter  20 value 46.655241\n",
      "iter  30 value 36.005199\n",
      "iter  40 value 24.215006\n",
      "iter  50 value 9.490394\n",
      "iter  60 value 0.148919\n",
      "iter  70 value 0.000210\n",
      "final  value 0.000056 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 75.763122\n",
      "iter  20 value 56.633873\n",
      "iter  30 value 54.509122\n",
      "iter  40 value 54.190518\n",
      "iter  50 value 54.148295\n",
      "iter  60 value 54.143914\n",
      "iter  70 value 54.143730\n",
      "final  value 54.143726 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 73.141723\n",
      "iter  20 value 46.669610\n",
      "iter  30 value 36.072998\n",
      "iter  40 value 24.520088\n",
      "iter  50 value 13.256947\n",
      "iter  60 value 9.256633\n",
      "iter  70 value 8.089155\n",
      "iter  80 value 7.317181\n",
      "iter  90 value 6.982830\n",
      "iter 100 value 6.612394\n",
      "final  value 6.612394 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.941272\n",
      "iter  20 value 46.709440\n",
      "iter  30 value 37.652497\n",
      "iter  40 value 27.054531\n",
      "iter  50 value 12.372993\n",
      "iter  60 value 0.109162\n",
      "iter  70 value 0.000164\n",
      "iter  70 value 0.000084\n",
      "iter  70 value 0.000083\n",
      "final  value 0.000083 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 79.999657\n",
      "iter  20 value 55.800727\n",
      "iter  30 value 52.461176\n",
      "iter  40 value 51.664500\n",
      "iter  50 value 51.516228\n",
      "iter  60 value 51.493264\n",
      "iter  70 value 51.492587\n",
      "final  value 51.492556 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.945687\n",
      "iter  20 value 46.722403\n",
      "iter  30 value 37.687605\n",
      "iter  40 value 27.204479\n",
      "iter  50 value 13.363703\n",
      "iter  60 value 5.406822\n",
      "iter  70 value 4.567416\n",
      "iter  80 value 4.196627\n",
      "iter  90 value 3.983870\n",
      "iter 100 value 3.818750\n",
      "final  value 3.818750 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 131.563389\n",
      "iter  20 value 100.471408\n",
      "iter  30 value 90.863225\n",
      "iter  40 value 83.755464\n",
      "iter  50 value 80.367251\n",
      "iter  60 value 77.498867\n",
      "iter  70 value 73.519238\n",
      "iter  80 value 67.914070\n",
      "iter  90 value 55.874111\n",
      "iter 100 value 53.011756\n",
      "final  value 53.011756 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 54.455993\n",
      "iter  20 value 29.469852\n",
      "iter  30 value 5.889393\n",
      "iter  40 value 0.051784\n",
      "iter  50 value 0.000944\n",
      "final  value 0.000081 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 57.741488\n",
      "iter  20 value 41.494803\n",
      "iter  30 value 37.799406\n",
      "iter  40 value 36.136342\n",
      "iter  50 value 35.897854\n",
      "iter  60 value 35.862466\n",
      "iter  70 value 35.858634\n",
      "iter  80 value 35.858501\n",
      "final  value 35.858499 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 54.459503\n",
      "iter  20 value 29.487874\n",
      "iter  30 value 6.066972\n",
      "iter  40 value 0.958533\n",
      "iter  50 value 0.870172\n",
      "iter  60 value 0.820985\n",
      "iter  70 value 0.789662\n",
      "iter  80 value 0.768408\n",
      "iter  90 value 0.739913\n",
      "iter 100 value 0.715505\n",
      "final  value 0.715505 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 63.237864\n",
      "iter  20 value 32.444755\n",
      "iter  30 value 12.904926\n",
      "iter  40 value 0.663069\n",
      "iter  50 value 0.001146\n",
      "final  value 0.000078 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 65.976559\n",
      "iter  20 value 42.525692\n",
      "iter  30 value 37.739508\n",
      "iter  40 value 36.610092\n",
      "iter  50 value 36.234713\n",
      "iter  60 value 36.137462\n",
      "iter  70 value 36.129132\n",
      "iter  80 value 36.128945\n",
      "final  value 36.128943 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 63.240771\n",
      "iter  20 value 32.462310\n",
      "iter  30 value 13.006385\n",
      "iter  40 value 1.165401\n",
      "iter  50 value 0.811894\n",
      "iter  60 value 0.771879\n",
      "iter  70 value 0.739935\n",
      "iter  80 value 0.706804\n",
      "iter  90 value 0.676191\n",
      "iter 100 value 0.654906\n",
      "final  value 0.654906 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.121715\n",
      "iter  20 value 45.721332\n",
      "iter  30 value 33.635632\n",
      "iter  40 value 18.984127\n",
      "iter  50 value 3.802698\n",
      "iter  60 value 0.030684\n",
      "iter  70 value 0.000165\n",
      "iter  70 value 0.000083\n",
      "iter  70 value 0.000082\n",
      "final  value 0.000082 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 82.055907\n",
      "iter  20 value 59.053464\n",
      "iter  30 value 55.442699\n",
      "iter  40 value 54.812746\n",
      "iter  50 value 54.686881\n",
      "iter  60 value 54.670886\n",
      "iter  70 value 54.669069\n",
      "final  value 54.669039 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.126031\n",
      "iter  20 value 45.741414\n",
      "iter  30 value 33.714347\n",
      "iter  40 value 19.255250\n",
      "iter  50 value 7.423829\n",
      "iter  60 value 4.847049\n",
      "iter  70 value 4.498816\n",
      "iter  80 value 4.256000\n",
      "iter  90 value 3.948772\n",
      "iter 100 value 3.665986\n",
      "final  value 3.665986 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 136.115303\n",
      "iter  20 value 100.950211\n",
      "iter  30 value 97.364039\n",
      "iter  40 value 96.786711\n",
      "iter  50 value 96.721124\n",
      "iter  60 value 96.718640\n",
      "iter  70 value 96.718377\n",
      "iter  80 value 96.718346\n",
      "final  value 96.718323 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 66.157605\n",
      "iter  20 value 36.770550\n",
      "iter  30 value 23.680869\n",
      "iter  40 value 11.893884\n",
      "iter  50 value 0.124331\n",
      "iter  60 value 0.000348\n",
      "final  value 0.000053 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 69.292955\n",
      "iter  20 value 47.847085\n",
      "iter  30 value 45.037753\n",
      "iter  40 value 44.335498\n",
      "iter  50 value 44.171203\n",
      "iter  60 value 44.162837\n",
      "iter  70 value 44.162652\n",
      "final  value 44.162640 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 66.160973\n",
      "iter  20 value 36.785956\n",
      "iter  30 value 23.773428\n",
      "iter  40 value 12.184085\n",
      "iter  50 value 2.432462\n",
      "iter  60 value 2.135511\n",
      "iter  70 value 2.002097\n",
      "iter  80 value 1.893124\n",
      "iter  90 value 1.771529\n",
      "iter 100 value 1.649219\n",
      "final  value 1.649219 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 53.957528\n",
      "iter  20 value 23.780357\n",
      "iter  30 value 5.316586\n",
      "iter  40 value 0.099655\n",
      "iter  50 value 0.000343\n",
      "final  value 0.000095 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 58.854538\n",
      "iter  20 value 37.396208\n",
      "iter  30 value 34.338543\n",
      "iter  40 value 33.302777\n",
      "iter  50 value 33.131006\n",
      "iter  60 value 33.118733\n",
      "iter  70 value 33.117683\n",
      "final  value 33.117591 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 53.962859\n",
      "iter  20 value 23.800956\n",
      "iter  30 value 5.438610\n",
      "iter  40 value 0.658836\n",
      "iter  50 value 0.616263\n",
      "iter  60 value 0.589431\n",
      "iter  70 value 0.561480\n",
      "iter  80 value 0.546846\n",
      "iter  90 value 0.534920\n",
      "iter 100 value 0.524121\n",
      "final  value 0.524121 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 58.731655\n",
      "iter  20 value 30.573613\n",
      "iter  30 value 11.935784\n",
      "iter  40 value 0.346510\n",
      "iter  50 value 0.009151\n",
      "iter  60 value 0.000806\n",
      "iter  70 value 0.000340\n",
      "final  value 0.000063 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 65.278850\n",
      "iter  20 value 44.876501\n",
      "iter  30 value 41.174226\n",
      "iter  40 value 39.793897\n",
      "iter  50 value 39.408690\n",
      "iter  60 value 39.326271\n",
      "iter  70 value 39.311292\n",
      "iter  80 value 39.311006\n",
      "final  value 39.311005 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 58.736737\n",
      "iter  20 value 30.592692\n",
      "iter  30 value 12.078096\n",
      "iter  40 value 1.609531\n",
      "iter  50 value 1.159518\n",
      "iter  60 value 1.095131\n",
      "iter  70 value 1.024941\n",
      "iter  80 value 0.963268\n",
      "iter  90 value 0.891570\n",
      "iter 100 value 0.843768\n",
      "final  value 0.843768 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 118.473427\n",
      "iter  20 value 78.004766\n",
      "iter  30 value 67.096896\n",
      "iter  40 value 57.676826\n",
      "iter  50 value 50.867674\n",
      "iter  60 value 45.948398\n",
      "iter  70 value 40.546649\n",
      "iter  80 value 37.718223\n",
      "iter  90 value 35.991930\n",
      "iter 100 value 33.798720\n",
      "final  value 33.798720 \n",
      "stopped after 100 iterations\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.943152\n",
      "iter  20 value 34.656220\n",
      "iter  30 value 16.124288\n",
      "iter  40 value 0.903173\n",
      "iter  50 value 0.003164\n",
      "final  value 0.000071 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 73.432755\n",
      "iter  20 value 46.913852\n",
      "iter  30 value 42.767146\n",
      "iter  40 value 40.542296\n",
      "iter  50 value 40.139489\n",
      "iter  60 value 40.088397\n",
      "iter  70 value 40.085157\n",
      "final  value 40.085050 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.945782\n",
      "iter  20 value 34.674329\n",
      "iter  30 value 16.323544\n",
      "iter  40 value 1.666225\n",
      "iter  50 value 1.124125\n",
      "iter  60 value 1.032340\n",
      "iter  70 value 0.932137\n",
      "iter  80 value 0.864782\n",
      "iter  90 value 0.813603\n",
      "iter 100 value 0.770323\n",
      "final  value 0.770323 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.151463\n",
      "iter  20 value 43.542368\n",
      "iter  30 value 27.640735\n",
      "iter  40 value 9.116235\n",
      "iter  50 value 0.073834\n",
      "iter  60 value 0.001371\n",
      "final  value 0.000093 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 79.370179\n",
      "iter  20 value 54.209397\n",
      "iter  30 value 51.553103\n",
      "iter  40 value 50.943428\n",
      "iter  50 value 50.868286\n",
      "iter  60 value 50.862462\n",
      "iter  70 value 50.862195\n",
      "final  value 50.862192 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.153827\n",
      "iter  20 value 43.557400\n",
      "iter  30 value 27.744969\n",
      "iter  40 value 9.842717\n",
      "iter  50 value 3.129349\n",
      "iter  60 value 2.774201\n",
      "iter  70 value 2.587909\n",
      "iter  80 value 2.455065\n",
      "iter  90 value 2.355632\n",
      "iter 100 value 2.267131\n",
      "final  value 2.267131 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.340128\n",
      "iter  20 value 50.122504\n",
      "iter  30 value 35.415428\n",
      "iter  40 value 14.960898\n",
      "iter  50 value 0.478636\n",
      "iter  60 value 0.001304\n",
      "final  value 0.000097 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 80.850256\n",
      "iter  20 value 60.635924\n",
      "iter  30 value 57.472680\n",
      "iter  40 value 56.851505\n",
      "iter  50 value 56.680125\n",
      "iter  60 value 56.664351\n",
      "iter  70 value 56.663476\n",
      "final  value 56.663455 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.342785\n",
      "iter  20 value 50.137148\n",
      "iter  30 value 35.496017\n",
      "iter  40 value 15.473638\n",
      "iter  50 value 3.909070\n",
      "iter  60 value 3.440736\n",
      "iter  70 value 3.196046\n",
      "iter  80 value 3.010999\n",
      "iter  90 value 2.869021\n",
      "iter 100 value 2.791277\n",
      "final  value 2.791277 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 135.709522\n",
      "iter  20 value 100.868229\n",
      "iter  30 value 91.130684\n",
      "iter  40 value 84.478389\n",
      "iter  50 value 81.308374\n",
      "iter  60 value 79.487511\n",
      "iter  70 value 77.667013\n",
      "iter  80 value 75.584605\n",
      "iter  90 value 74.536508\n",
      "iter 100 value 74.101818\n",
      "final  value 74.101818 \n",
      "stopped after 100 iterations\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.579022\n",
      "iter  20 value 49.399032\n",
      "iter  30 value 34.465255\n",
      "iter  40 value 21.208978\n",
      "iter  50 value 8.464309\n",
      "iter  60 value 0.038480\n",
      "iter  70 value 0.000562\n",
      "final  value 0.000062 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.031687\n",
      "iter  20 value 59.676878\n",
      "iter  30 value 57.110941\n",
      "iter  40 value 56.673458\n",
      "iter  50 value 56.587495\n",
      "iter  60 value 56.580256\n",
      "iter  70 value 56.579829\n",
      "final  value 56.579826 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.581630\n",
      "iter  20 value 49.413855\n",
      "iter  30 value 34.574471\n",
      "iter  40 value 21.677855\n",
      "iter  50 value 11.759449\n",
      "iter  60 value 8.657476\n",
      "iter  70 value 7.499748\n",
      "iter  80 value 6.797757\n",
      "iter  90 value 5.968707\n",
      "iter 100 value 5.597600\n",
      "final  value 5.597600 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 88.773617\n",
      "iter  20 value 60.484601\n",
      "iter  30 value 50.487837\n",
      "iter  40 value 42.942445\n",
      "iter  50 value 39.166076\n",
      "iter  60 value 37.493025\n",
      "iter  70 value 37.228151\n",
      "iter  80 value 37.179897\n",
      "iter  90 value 37.176916\n",
      "final  value 37.176872 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 91.073155\n",
      "iter  20 value 69.243089\n",
      "iter  30 value 67.095192\n",
      "iter  40 value 66.717342\n",
      "iter  50 value 66.638956\n",
      "iter  60 value 66.631158\n",
      "final  value 66.630965 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 88.776067\n",
      "iter  20 value 60.496493\n",
      "iter  30 value 50.530315\n",
      "iter  40 value 43.105392\n",
      "iter  50 value 39.512372\n",
      "iter  60 value 38.163957\n",
      "iter  70 value 38.037247\n",
      "iter  80 value 37.993265\n",
      "iter  90 value 37.956444\n",
      "iter 100 value 37.927940\n",
      "final  value 37.927940 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.349621\n",
      "iter  20 value 41.245086\n",
      "iter  30 value 21.063732\n",
      "iter  40 value 3.440590\n",
      "iter  50 value 0.008650\n",
      "final  value 0.000065 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.666153\n",
      "iter  20 value 51.035515\n",
      "iter  30 value 47.638231\n",
      "iter  40 value 46.610836\n",
      "iter  50 value 46.383612\n",
      "iter  60 value 46.359860\n",
      "iter  70 value 46.358619\n",
      "final  value 46.358587 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.352076\n",
      "iter  20 value 41.259142\n",
      "iter  30 value 21.214668\n",
      "iter  40 value 4.005118\n",
      "iter  50 value 1.729388\n",
      "iter  60 value 1.558900\n",
      "iter  70 value 1.447487\n",
      "iter  80 value 1.362537\n",
      "iter  90 value 1.313591\n",
      "iter 100 value 1.275340\n",
      "final  value 1.275340 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 147.275344\n",
      "iter  20 value 102.528995\n",
      "iter  30 value 89.105036\n",
      "iter  40 value 80.264937\n",
      "iter  50 value 71.724336\n",
      "iter  60 value 66.605630\n",
      "iter  70 value 64.996181\n",
      "iter  80 value 64.506321\n",
      "iter  90 value 64.444206\n",
      "final  value 64.443995 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 81.933026\n",
      "iter  20 value 49.016507\n",
      "iter  30 value 37.832665\n",
      "iter  40 value 23.383152\n",
      "iter  50 value 10.910867\n",
      "iter  60 value 0.077557\n",
      "iter  70 value 0.002551\n",
      "final  value 0.000053 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 81.606497\n",
      "iter  20 value 60.130167\n",
      "iter  30 value 57.053506\n",
      "iter  40 value 56.336824\n",
      "iter  50 value 56.182156\n",
      "iter  60 value 56.162778\n",
      "iter  70 value 56.160626\n",
      "final  value 56.160603 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 81.936107\n",
      "iter  20 value 49.031727\n",
      "iter  30 value 37.895025\n",
      "iter  40 value 23.676759\n",
      "iter  50 value 12.955441\n",
      "iter  60 value 8.302320\n",
      "iter  70 value 7.543561\n",
      "iter  80 value 6.919046\n",
      "iter  90 value 6.112307\n",
      "iter 100 value 5.639264\n",
      "final  value 5.639264 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 74.520850\n",
      "iter  20 value 40.851356\n",
      "iter  30 value 22.506927\n",
      "iter  40 value 4.532571\n",
      "iter  50 value 0.035233\n",
      "iter  60 value 0.000309\n",
      "final  value 0.000079 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 76.126702\n",
      "iter  20 value 52.015770\n",
      "iter  30 value 47.983742\n",
      "iter  40 value 47.016017\n",
      "iter  50 value 46.800175\n",
      "iter  60 value 46.784377\n",
      "iter  70 value 46.783172\n",
      "final  value 46.783155 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 74.522543\n",
      "iter  20 value 40.867671\n",
      "iter  30 value 22.690053\n",
      "iter  40 value 5.252924\n",
      "iter  50 value 2.081311\n",
      "iter  60 value 1.927254\n",
      "iter  70 value 1.797615\n",
      "iter  80 value 1.690884\n",
      "iter  90 value 1.612940\n",
      "iter 100 value 1.543408\n",
      "final  value 1.543408 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 65.563100\n",
      "iter  20 value 41.082416\n",
      "iter  30 value 19.389143\n",
      "iter  40 value 2.645140\n",
      "iter  50 value 0.026799\n",
      "iter  60 value 0.000632\n",
      "final  value 0.000080 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 67.926398\n",
      "iter  20 value 50.641579\n",
      "iter  30 value 47.959779\n",
      "iter  40 value 47.242088\n",
      "iter  50 value 47.052773\n",
      "iter  60 value 47.035100\n",
      "iter  70 value 47.033078\n",
      "final  value 47.033067 \n",
      "converged\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 65.565590\n",
      "iter  20 value 41.096344\n",
      "iter  30 value 19.620001\n",
      "iter  40 value 4.026572\n",
      "iter  50 value 2.249003\n",
      "iter  60 value 1.975066\n",
      "iter  70 value 1.784794\n",
      "iter  80 value 1.671370\n",
      "iter  90 value 1.565782\n",
      "iter 100 value 1.509327\n",
      "final  value 1.509327 \n",
      "stopped after 100 iterations\n",
      "# weights:  156 (102 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 130.263502\n",
      "iter  20 value 92.194248\n",
      "iter  30 value 79.708355\n",
      "iter  40 value 68.153701\n",
      "iter  50 value 63.235281\n",
      "iter  60 value 61.193303\n",
      "iter  70 value 59.133610\n",
      "iter  80 value 56.725823\n",
      "iter  90 value 55.859781\n",
      "iter 100 value 55.451943\n",
      "final  value 55.451943 \n",
      "stopped after 100 iterations\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.147010\n",
      "iter  20 value 67.352147\n",
      "iter  30 value 66.880240\n",
      "iter  40 value 66.633803\n",
      "iter  50 value 66.590546\n",
      "iter  60 value 66.589671\n",
      "final  value 66.589666 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 72.996455\n",
      "iter  20 value 71.304059\n",
      "iter  30 value 71.239984\n",
      "iter  40 value 71.237111\n",
      "iter  50 value 71.236593\n",
      "final  value 71.236553 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.150050\n",
      "iter  20 value 67.357121\n",
      "iter  30 value 66.886885\n",
      "iter  40 value 66.641533\n",
      "iter  50 value 66.598408\n",
      "iter  60 value 66.597535\n",
      "final  value 66.597530 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 69.395230\n",
      "iter  20 value 66.003501\n",
      "iter  30 value 64.256805\n",
      "iter  40 value 63.169162\n",
      "iter  50 value 62.837291\n",
      "iter  60 value 62.794318\n",
      "iter  70 value 62.792780\n",
      "final  value 62.792759 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 72.504295\n",
      "iter  20 value 70.858579\n",
      "iter  30 value 70.750493\n",
      "iter  40 value 70.720816\n",
      "iter  50 value 70.716279\n",
      "final  value 70.716183 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 69.398584\n",
      "iter  20 value 66.010017\n",
      "iter  30 value 64.270062\n",
      "iter  40 value 63.190462\n",
      "iter  50 value 62.861905\n",
      "iter  60 value 62.819582\n",
      "iter  70 value 62.818104\n",
      "final  value 62.818085 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 76.900074\n",
      "iter  20 value 74.915967\n",
      "iter  30 value 74.562585\n",
      "iter  40 value 74.488523\n",
      "iter  50 value 74.473152\n",
      "iter  60 value 74.472776\n",
      "final  value 74.472775 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 79.460891\n",
      "iter  20 value 78.202040\n",
      "iter  30 value 78.155868\n",
      "iter  40 value 78.153823\n",
      "iter  50 value 78.153467\n",
      "final  value 78.153450 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 76.902819\n",
      "iter  20 value 74.919927\n",
      "iter  30 value 74.567375\n",
      "iter  40 value 74.493526\n",
      "iter  50 value 74.478196\n",
      "iter  60 value 74.477822\n",
      "final  value 74.477820 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 213.130784 \n",
      "iter  10 value 157.559239\n",
      "iter  20 value 148.490798\n",
      "iter  30 value 146.652517\n",
      "iter  40 value 146.594120\n",
      "iter  50 value 146.592652\n",
      "final  value 146.592626 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.852550\n",
      "iter  20 value 66.991371\n",
      "iter  30 value 65.070393\n",
      "iter  40 value 64.122776\n",
      "iter  50 value 63.993268\n",
      "iter  60 value 63.982087\n",
      "iter  70 value 63.981743\n",
      "final  value 63.981738 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 74.575494\n",
      "iter  20 value 72.769540\n",
      "iter  30 value 72.630011\n",
      "iter  40 value 72.603629\n",
      "iter  50 value 72.598597\n",
      "final  value 72.598442 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.856646\n",
      "iter  20 value 66.999338\n",
      "iter  30 value 65.086009\n",
      "iter  40 value 64.145386\n",
      "iter  50 value 64.017741\n",
      "iter  60 value 64.006956\n",
      "iter  70 value 64.006630\n",
      "final  value 64.006625 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 68.420609\n",
      "iter  20 value 62.491758\n",
      "iter  30 value 56.922842\n",
      "iter  40 value 52.853630\n",
      "iter  50 value 51.183844\n",
      "iter  60 value 50.509789\n",
      "iter  70 value 49.943582\n",
      "iter  80 value 49.329415\n",
      "iter  90 value 48.664947\n",
      "iter 100 value 48.603722\n",
      "final  value 48.603722 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 72.908879\n",
      "iter  20 value 70.346245\n",
      "iter  30 value 70.086956\n",
      "iter  40 value 69.957641\n",
      "iter  50 value 69.938885\n",
      "iter  60 value 69.938385\n",
      "final  value 69.938384 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 68.425617\n",
      "iter  20 value 62.503257\n",
      "iter  30 value 56.969606\n",
      "iter  40 value 52.966580\n",
      "iter  50 value 51.390495\n",
      "iter  60 value 50.793274\n",
      "iter  70 value 50.326179\n",
      "iter  80 value 49.970069\n",
      "iter  90 value 49.722548\n",
      "iter 100 value 49.715326\n",
      "final  value 49.715326 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 69.638542\n",
      "iter  20 value 66.577865\n",
      "iter  30 value 64.615516\n",
      "iter  40 value 64.096619\n",
      "iter  50 value 64.044532\n",
      "iter  60 value 64.042120\n",
      "final  value 64.042089 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 72.348469\n",
      "iter  20 value 70.923280\n",
      "iter  30 value 70.430076\n",
      "iter  40 value 70.363292\n",
      "iter  50 value 70.357143\n",
      "final  value 70.356965 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 69.641434\n",
      "iter  20 value 66.583359\n",
      "iter  30 value 64.624544\n",
      "iter  40 value 64.107393\n",
      "iter  50 value 64.055540\n",
      "iter  60 value 64.053141\n",
      "final  value 64.053110 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 155.060723\n",
      "iter  20 value 147.792454\n",
      "iter  30 value 145.466122\n",
      "iter  40 value 145.301023\n",
      "iter  50 value 145.298589\n",
      "final  value 145.298547 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 75.158000\n",
      "iter  20 value 69.406424\n",
      "iter  30 value 63.989703\n",
      "iter  40 value 58.896699\n",
      "iter  50 value 52.637590\n",
      "iter  60 value 44.627505\n",
      "iter  70 value 42.182407\n",
      "iter  80 value 41.975609\n",
      "iter  90 value 41.973032\n",
      "final  value 41.973028 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.427066\n",
      "iter  20 value 75.845460\n",
      "iter  30 value 75.380025\n",
      "iter  40 value 75.286026\n",
      "iter  50 value 75.278226\n",
      "iter  60 value 75.277598\n",
      "final  value 75.277595 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 75.161586\n",
      "iter  20 value 69.415823\n",
      "iter  30 value 64.024199\n",
      "iter  40 value 59.045402\n",
      "iter  50 value 53.348692\n",
      "iter  60 value 47.851397\n",
      "iter  70 value 46.843151\n",
      "iter  80 value 46.443695\n",
      "iter  90 value 46.309968\n",
      "iter 100 value 46.190241\n",
      "final  value 46.190241 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 74.952027\n",
      "iter  20 value 73.616625\n",
      "iter  30 value 73.512492\n",
      "iter  40 value 73.464284\n",
      "iter  50 value 73.455700\n",
      "final  value 73.455465 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.382176\n",
      "iter  20 value 76.498070\n",
      "iter  30 value 76.466511\n",
      "iter  40 value 76.452405\n",
      "iter  50 value 76.450645\n",
      "final  value 76.450581 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 74.954625\n",
      "iter  20 value 73.619986\n",
      "iter  30 value 73.516185\n",
      "iter  40 value 73.468190\n",
      "iter  50 value 73.459635\n",
      "final  value 73.459400 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.459576\n",
      "iter  20 value 66.807033\n",
      "iter  30 value 65.568826\n",
      "iter  40 value 64.721115\n",
      "iter  50 value 64.603724\n",
      "iter  60 value 64.594832\n",
      "iter  70 value 64.594505\n",
      "iter  70 value 64.594504\n",
      "iter  70 value 64.594504\n",
      "final  value 64.594504 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 73.325878\n",
      "iter  20 value 71.703907\n",
      "iter  30 value 71.593118\n",
      "iter  40 value 71.571136\n",
      "iter  50 value 71.564228\n",
      "iter  60 value 71.563875\n",
      "iter  60 value 71.563874\n",
      "iter  60 value 71.563874\n",
      "final  value 71.563874 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 70.462663\n",
      "iter  20 value 66.813973\n",
      "iter  30 value 65.580328\n",
      "iter  40 value 64.738886\n",
      "iter  50 value 64.622298\n",
      "iter  60 value 64.613430\n",
      "iter  70 value 64.613108\n",
      "iter  70 value 64.613108\n",
      "iter  70 value 64.613108\n",
      "final  value 64.613108 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 158.247354\n",
      "iter  20 value 148.903731\n",
      "iter  30 value 146.555760\n",
      "iter  40 value 146.443536\n",
      "iter  50 value 146.440166\n",
      "final  value 146.440101 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 73.075110\n",
      "iter  20 value 68.311988\n",
      "iter  30 value 64.738390\n",
      "iter  40 value 62.735110\n",
      "iter  50 value 61.758558\n",
      "iter  60 value 61.452444\n",
      "iter  70 value 61.403209\n",
      "iter  80 value 61.395302\n",
      "final  value 61.394915 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 75.898151\n",
      "iter  20 value 73.829478\n",
      "iter  30 value 73.460546\n",
      "iter  40 value 73.384604\n",
      "iter  50 value 73.379411\n",
      "final  value 73.379279 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 73.078155\n",
      "iter  20 value 68.320145\n",
      "iter  30 value 64.762518\n",
      "iter  40 value 62.777528\n",
      "iter  50 value 61.826993\n",
      "iter  60 value 61.538505\n",
      "iter  70 value 61.494909\n",
      "iter  80 value 61.488770\n",
      "iter  90 value 61.488504\n",
      "iter  90 value 61.488503\n",
      "iter  90 value 61.488503\n",
      "final  value 61.488503 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.857196\n",
      "iter  20 value 75.998750\n",
      "iter  30 value 74.752343\n",
      "iter  40 value 74.267829\n",
      "iter  50 value 74.162692\n",
      "iter  60 value 74.155862\n",
      "final  value 74.155753 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 81.735148\n",
      "iter  20 value 80.289249\n",
      "iter  30 value 80.239592\n",
      "iter  40 value 80.230160\n",
      "iter  50 value 80.228843\n",
      "final  value 80.228699 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.860365\n",
      "iter  20 value 76.004545\n",
      "iter  30 value 74.762842\n",
      "iter  40 value 74.281321\n",
      "iter  50 value 74.176847\n",
      "iter  60 value 74.170088\n",
      "final  value 74.169981 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.609093\n",
      "iter  20 value 70.140682\n",
      "iter  30 value 68.523146\n",
      "iter  40 value 68.131762\n",
      "iter  50 value 68.085908\n",
      "iter  60 value 68.084471\n",
      "final  value 68.084438 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 76.001391\n",
      "iter  20 value 74.569717\n",
      "iter  30 value 74.328933\n",
      "iter  40 value 74.292379\n",
      "iter  50 value 74.289013\n",
      "final  value 74.288941 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.611669\n",
      "iter  20 value 70.147075\n",
      "iter  30 value 68.534984\n",
      "iter  40 value 68.146104\n",
      "iter  50 value 68.100587\n",
      "iter  60 value 68.099152\n",
      "final  value 68.099119 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 160.174394\n",
      "iter  20 value 151.573889\n",
      "iter  30 value 150.173681\n",
      "iter  40 value 150.129556\n",
      "iter  50 value 150.128512\n",
      "final  value 150.128496 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 61.646148\n",
      "iter  20 value 52.657318\n",
      "iter  30 value 37.584014\n",
      "iter  40 value 17.197312\n",
      "iter  50 value 0.408061\n",
      "iter  60 value 0.010210\n",
      "iter  70 value 0.001159\n",
      "iter  80 value 0.000103\n",
      "final  value 0.000100 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 64.941806\n",
      "iter  20 value 61.828920\n",
      "iter  30 value 60.637062\n",
      "iter  40 value 60.387935\n",
      "iter  50 value 60.359771\n",
      "iter  60 value 60.359397\n",
      "iter  60 value 60.359397\n",
      "iter  60 value 60.359397\n",
      "final  value 60.359397 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 61.649753\n",
      "iter  20 value 52.674303\n",
      "iter  30 value 37.861035\n",
      "iter  40 value 18.924662\n",
      "iter  50 value 10.739884\n",
      "iter  60 value 9.145606\n",
      "iter  70 value 7.738045\n",
      "iter  80 value 6.792077\n",
      "iter  90 value 6.087391\n",
      "iter 100 value 5.769873\n",
      "final  value 5.769873 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 70.380779\n",
      "iter  20 value 66.515719\n",
      "iter  30 value 61.987773\n",
      "iter  40 value 58.234198\n",
      "iter  50 value 54.028766\n",
      "iter  60 value 46.007882\n",
      "iter  70 value 35.711051\n",
      "iter  80 value 27.528637\n",
      "iter  90 value 24.214630\n",
      "iter 100 value 22.359479\n",
      "final  value 22.359479 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 73.657341\n",
      "iter  20 value 72.088553\n",
      "iter  30 value 71.804978\n",
      "iter  40 value 71.752891\n",
      "iter  50 value 71.745502\n",
      "iter  60 value 71.745137\n",
      "final  value 71.745136 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 70.384372\n",
      "iter  20 value 66.523765\n",
      "iter  30 value 62.023854\n",
      "iter  40 value 58.297787\n",
      "iter  50 value 54.805527\n",
      "iter  60 value 50.449961\n",
      "iter  70 value 48.538332\n",
      "iter  80 value 47.787145\n",
      "iter  90 value 47.477281\n",
      "iter 100 value 47.372240\n",
      "final  value 47.372240 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 88.600419\n",
      "iter  20 value 86.553236\n",
      "iter  30 value 86.395066\n",
      "iter  40 value 86.342227\n",
      "iter  50 value 86.333478\n",
      "iter  60 value 86.332082\n",
      "final  value 86.332070 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 90.995369\n",
      "iter  20 value 89.467693\n",
      "iter  30 value 89.395770\n",
      "iter  40 value 89.385721\n",
      "iter  50 value 89.384847\n",
      "final  value 89.384759 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 88.603049\n",
      "iter  20 value 86.556865\n",
      "iter  30 value 86.399193\n",
      "iter  40 value 86.346659\n",
      "iter  50 value 86.337961\n",
      "iter  60 value 86.336573\n",
      "final  value 86.336561 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 154.374526\n",
      "iter  20 value 148.088623\n",
      "iter  30 value 145.748469\n",
      "iter  40 value 145.587671\n",
      "iter  50 value 145.583829\n",
      "final  value 145.583755 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.548649\n",
      "iter  20 value 71.337674\n",
      "iter  30 value 70.662874\n",
      "iter  40 value 70.303296\n",
      "iter  50 value 70.227245\n",
      "iter  60 value 70.223878\n",
      "final  value 70.223777 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 76.070072\n",
      "iter  20 value 74.700230\n",
      "iter  30 value 74.643872\n",
      "iter  40 value 74.641545\n",
      "iter  50 value 74.641038\n",
      "final  value 74.641009 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.551344\n",
      "iter  20 value 71.341836\n",
      "iter  30 value 70.669355\n",
      "iter  40 value 70.312216\n",
      "iter  50 value 70.236717\n",
      "iter  60 value 70.233365\n",
      "final  value 70.233265 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 68.308652\n",
      "iter  20 value 63.538830\n",
      "iter  30 value 60.693346\n",
      "iter  40 value 58.484803\n",
      "iter  50 value 58.029170\n",
      "iter  60 value 57.864107\n",
      "iter  70 value 57.819115\n",
      "iter  80 value 57.810610\n",
      "iter  90 value 57.809485\n",
      "final  value 57.809479 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 71.780120\n",
      "iter  20 value 69.217197\n",
      "iter  30 value 69.040342\n",
      "iter  40 value 68.993970\n",
      "iter  50 value 68.987675\n",
      "final  value 68.987523 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 68.312425\n",
      "iter  20 value 63.546557\n",
      "iter  30 value 60.712002\n",
      "iter  40 value 58.531799\n",
      "iter  50 value 58.088488\n",
      "iter  60 value 57.930072\n",
      "iter  70 value 57.889789\n",
      "iter  80 value 57.882486\n",
      "iter  90 value 57.881608\n",
      "final  value 57.881605 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 139.523761 \n",
      "iter  10 value 68.244382\n",
      "iter  20 value 64.535475\n",
      "iter  30 value 61.629958\n",
      "iter  40 value 59.670212\n",
      "iter  50 value 58.427297\n",
      "iter  60 value 56.732410\n",
      "iter  70 value 55.291786\n",
      "iter  80 value 52.007628\n",
      "iter  90 value 38.611933\n",
      "iter 100 value 38.375973\n",
      "final  value 38.375973 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 139.523761 \n",
      "iter  10 value 71.772113\n",
      "iter  20 value 70.244146\n",
      "iter  30 value 70.074602\n",
      "iter  40 value 70.029504\n",
      "iter  50 value 70.022224\n",
      "final  value 70.022146 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 139.523761 \n",
      "iter  10 value 68.248269\n",
      "iter  20 value 64.543662\n",
      "iter  30 value 61.651111\n",
      "iter  40 value 59.724718\n",
      "iter  50 value 58.527972\n",
      "iter  60 value 57.113844\n",
      "iter  70 value 56.516948\n",
      "iter  80 value 56.220310\n",
      "iter  90 value 56.167542\n",
      "iter 100 value 56.163092\n",
      "final  value 56.163092 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 210.933559 \n",
      "iter  10 value 156.329166\n",
      "iter  20 value 145.636808\n",
      "iter  30 value 144.550321\n",
      "iter  40 value 144.468858\n",
      "iter  50 value 144.459217\n",
      "iter  60 value 144.458799\n",
      "final  value 144.458780 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 70.084430\n",
      "iter  20 value 67.985091\n",
      "iter  30 value 66.722417\n",
      "iter  40 value 66.164729\n",
      "iter  50 value 66.052628\n",
      "iter  60 value 66.029601\n",
      "iter  70 value 66.028102\n",
      "final  value 66.028072 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 72.521716\n",
      "iter  20 value 71.580315\n",
      "iter  30 value 71.467776\n",
      "iter  40 value 71.445655\n",
      "iter  50 value 71.443214\n",
      "final  value 71.443174 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 70.087046\n",
      "iter  20 value 67.989780\n",
      "iter  30 value 66.731809\n",
      "iter  40 value 66.178463\n",
      "iter  50 value 66.067934\n",
      "iter  60 value 66.045695\n",
      "iter  70 value 66.044262\n",
      "final  value 66.044234 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 76.647990\n",
      "iter  20 value 71.405096\n",
      "iter  30 value 66.321895\n",
      "iter  40 value 62.464078\n",
      "iter  50 value 59.991716\n",
      "iter  60 value 56.150356\n",
      "iter  70 value 49.694608\n",
      "iter  80 value 41.554915\n",
      "iter  90 value 40.355804\n",
      "iter 100 value 40.347416\n",
      "final  value 40.347416 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 80.071234\n",
      "iter  20 value 77.925858\n",
      "iter  30 value 77.555551\n",
      "iter  40 value 77.501467\n",
      "iter  50 value 77.497968\n",
      "final  value 77.497843 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 76.651773\n",
      "iter  20 value 71.414709\n",
      "iter  30 value 66.357432\n",
      "iter  40 value 62.596738\n",
      "iter  50 value 60.328519\n",
      "iter  60 value 57.302733\n",
      "iter  70 value 55.008879\n",
      "iter  80 value 53.279677\n",
      "iter  90 value 52.099563\n",
      "iter 100 value 51.968390\n",
      "final  value 51.968390 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 77.140114\n",
      "iter  20 value 72.926841\n",
      "iter  30 value 69.604661\n",
      "iter  40 value 67.423581\n",
      "iter  50 value 64.940753\n",
      "iter  60 value 62.243371\n",
      "iter  70 value 57.357479\n",
      "iter  80 value 45.906524\n",
      "iter  90 value 43.740125\n",
      "iter 100 value 43.731478\n",
      "final  value 43.731478 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 80.381009\n",
      "iter  20 value 78.458842\n",
      "iter  30 value 78.237834\n",
      "iter  40 value 78.198079\n",
      "iter  50 value 78.194584\n",
      "final  value 78.194424 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 77.143659\n",
      "iter  20 value 72.934576\n",
      "iter  30 value 69.629559\n",
      "iter  40 value 67.490589\n",
      "iter  50 value 65.186670\n",
      "iter  60 value 63.281869\n",
      "iter  70 value 62.601454\n",
      "iter  80 value 61.980155\n",
      "iter  90 value 61.467890\n",
      "iter 100 value 61.375809\n",
      "final  value 61.375809 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 162.851166\n",
      "iter  20 value 154.543001\n",
      "iter  30 value 152.235440\n",
      "iter  40 value 151.708565\n",
      "iter  50 value 151.686088\n",
      "iter  60 value 151.685653\n",
      "final  value 151.685630 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 79.144106\n",
      "iter  20 value 74.855939\n",
      "iter  30 value 73.338052\n",
      "iter  40 value 72.365054\n",
      "iter  50 value 72.137645\n",
      "iter  60 value 72.103526\n",
      "iter  70 value 72.101810\n",
      "iter  80 value 72.101729\n",
      "final  value 72.101726 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 82.242256\n",
      "iter  20 value 80.003793\n",
      "iter  30 value 79.944744\n",
      "iter  40 value 79.936891\n",
      "iter  50 value 79.935974\n",
      "final  value 79.935936 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 79.147507\n",
      "iter  20 value 74.863044\n",
      "iter  30 value 73.351866\n",
      "iter  40 value 72.387059\n",
      "iter  50 value 72.163469\n",
      "iter  60 value 72.130447\n",
      "iter  70 value 72.128866\n",
      "iter  80 value 72.128794\n",
      "final  value 72.128792 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 76.557818\n",
      "iter  20 value 72.238856\n",
      "iter  30 value 71.407663\n",
      "iter  40 value 70.687452\n",
      "iter  50 value 70.502838\n",
      "iter  60 value 70.476801\n",
      "iter  70 value 70.475842\n",
      "final  value 70.475810 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 80.158734\n",
      "iter  20 value 77.477027\n",
      "iter  30 value 77.385826\n",
      "iter  40 value 77.372351\n",
      "iter  50 value 77.367917\n",
      "iter  60 value 77.367629\n",
      "iter  60 value 77.367629\n",
      "iter  60 value 77.367629\n",
      "final  value 77.367629 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 76.561723\n",
      "iter  20 value 72.245744\n",
      "iter  30 value 71.418201\n",
      "iter  40 value 70.704065\n",
      "iter  50 value 70.521740\n",
      "iter  60 value 70.496235\n",
      "iter  70 value 70.495285\n",
      "final  value 70.495254 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 67.488960\n",
      "iter  20 value 62.855042\n",
      "iter  30 value 57.894519\n",
      "iter  40 value 54.238176\n",
      "iter  50 value 51.406662\n",
      "iter  60 value 48.731263\n",
      "iter  70 value 44.293653\n",
      "iter  80 value 35.334529\n",
      "iter  90 value 24.989535\n",
      "iter 100 value 6.777093\n",
      "final  value 6.777093 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 70.857981\n",
      "iter  20 value 69.210474\n",
      "iter  30 value 68.769288\n",
      "iter  40 value 68.690057\n",
      "iter  50 value 68.670115\n",
      "final  value 68.669654 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 67.492643\n",
      "iter  20 value 62.864651\n",
      "iter  30 value 57.928084\n",
      "iter  40 value 54.354785\n",
      "iter  50 value 51.697016\n",
      "iter  60 value 49.471065\n",
      "iter  70 value 46.835734\n",
      "iter  80 value 44.222367\n",
      "iter  90 value 42.499372\n",
      "iter 100 value 42.269308\n",
      "final  value 42.269308 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 159.518801\n",
      "iter  20 value 149.073386\n",
      "iter  30 value 148.357001\n",
      "iter  40 value 148.325664\n",
      "iter  50 value 148.323314\n",
      "final  value 148.323177 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.396755\n",
      "iter  20 value 76.113359\n",
      "iter  30 value 75.628716\n",
      "iter  40 value 75.450180\n",
      "iter  50 value 75.418253\n",
      "iter  60 value 75.416885\n",
      "final  value 75.416879 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 81.182723\n",
      "iter  20 value 79.797670\n",
      "iter  30 value 79.733883\n",
      "iter  40 value 79.730049\n",
      "iter  50 value 79.729464\n",
      "final  value 79.729432 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 78.399748\n",
      "iter  20 value 76.117971\n",
      "iter  30 value 75.634909\n",
      "iter  40 value 75.457155\n",
      "iter  50 value 75.425384\n",
      "iter  60 value 75.424021\n",
      "final  value 75.424015 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 74.731884\n",
      "iter  20 value 72.324321\n",
      "iter  30 value 71.167261\n",
      "iter  40 value 70.845024\n",
      "iter  50 value 70.770971\n",
      "iter  60 value 70.766746\n",
      "iter  70 value 70.766596\n",
      "iter  70 value 70.766596\n",
      "iter  70 value 70.766596\n",
      "final  value 70.766596 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 77.569127\n",
      "iter  20 value 76.440966\n",
      "iter  30 value 76.315034\n",
      "iter  40 value 76.284079\n",
      "iter  50 value 76.281619\n",
      "final  value 76.281537 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 74.734931\n",
      "iter  20 value 72.329570\n",
      "iter  30 value 71.175511\n",
      "iter  40 value 70.854682\n",
      "iter  50 value 70.781000\n",
      "iter  60 value 70.776827\n",
      "iter  70 value 70.776680\n",
      "iter  70 value 70.776680\n",
      "iter  70 value 70.776679\n",
      "final  value 70.776679 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.952544\n",
      "iter  20 value 69.526974\n",
      "iter  30 value 69.216340\n",
      "iter  40 value 69.099418\n",
      "iter  50 value 69.073778\n",
      "iter  60 value 69.073436\n",
      "final  value 69.073435 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 74.706543\n",
      "iter  20 value 73.207418\n",
      "iter  30 value 73.149856\n",
      "iter  40 value 73.144460\n",
      "iter  50 value 73.143175\n",
      "final  value 73.143134 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.955502\n",
      "iter  20 value 69.531564\n",
      "iter  30 value 69.221913\n",
      "iter  40 value 69.105510\n",
      "iter  50 value 69.079970\n",
      "iter  60 value 69.079632\n",
      "final  value 69.079631 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 163.096720\n",
      "iter  20 value 154.362579\n",
      "iter  30 value 151.867335\n",
      "iter  40 value 151.747646\n",
      "iter  50 value 151.744921\n",
      "final  value 151.744868 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 90.892565\n",
      "iter  20 value 88.125858\n",
      "iter  30 value 87.435277\n",
      "iter  40 value 87.037384\n",
      "iter  50 value 86.973093\n",
      "iter  60 value 86.964831\n",
      "final  value 86.964721 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 93.284135\n",
      "iter  20 value 91.678034\n",
      "iter  30 value 91.639332\n",
      "iter  40 value 91.638028\n",
      "iter  50 value 91.637816\n",
      "final  value 91.637777 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 90.895198\n",
      "iter  20 value 88.130658\n",
      "iter  30 value 87.443134\n",
      "iter  40 value 87.048284\n",
      "iter  50 value 86.984819\n",
      "iter  60 value 86.976650\n",
      "final  value 86.976545 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.531571\n",
      "iter  20 value 70.839634\n",
      "iter  30 value 66.219870\n",
      "iter  40 value 61.700011\n",
      "iter  50 value 55.623876\n",
      "iter  60 value 44.141665\n",
      "iter  70 value 41.921356\n",
      "iter  80 value 41.786490\n",
      "iter  90 value 41.785357\n",
      "final  value 41.785355 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.716675\n",
      "iter  20 value 76.629408\n",
      "iter  30 value 76.463391\n",
      "iter  40 value 76.417089\n",
      "iter  50 value 76.413350\n",
      "final  value 76.413244 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.535119\n",
      "iter  20 value 70.848269\n",
      "iter  30 value 66.254559\n",
      "iter  40 value 61.828373\n",
      "iter  50 value 56.445517\n",
      "iter  60 value 50.383502\n",
      "iter  70 value 49.543424\n",
      "iter  80 value 49.015712\n",
      "iter  90 value 48.312725\n",
      "iter 100 value 48.134990\n",
      "final  value 48.134990 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.425182\n",
      "iter  20 value 73.867761\n",
      "iter  30 value 69.701725\n",
      "iter  40 value 64.331886\n",
      "iter  50 value 58.281725\n",
      "iter  60 value 46.855028\n",
      "iter  70 value 44.694478\n",
      "iter  80 value 44.483762\n",
      "iter  90 value 44.473767\n",
      "final  value 44.473739 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 81.253696\n",
      "iter  20 value 79.376222\n",
      "iter  30 value 79.178090\n",
      "iter  40 value 79.141359\n",
      "iter  50 value 79.139482\n",
      "iter  60 value 79.139233\n",
      "iter  60 value 79.139233\n",
      "iter  60 value 79.139233\n",
      "final  value 79.139233 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.428283\n",
      "iter  20 value 73.876233\n",
      "iter  30 value 69.734791\n",
      "iter  40 value 64.415875\n",
      "iter  50 value 59.572983\n",
      "iter  60 value 54.205101\n",
      "iter  70 value 53.581613\n",
      "iter  80 value 53.077903\n",
      "iter  90 value 52.611118\n",
      "iter 100 value 52.505182\n",
      "final  value 52.505182 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 156.559616\n",
      "iter  20 value 151.573581\n",
      "iter  30 value 150.085278\n",
      "iter  40 value 149.757948\n",
      "iter  50 value 149.745476\n",
      "iter  60 value 149.745216\n",
      "iter  60 value 149.745216\n",
      "iter  60 value 149.745216\n",
      "final  value 149.745216 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 81.993233\n",
      "iter  20 value 79.472614\n",
      "iter  30 value 79.128365\n",
      "iter  40 value 78.999155\n",
      "iter  50 value 78.953331\n",
      "iter  60 value 78.949906\n",
      "final  value 78.949886 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 84.284142\n",
      "iter  20 value 82.569606\n",
      "iter  30 value 82.469481\n",
      "iter  40 value 82.455523\n",
      "iter  50 value 82.453650\n",
      "final  value 82.453575 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 81.995683\n",
      "iter  20 value 79.476526\n",
      "iter  30 value 79.133485\n",
      "iter  40 value 79.005109\n",
      "iter  50 value 78.959600\n",
      "iter  60 value 78.956206\n",
      "final  value 78.956186 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 77.296917\n",
      "iter  20 value 74.948551\n",
      "iter  30 value 74.729753\n",
      "iter  40 value 74.622289\n",
      "iter  50 value 74.611471\n",
      "final  value 74.611196 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 80.043837\n",
      "iter  20 value 78.586860\n",
      "iter  30 value 78.533289\n",
      "iter  40 value 78.522212\n",
      "iter  50 value 78.520189\n",
      "final  value 78.520126 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 77.299856\n",
      "iter  20 value 74.953061\n",
      "iter  30 value 74.735054\n",
      "iter  40 value 74.628057\n",
      "iter  50 value 74.617281\n",
      "final  value 74.617007 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 67.602332\n",
      "iter  20 value 61.864109\n",
      "iter  30 value 57.809871\n",
      "iter  40 value 54.851197\n",
      "iter  50 value 52.139512\n",
      "iter  60 value 48.018284\n",
      "iter  70 value 41.283156\n",
      "iter  80 value 34.015505\n",
      "iter  90 value 33.395287\n",
      "iter 100 value 33.391297\n",
      "final  value 33.391297 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 71.414755\n",
      "iter  20 value 69.102758\n",
      "iter  30 value 68.913453\n",
      "iter  40 value 68.881989\n",
      "iter  50 value 68.874235\n",
      "final  value 68.874027 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 67.606547\n",
      "iter  20 value 61.875302\n",
      "iter  30 value 57.852967\n",
      "iter  40 value 54.955258\n",
      "iter  50 value 52.420375\n",
      "iter  60 value 49.266690\n",
      "iter  70 value 46.940491\n",
      "iter  80 value 45.877696\n",
      "iter  90 value 45.083806\n",
      "iter 100 value 44.962143\n",
      "final  value 44.962143 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 213.130784 \n",
      "iter  10 value 159.180331\n",
      "iter  20 value 148.826747\n",
      "iter  30 value 146.108134\n",
      "iter  40 value 146.020943\n",
      "iter  50 value 146.019460\n",
      "final  value 146.019428 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 79.099048\n",
      "iter  20 value 74.547912\n",
      "iter  30 value 72.080766\n",
      "iter  40 value 70.800132\n",
      "iter  50 value 70.383226\n",
      "iter  60 value 70.303904\n",
      "iter  70 value 70.290480\n",
      "final  value 70.290163 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 81.899109\n",
      "iter  20 value 79.752254\n",
      "iter  30 value 79.614524\n",
      "iter  40 value 79.596747\n",
      "iter  50 value 79.595062\n",
      "final  value 79.594948 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 79.102138\n",
      "iter  20 value 74.555685\n",
      "iter  30 value 72.099131\n",
      "iter  40 value 70.837306\n",
      "iter  50 value 70.430780\n",
      "iter  60 value 70.356304\n",
      "iter  70 value 70.344063\n",
      "iter  80 value 70.343752\n",
      "final  value 70.343710 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 71.598764\n",
      "iter  20 value 65.882665\n",
      "iter  30 value 60.956307\n",
      "iter  40 value 55.710951\n",
      "iter  50 value 48.510021\n",
      "iter  60 value 41.085977\n",
      "iter  70 value 40.543526\n",
      "iter  80 value 40.518587\n",
      "final  value 40.518488 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 75.222806\n",
      "iter  20 value 72.858530\n",
      "iter  30 value 72.602258\n",
      "iter  40 value 72.552188\n",
      "iter  50 value 72.544879\n",
      "iter  60 value 72.544502\n",
      "iter  60 value 72.544502\n",
      "iter  60 value 72.544502\n",
      "final  value 72.544502 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 141.720985 \n",
      "iter  10 value 71.602763\n",
      "iter  20 value 65.893302\n",
      "iter  30 value 61.000741\n",
      "iter  40 value 55.904895\n",
      "iter  50 value 49.663097\n",
      "iter  60 value 45.328243\n",
      "iter  70 value 45.056751\n",
      "iter  80 value 44.693224\n",
      "iter  90 value 44.510525\n",
      "iter 100 value 44.303295\n",
      "final  value 44.303295 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 67.358349\n",
      "iter  20 value 63.604289\n",
      "iter  30 value 61.633840\n",
      "iter  40 value 60.605911\n",
      "iter  50 value 60.426535\n",
      "iter  60 value 60.414792\n",
      "iter  70 value 60.414384\n",
      "final  value 60.414381 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 70.900469\n",
      "iter  20 value 69.066770\n",
      "iter  30 value 68.929665\n",
      "iter  40 value 68.876384\n",
      "iter  50 value 68.868221\n",
      "final  value 68.868071 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 67.362148\n",
      "iter  20 value 63.611625\n",
      "iter  30 value 61.648272\n",
      "iter  40 value 60.626141\n",
      "iter  50 value 60.447673\n",
      "iter  60 value 60.436192\n",
      "iter  70 value 60.435798\n",
      "iter  70 value 60.435798\n",
      "iter  70 value 60.435798\n",
      "final  value 60.435798 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 213.130784 \n",
      "iter  10 value 160.791344\n",
      "iter  20 value 148.926490\n",
      "iter  30 value 147.712678\n",
      "iter  40 value 147.687564\n",
      "iter  50 value 147.686960\n",
      "final  value 147.686941 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.046973\n",
      "iter  20 value 74.531783\n",
      "iter  30 value 73.149584\n",
      "iter  40 value 72.631368\n",
      "iter  50 value 72.552979\n",
      "iter  60 value 72.546700\n",
      "iter  70 value 72.546291\n",
      "final  value 72.546289 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 79.686538\n",
      "iter  20 value 78.328996\n",
      "iter  30 value 78.259680\n",
      "iter  40 value 78.241900\n",
      "iter  50 value 78.239912\n",
      "iter  60 value 78.239702\n",
      "final  value 78.239700 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 77.049831\n",
      "iter  20 value 74.536692\n",
      "iter  30 value 73.159690\n",
      "iter  40 value 72.646341\n",
      "iter  50 value 72.568493\n",
      "iter  60 value 72.562338\n",
      "iter  70 value 72.561937\n",
      "final  value 72.561935 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 79.223870\n",
      "iter  20 value 77.391629\n",
      "iter  30 value 77.025830\n",
      "iter  40 value 76.933552\n",
      "iter  50 value 76.920450\n",
      "final  value 76.920177 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 81.502152\n",
      "iter  20 value 80.482735\n",
      "iter  30 value 80.457003\n",
      "iter  40 value 80.455203\n",
      "iter  50 value 80.454763\n",
      "final  value 80.454748 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 79.226344\n",
      "iter  20 value 77.395516\n",
      "iter  30 value 77.030823\n",
      "iter  40 value 76.938881\n",
      "iter  50 value 76.925817\n",
      "final  value 76.925543 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 60.542540\n",
      "iter  20 value 54.327761\n",
      "iter  30 value 47.737958\n",
      "iter  40 value 42.778300\n",
      "iter  50 value 39.200502\n",
      "iter  60 value 38.283250\n",
      "iter  70 value 37.602822\n",
      "iter  80 value 36.699523\n",
      "iter  90 value 36.128093\n",
      "iter 100 value 35.978451\n",
      "final  value 35.978451 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 63.638081\n",
      "iter  20 value 60.552323\n",
      "iter  30 value 59.583960\n",
      "iter  40 value 59.325158\n",
      "iter  50 value 59.311153\n",
      "final  value 59.311100 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 60.545902\n",
      "iter  20 value 54.336969\n",
      "iter  30 value 47.769396\n",
      "iter  40 value 42.862283\n",
      "iter  50 value 39.456713\n",
      "iter  60 value 38.685265\n",
      "iter  70 value 38.084682\n",
      "iter  80 value 37.481758\n",
      "iter  90 value 37.171215\n",
      "iter 100 value 37.112555\n",
      "final  value 37.112555 \n",
      "stopped after 100 iterations\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 155.872921\n",
      "iter  20 value 145.938892\n",
      "iter  30 value 143.841864\n",
      "iter  40 value 143.789404\n",
      "iter  50 value 143.788289\n",
      "final  value 143.788268 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.993566\n",
      "iter  20 value 71.785567\n",
      "iter  30 value 70.677790\n",
      "iter  40 value 69.861649\n",
      "iter  50 value 69.612878\n",
      "iter  60 value 69.582035\n",
      "iter  70 value 69.580459\n",
      "final  value 69.580428 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 78.964439\n",
      "iter  20 value 76.378913\n",
      "iter  30 value 76.310059\n",
      "iter  40 value 76.303929\n",
      "iter  50 value 76.302729\n",
      "final  value 76.302671 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.996788\n",
      "iter  20 value 71.791728\n",
      "iter  30 value 70.689018\n",
      "iter  40 value 69.881585\n",
      "iter  50 value 69.637188\n",
      "iter  60 value 69.607274\n",
      "iter  70 value 69.605752\n",
      "final  value 69.605724 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.143611\n",
      "iter  20 value 70.318774\n",
      "iter  30 value 69.237508\n",
      "iter  40 value 68.852329\n",
      "iter  50 value 68.726087\n",
      "iter  60 value 68.718695\n",
      "iter  70 value 68.718248\n",
      "final  value 68.718239 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 75.983302\n",
      "iter  20 value 74.444916\n",
      "iter  30 value 74.372187\n",
      "iter  40 value 74.366572\n",
      "iter  50 value 74.364442\n",
      "final  value 74.364328 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.146660\n",
      "iter  20 value 70.324063\n",
      "iter  30 value 69.246817\n",
      "iter  40 value 68.864370\n",
      "iter  50 value 68.739189\n",
      "iter  60 value 68.731871\n",
      "iter  70 value 68.731426\n",
      "final  value 68.731418 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 81.423993\n",
      "iter  20 value 79.621990\n",
      "iter  30 value 79.528621\n",
      "iter  40 value 79.516187\n",
      "iter  50 value 79.510505\n",
      "final  value 79.510292 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 83.556311\n",
      "iter  20 value 82.152723\n",
      "iter  30 value 82.050229\n",
      "iter  40 value 82.033493\n",
      "iter  50 value 82.032022\n",
      "final  value 82.031883 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 81.426269\n",
      "iter  20 value 79.625058\n",
      "iter  30 value 79.531896\n",
      "iter  40 value 79.519555\n",
      "iter  50 value 79.513913\n",
      "final  value 79.513702 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 156.642943\n",
      "iter  20 value 144.800853\n",
      "iter  30 value 143.823042\n",
      "iter  40 value 143.792150\n",
      "iter  50 value 143.791189\n",
      "final  value 143.791140 \n",
      "converged\n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.058174\n",
      "iter  20 value 66.965548\n",
      "iter  30 value 65.207892\n",
      "iter  40 value 64.517647\n",
      "iter  50 value 64.409784\n",
      "iter  60 value 64.401478\n",
      "final  value 64.401346 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.878862\n",
      "iter  20 value 72.025173\n",
      "iter  30 value 71.871943\n",
      "iter  40 value 71.840751\n",
      "iter  50 value 71.837528\n",
      "final  value 71.837479 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 71.061206\n",
      "iter  20 value 66.972620\n",
      "iter  30 value 65.220695\n",
      "iter  40 value 64.534950\n",
      "iter  50 value 64.427711\n",
      "iter  60 value 64.419481\n",
      "final  value 64.419351 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 70.413506\n",
      "iter  20 value 68.409907\n",
      "iter  30 value 67.808355\n",
      "iter  40 value 67.536579\n",
      "iter  50 value 67.505920\n",
      "iter  60 value 67.505141\n",
      "final  value 67.505140 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 73.101244\n",
      "iter  20 value 72.052591\n",
      "iter  30 value 72.009729\n",
      "iter  40 value 72.003033\n",
      "iter  50 value 72.002005\n",
      "final  value 72.001958 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 140.622373 \n",
      "iter  10 value 70.416390\n",
      "iter  20 value 68.414474\n",
      "iter  30 value 67.814831\n",
      "iter  40 value 67.544114\n",
      "iter  50 value 67.513583\n",
      "iter  60 value 67.512807\n",
      "final  value 67.512805 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 88.031079\n",
      "iter  20 value 85.554902\n",
      "iter  30 value 85.438383\n",
      "iter  40 value 85.433350\n",
      "iter  50 value 85.433013\n",
      "final  value 85.432996 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 90.216254\n",
      "iter  20 value 88.210429\n",
      "iter  30 value 87.991599\n",
      "iter  40 value 87.964300\n",
      "iter  50 value 87.962899\n",
      "final  value 87.962879 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 142.819598 \n",
      "iter  10 value 88.033419\n",
      "iter  20 value 85.558184\n",
      "iter  30 value 85.441770\n",
      "iter  40 value 85.436746\n",
      "iter  50 value 85.436411\n",
      "final  value 85.436394 \n",
      "converged\n",
      "# weights:  141 (92 variable)\n",
      "initial  value 212.032172 \n",
      "iter  10 value 152.333361\n",
      "iter  20 value 145.259925\n",
      "iter  30 value 142.954921\n",
      "iter  40 value 142.776159\n",
      "iter  50 value 142.772510\n",
      "final  value 142.772425 \n",
      "converged\n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 122 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 50 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 50 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 50 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 50 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  92 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 24 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 61 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 61 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 30 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 50 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 50 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  92 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 24 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 61 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 61 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 30 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 181 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 46 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "21 60 50 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 50 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 181 152 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 46 39 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 120 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 101 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 122 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 60 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 65 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 43 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 66 182 153 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "16 45 38 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 44 121 102 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "22 61 51 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 52 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "14 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "34 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "36 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "17 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Outer fold train\"\n",
      "\n",
      "  1   2   3 \n",
      " 53 144  93 \n",
      "[1] \"Outer fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "13 36 23 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n",
      "[1] \"Inner fold train\"\n",
      "\n",
      " 1  2  3 \n",
      "35 96 62 \n",
      "[1] \"Inner fold test\"\n",
      "\n",
      " 1  2  3 \n",
      "18 48 31 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAQlBMVEUAAAAAv8QzMzNNTU1oaGh8fHx8rgCMjIyampqnp6eysrK9vb3HfP/Hx8fQ0NDZ2dnh4eHp6enr6+vw8PD4dm3///+bhgaxAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO2dDXuqPLNGOUVPbXt2P15f//9fPXwpQQOGMBMyZq3rep5NFecmcZYgWlpdAGAz1d4bAPAKIBKAAIgEIAAiAQiASAACIBKAAIgEIAAiAQiASAACIBKAABtFqt+//obFv6/3ejalWvy5rmYfmQlV9e+2NL/W+TT/ePenf+9VVb1/R21JXf3dlv/u5q1NmSTdb2y/gUtDGB955eGO+fIls3Eqmon+GBY/HifdWW3p5+/mkXFdlYzq1rJLzRM2Ab/10KLHmC35vE14O+WfDymLIvU/I5ICm0U6XDusPsSK9F59VO/btkObpqFO16WltQLu+W12Rj/Nvz/HqEG7eyF37+TNf3IksMDsmojkZ7NIn9VPt/TTLMWJdK4Ol0N13rYhyjTNX/0OS0trBdxzqL6GpWPUfnh81Pf9Pg2R9mOzSH/DocZH9TvM6++pec9z6tvu8n2s6s9hxpvX4Or43T/MqfHZdNbX7SCleUB1Ok8Xh9X7I5fzoXsl/2h2gMefyWNaIztuC/71nCrutv6emgO408/d4nWc15rDtoxjGVe+HQk5d04moPt53A/9tlO3elPGAu+9UuMInUM7N/a2wrCBj89Tc8tHXR0cr6eOTFedln/YwDLZLNJlOLar6+scD8fW/ZPcLZ66e/71t39c7p6mumodGA5Y+gfU08WJSO9difohpG4X+lb4N7538K53q+Ju68+47CyO4/zq9yT9tjhjGVe+iuTcOZmAjve73dDqTenmq2WYM2eEoyVu7LjCRCQ3sBHtccAj01Wn5T0bWCTbRfroju1+mmboX6Cao71GjGaq/7of/jXPQ93e89u9Kv4e+2d0LNG/wp76Z+K3qr8v52PbWc7iRKRj20afnSqf3bHNuOLfsNc43t47+Ne7Vpls66E7MfevLeEsjuNsXjFue0d3LM7K/Xa6d7oT0FPfHcSu3pRmwvtjw69OVXeEN0vc2PsVLp7nqXl5+bmc351DxcnZkemq0/KeDSyS7SL9dM9nq9PwYtUf6p3af4fn/FxX7XLXQefWG/dp6l+ihwOWU/eA7jDKWZyI1B1EDO+pujucFftazpHdzHpDlcm2Otv0eOzft8/pcntF9o7lujcY73QnwF979aY023EYxvZ7N8KbSG7s/QoXz/NUDfPm5g74ts0tz/uknu0itQd17QvtMKeHYW/w17+e9i+/790TOj43zuxfD+r6V2rnpIOzOBHpeuPv9+dxSLyt+Nvp+G9yVti33lBlsq3vzZH+v79hc2+L7gNObecOpcaxOCv3Zd073QmYRF/ufg7flHbd/hjg+nJxG2E1PgmT2MkKvufJmeDbZo0iPazqlvdtYIkIiNTujH7aV2vnubpM2/5YOU/NVKTP282fl7un8n7RfeRXfXuep7u3X/fIbm69+8ZpF/66NQ/ta62z6D7gXB9ugxzH4qx87dPHgR5v2ffnJ4M35TaO5oWi3TWehs+I70Y4GWoX+zAFs8/TzJ7wYVW3/ONclYmASN/NHv/j9s7HK9KdPO5yfWu7+jL3VD6K9NW8tfj49/cgUrtLcs/Zzazn695mIKerz+6is0J7vuEh0lnZ6dO7QYy3ndy35X8rNmUU6Txsw9k3wsn2tf8+ToGYSA/bWjACIl0aBerbc+M7ZOie+Xr4IOb2sI67k7nOW/F66dCuP7rpf5q8fW/2Ru6R3cx6vuOpjt/T7fNOZ3F8QH0eSo1jcVbu1/IM9OwbcPNifozYlEu/M/o3fELsjvBepHN/HDZdIfTQbox7WPVhVPcbWCASIjUvsuM5oY/hCe7emQ6fYn6195z6O36ro/s0vVfXTyB+2g47De9668li/+L7/fDa+X2Nv9zeazW7R/fIbma9ocpkWyePmFn8Hc4ou2Nx1ujXcu90J2Cgvn5trzko+o7YlEv/9mjwYzLC2za4sfcr+J6nZZEeVvWMarqBBSIhUvsxw7/rD80xxEd/rvS3ner6X/+5SnfO9KP7opl7+ts9DGvfPXxX9e9witpZPFbv5+Fs6+0F/Ot2VtlZsb2nds/Ezqw3VJlsa38et/uykrPojvPS9lK35I7FWbk7Pzy5052AgZ/+K0Ln5q3L+yViU1qa2tddgDvC2wS5sdMV/rzP07JID6tOy/s2sDwkRGp28dX4BYTJB7L953yfN9+quw9kP513DN/tIVn/UV/3Qj8u9h/6fTgifV3fWP1MVuxTnMP1mfWu+Z5PQeu/yaI7zkt3xtcd5Mf0cYfqfqCTCbhMQ/veW70p/bTdRumOcJwgJ9Zdod/Ax+dpWaTHVZ3y/g0sDwmRmnk9jj9MvyL0z/mqyl/7NRTn6wGX4dT5xf3h61DVw9HNuPhzuFa5PvKrzfgZ3nA4j2mtdp9T/3rOwf24rT/dd13+7hbdcV66l+HLdCzOyr+Hfj/h3DmZgOsmtiejq9P3tHLopgyDvL3hc0boTJAT66zQb+Dj8/REpMdVnfLeDSyPlzu0/Sr+M3bYg1cTqXlrUvz3J2EHXkuk21sTgLS8lkgHPmKHfXgtkQB2ApEABEAkAAEQCUAARAIQAJEABEAkAAEQCUAARAIQYJNI/5FBqo6JWAYbUcYAiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiFREqu3BSjW7JohURKrtwUo1uyaIVESq7cFKNbsmiCTK29vbDqkBIJIyiCTJ29tTk15nsOlSpZpdE0QS5O3tuUkvM9iEqVLNrgkiCYJIOqlSza4JIgmCSDqpUs2uCSJJwnsklVSpZtcEkUThrJ1GqlSza4JIRaTaHqxUs2uCSEWk2h6sVLNrgkhFpNoerFSza4JIRaTaHqxUs2uCSEWk2h6sVLNrgkhFpNoerFSza4JIRaTaHqxUs2uCSEWk2h6sVLNrgkhFpNoerFSza4JIRaTaHqxUs2sSIFLd4CzefkAkO6m2B6vT+rI8F6m+/c+9oUNmmuitl41FJId7kZxFmWmit142FpEcEOkFUm0PVrzrFVgt0nWp/c0blS0CMEi0SC0yrze8SL9sLHskB0R6gVTbgxXvegXWiuR6hEhmUm0PVrzrFUCkIlJtD1a86xVApCJSbQ9WvOsVWPHNhodPZhHJTKrtwWo0vjR8166IVNuDlWp2TRCpiFTbg5Vqdk0QqYhU24OVanZNEKmIVNuDlWp2TRBpv9RnF2VVirWXKtXsmiDSfqmIFFrGAIi0XyoihZYxACLtl4pIoWUMgEj7pSJSaBkDINJ+qYgUWsYAiLRfKiKFljEAIu2XikihZQyASPulIlJoGQMg0n6piBRaxgCItF8qIoWWMQAi7ZeKSKFlDIBI+6UiUmgZAyDSfqmIFFrGAIi0XyoihZYxACLtl4pIoWUMgEj7pSJSaBkDINJ+qYgUWsYAiLRfKiKFljEAIu2XikihZQyASPulIlJoGQO8rkhP23T33kKk0DIGQKTEIFJEGQMgUmIQKaKMARApMYgUUcYAiJQYRIooYwBESgwiRZQxACIlBpEiyhgAkRKDSBFlDIBIiUGkiDIGQKTEIFJEGQMgUmIQKaKMARApMYgUUcYAiJQYRIooYwBESgwiRZQxACIlBpEiyhgAkRKDSBFlDIBIiUGkiDIGQKTEIFJEGQMgUmIQKaKMARApMYgUUcYAiJQYRIooYwBESgwiRZQxACIlBpEiyhgAkRKDSBFlDIBIiUGkiDIGQKTEIFJEGQMgUmIQKaKMARApMYgUUcYAiJQYRIooYwBESgwiRZQxACIl5vLmQz9WPUExVarZNUGkxFze/ucRRFouYwBESgwiRZQxACIlBpEiyhgAkRKDSBFlDIBIiUGkiDIGSCDSTh2NSJNY9QTFVKlm1wSREoNIEWUMgEiJQaSIMgZApMQgUkQZAyBSYhApoowBECkxiBRRxgCIlBhEiihjAERKDCJFlDEAIiUGkSLKGACREoNIEWUMgEiJQaSIMgZApMQgUkQZAyBSYhApoowBXk2kFb/H/UIiPX88IinzciL99wFE+g8iqYNIiUGkiDIGQKTEIFJEGQMgUmIQKaKMARApMYgUUcYAiJQYRIooYwBESgwiRZQxACIlBpEiyhgAkRKDSBFlDIBIiUGkiDIGQKTEIFJEGQNsEimMN/0IJ8wjUoJUH3Pr+kTamr/x8bAZ9khKqXOx7JEiyhgAkZRSEUkuVarZNUEkpVREkkuVanZNEEkpFZHkUqWaXRNEUkpFJLlUqWbXBJGUUhFJLlWq2TVBJKXUBCKt+fvoiKQMIimlphApPBWRtEEkpVREkkuVanZNEEkpFZHkUqWaXRNEEkkNf7fi/zpRXCoi5QMiiaQikmaqVLNrgkgiqRtFikxFpHxAJKXU2fdIzqPSpSKSNoiklIpIcqlSza4JIimlIpJcqlSza4JISqmIJJcq1eyaIJJSKiLJpUo1uyaIJJK64qyd86itqYiUD4iUGESKKGMAREoMIkWUMQAiJQaRIsoYAJESg0gRZQyASIlBpIgyBkCkxCBSRBkDIFJiECmijAEQKTGIFFHGAIiUGESKKGMAREoMIkWUMQAiJUZSpBW/I7j7YDeVMQAiJQaRIsoYAJESg0gRZQyASInhPVJEGQMgUmIQKaKMARApMYgUUcYAiJQYRIooYwBESgwiRZQxgJpIcb99vRlEehqbEEQKY2nwcdcD2QwiPY1NCCKFsTR4RHqaikihZQzAoV1iECmijAEQKTGIFFHGAIiUGESKKGMA3iMlBpEiyhgAkRKDSBFlDIBIiUGkiDIGQKTECKYiUkYgUmIQKaKMARApMYgUUcYAiJQYRIooYwBESgwiRZQxACIlBpEiyhgAkRKDSBFlDIBIiUGkiDIGQKTEIFJEGQMgUmIQKaKMARApMYgUUcYAiJQYRIooYwBESgwiRZQxACIlBpEiyhgAkRKDSBFlDPByIhXyBxpaECkjECkxiBRRxgCIlBhEiihjgJcTqZDeakGkjECkxCBSRBkDIFJiECmijAEQKTGIFFHGAIiUGESKKGMAREoMIkWUMQAiJQaRIsoYAJESg0gRZQyASIlBpIgyBkCkxCBSRBkDIFJiECmijAEQKTGIFFHGAIiUGESKKGMAREoMIkWUMQAiJQaRIsoYAJESg0gRZQyASIlBpIgyBtATKfx3VREpjhVTbHuwUs2uiZpII0//5jAivWosIoURNg2ItH+q7cFKNbsmiJQYRIooYwBESgwiRZQxACIlBpEiyhgAkRKDSBFlDIBIiSlVpKddsFTGAAEi1Q2+ZUSKAZEiyhjguUj17X/T5QsixYBIEWUMgEiJQaSIMgaIEGkkbBoQaf/U/QeLSFORbu+R2u91hUUEriaDT6SU+TDDqz8LK0WqLxzabYM9UkQZA/AeKTGIFFHGAIiUGESKKGMAREoMIkWUMQAiJQaRIsoYYMU3G2pnuSdsGhBp/9T9B4tIC4RNAyLtn7r/YBFpgbBpQKT9U/cfLCItEDYNiLR/6v6DRaQFwqYBkfZP3X+wiLRA2DQg0v6p+w8WkRYImwZE2j91/8Ei0gJh04BI+6fuP1hEWiBsGhBp/9T9B4tIC4RNAyLtn7r/YBFpgbBpQKT9U/cfLCItEDYNiLR/6v6DRaQFwqYhrUiF/IEGG7GIFEbYNCQVaffYPFP3HywiLRA2DYi0f+r+g0WkBcKmAZH2T91/sIi0QNg0INL+qfsPFpEWCJsGRNo/df/BItICYdOASPun7j9YRFogbBoQaf/U/QeLSAuETQMi7Z+6/2ARaYGwaUCk/VP3HywiLRA2DfmLNP/tB3kQKaKMARBp+FqRyjYspaYFkZRBpP8sfyNPGkSKKGMAREKkJKmItEDYNCCSLzUxiKQMIvEeKUkqIi0QNg3Zi8RZuwSpiLRA2DTkL1JKECmijAEQKTGIFFHGAAlEej5PQnWm5CSSsy2IFFHGAIiUAkRCpCU2T/QwT0J1piCSCyIpg0gpQCREWmLzRA/zJFRnCiK5IJIyiJQCREKkJTZP9DBPQnWmIJILIimDSClAJERaYvNED/MkVGcKIrkgkjKIlAJEQqQlNk/0ME9CdaYgkgsiKYNIKUAkRFpi80QP8yRUZwoiuSCSMoiUAkRCpCU2T/QwT0J1piCSCyIpg0gpQCREWmLzRA/zJFRnCiK5IJIyiJQCREKkJTZP9DBPQnWmIJILIinzuiLlFItIiLTE5oke5slZTnddrMJEevOhnjouItICmyd6mCdnGZF0uLz9zyOIJAcipQCREGmJzRM9zJOzjEg67CSSzAGlVLNrgkgpKFckkVSpZtcEkVKASIi0hNR0O8uIpAMiKYNIKdhHJHcuEUkZREoBIiHSElLT7Swjkkrqq4p0rg7D0qH6e+jtyv9TNdf056/3ujp+TW/8qoNcQKQUIJLWHuk4+PNXHR97e6VIv3XVUZ/nq8yCSClAJC2R/lWf3b+f1b9nnf5UpEN1ahT6O1Yf/sctlw9aawap6XaWEUkl9WVFuh7bHarGgZ/3Znfy0TX/b33sFXBuu7xXx7+rGudT1XnjulANJd37211UiAuIlAJE0hKpkaN1ozuy++6PzD7a7j9Wp04M97b34bCtM6M7jDvclfoef7jej0irYpVBJDWRvrtju+7I7tD+77ft+86cThj3tuP5cuyVah/QLHxUkxMLf3V1+PjXv+ca7+fQbk2sMoikJtKl2610R3aNCt+fx16a2yHc9La/fifTPqB77Puk1Pnz0O6Gfi7u/Yi0JlYZRNIT6dQI8tcbceyP467N3/3fc1v/3/X2Kb8fp2O7ExvvR6Q1sSp4v/qMSMIitcd2n927m1N1+Pr+m0rju21JpG6dGpFiY1V4+99HEEn8mw3N0dph3AOdH6W53vZ4aHdXqD8+vLsfkdbEqoBISUQ6Vd/VqW/5n8v5eC/SeNuxXfrsb/9oTyb8m36K+1Edm7dH54/2OHG8H5HWxKqASElEas9wf/ciPL4fcm9zT3+f+28x/E4qHYZvNvy591dV0HeEEEkPRErzpdX6utM4NXudn7uTDe5t79X77WzeX3fHXaWvY/vpbX8C8Hr/FyKtiFUBkfj2dxhS0+0sI5JgvrOMSMogkh6IZECkqhrPdG+qs+XBUtPtLCOSYL6zjEgzIJJorAqIZEAkKRBJD0RCpDCkpttZRiTBfGcZkZRBJD0QCZHCkJpuZxmRBPOdZURSBpH0QCRECkNqup1lRBLMd5ZfVaTYx4mDSHogEiKFETu/9+N1lhFJMN9ZRiRlEEkPREou0lvo48TZ+MUIcd723gBB/CIlzJ/84Gtp/U3QTn0NkVa/tMy84MzOhCrskdgjyYFIeiBSuSIdPu9/aXCJDVM8Ge/sTKiCSC8ikvdqTe2fqo0RIpY7kdrfWD99+1d9RGq6/VMhVH0hVhlESiTSf33sK9L5X3uFiOr47+GPzfiQmu7/7P2363VApHJFavn+aK+gcgjYL0lNNyLp5DvLiKR8htpX/K+/htHjX266R2q6EUkn31lGpEmvyzv1WPH3vdsd/RzvrjDuQWq6EUkn31lGpMQifR9vR3XPf4tdaroRSSffWS5dpPaaDNXl+ueO3P8LcX/6u6rer1effH5hPKnpRiSdfGf5pUV6fvq7d2ho9+Hf67IM96e/P37963mRmm5E0sl3ll9apOd7pIk0ldP2WiKd/WvNIDXdiKST7yw/a2mdz+0yFGk4qruMyzLcF3rv0w58jrQdQyIpfQKen0jDf5OfRbgr9HG9/Pgp5MFS041IOvnO8nJLa32XJDuRkr1Hqqvuu3a/Ybs8qelGJJ18ZxmRbicbKkcktUO7a2FEEgCRshHJPf196c98j7eJcFfovTqduz9a9vxrDRdEekIykWYcKOY9Uobf/v6rhz9aFnQWXGq6EWlbzowFpZy1c8jm95GandGhqg4fQSftEGmZRCLNHpeV8jmSQz4irWLDFE/Gi0ibYhDpBiIhUnwMIt3IR6SPNX92acMUT8aLSNtyBN4j6VDude1uHiHSdgydtVOiXJHq6vdY/Z2PVdA1UGLn9368iKST7ywjkjKPH8h+Vt+XM58jCYBIRYv0XX3xzQYREKlckd6rf3/V4fKDSALsI5L/U/5CRMrmrF1r0LE918C3v7ezk0i+VETS5uGaDYfL5VRVH0EP3jDFk/HuJJL2ZSkRqWCRVrFhiifj3Usk5VREKlekY9Ah3ZUNUzwZLyJppyKSNg+fI6158IYpnowXkbRTX1qkHH+N4vcY+MXvDqnpRiTt1NcWyTPidsw7/zWKcr4ihEja24JIiCQAIuUlUvKL6AcjNd2IJJla3AeyESKluIj+CqSmG5EkUxEpA5E4tBMMQKR8RAq5iP7kIqwh/T958N2PiCQH75GyOf0dchH9h/tW4X3E3/Ez6MFS073T35AtSyTDU/ykBQP2SCEX0XcuYxxx5Od/yLkKMklquhFJOxWRbv+bvYj+eCQW8w5q5jGpD+0MP8vzIFJ+Ii1cRL/yLIXjf8y/539krEVqunmPpJ362u+RwkV6+h6pX9h+aHc71xD0exRS041I2qmI9Pwi+qInGwaN6jJ+HwmRlMlGpKCL6Eue/l6H1HQjknbqa4vkh1/ss/Usz4NI5f4+UlF/+hKRtLfFgkhrvoGwVGb6Y1F/+hKRtLfFgkhCPPyGbEF/+hKRtLelXJGK+tOXiKS9LSVfILKgP32JSNrbUq5IRf3pS0TS3pZyRSrqT19qf/0MkQoWaRWx83s/3lcVyQciIdIDsfN7P15EkkwtWaRsztrxgaxgACKVKxIfyAoG8B6pXJH4QFYwAJHKFYkPZAUDEKlckfhAVjAAkcr9NQo+kBUMQKREInlCupgNXqym6A9kEUmZgkVahdR0I5LzoK0fZSHSnEhcRF+HLEXa/qEwIgWIlOoi+j8fXI5rOxEiCXy9ApFyEen7VFepr2un/GUdfywibckJIR+Rwi+i/3C9uzDuH/B9asudvoMeLDXdQnXWxqp/1w6Rcjn9vfYi+htF6i2qqnPgg6WmW6hOfKxOR/EeKZs90pqL6G8XadgXhV9QRWq6herEx+YjEmftfGWWW3CVSAsX0R/+JyHS+/kS+vWg6ygkpluoTnxsRiLppCYUyX0lyE+kZxfRZ4+0KRaR5OLdY9PsROI9kgKIpDDs6dmSrERadRF9qbN2P0EPFpp8RFJP1RHJ8/hMRVpxEf3H24PI43OkXUCkVxEpw29/D6T+ZsMuIJKCSHu8R5rdohghYsnju3a7gEgaIu1w1m52i8IMULmI/jpWz8jMPAnViY9FpLioZytYEEkIRGpBpLioZytwXbswVs/IzHiF6sTHIlJc1LMVECmM1TMyM16hOvGxiBQX9WwFRApj9YzMjFeoTnwsIsVFPVsBkcJYPSMz4xWqEx+LSHFRz1ZApDBWz8jMeIXqxMe+lEjeDycRSRlEanklkfwUIhKnv3cAkRBJDkRqQaQoEGkEkVoQKQpEGgkQqW5wl8fvs66ekZl5EqoTH4tIUWQiUsbf/napb/9z/u2JmHvvPAnViY9FpChyEen/fCBSKhAJkeRYJ9LdbylFzL13noTqxMciUhQBIvmPuVay0J3dZhgUaXyL1M6I2la9Bn6R9toYn0j+Rn9WacVj/OvGpM6wRqSdL6L/sEd6wZMNOhjYI/l68Nke4+2/j8w8ZmaPtDZ1oTu7DVovUqqL6LvcyYNIwSCSUOpCd3YbhEjDPAnVyS0WkfIRactF9CcXZ53bEA7t9ECkRCL5mbuu3doLRD48xst6kZydU9xz+jhPQnVyi0WkbPZIWy6i71zeeMGWFd9sqJ3lcRQCIJI+iBR9Ef3xIkNLsvBdOz0QKT+RIi6iX3mWHkEkPRApO5Gi3yP1C9sO7ZZHIQAi6YNI0RfRlzrZ8GQUAiCSPoWLtOki+kKnv5+MQgBE0uelRXp++lsfRNIDkeZS/X0/v/HBLZj1L/bN8+zZCwSR9BH61luLwHftchJp7iL6Ky+uj0h6ZCWSs1nOzdoizaSu84g9UiD795YOiPT0V77CfjcptgW39PZaEEkPREKkMIJmIWCehOrkFotIiBRG0CwEzJNQndxiEUlfpGzYTSRnCvfvLR0QCZHCCJqFGRApKYikDCLpgUiIFEbQLMyASElBJGUQSQ9EQqQwgmZhBkRKCiIpg0h6WBBp7bd1/oNIfhBpns1X9M1TJJe9RQpDqtk1QaR5ChXpWSlE8oFI8xQg0kj4YBHJByLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNg0j+NRHJAyLNs1kkH/YH6xfp2WARaYENc1OCSN5K9gc7I9KT3S8iLbBhbl6rt1ZUsj9YRPKBSPMgkn9NRPKASPMgkn9NRPKASPMgkn9NRPKASPMUJVI4iOSjMJHcC4kiUhyI5KMskSaX5EWkOBDJR1EiTS9ujUhx+C+8zweyG9j0dDjztKXOqkxEEgCRfCDSwupywePia4r0/PtQiLTApqfDmactddaFOh4h0mbcCeI90sUqluYAAA0LSURBVAY2zA1n7dKCSMoUJpILIm0FkUYQaR5EegIijSDSPIj0BEQaQaR5EOkJiDSCSPMg0hMQaQSR5kGkJyDSCCLNg0hPQKQRRJoHkZ6ASCOINA8iPQGRRhBpHkR6AiKNINI8iPQERBpBpHkQ6QmINIJI8yDSExBpBJHmQaQnINIIIs2DSE9ApBFEmgeRnoBII4g0DyI9AZFGEGkeRHoCIo3YEEmupR2yEsl/aR45dhdpC1LNrgkipUgNEOn/HkGkAalm1wSRUqQi0iakml0TREqRikibkGp2TRApRSoibUKq2TVBpBSpiLQJqWbXBJFSpCLSJqSaXRNEyiPVvkhPrv29Balm1wSR8kg1L5L3VkQKY8vkINI0C5HmkWp2TRApj1REWkCq2TVBpDxSEWkBqWbXBJHySEWkBaSaXRNEyiMVkRaQanZNECmPVERaQKrZNdkk0hbe1FYWI2WqV6SE+VH4NzD7zVaBPVIeqeyRFpBqdk0QKY9URFpAqtk1QaQ8UhFpAalm1wSR8khFpAWkml0TRMojFZEWkGp2TRApj1REWkCq2TVBpDxSEWkBqWbXBJHySEWkBaSaXZPEIkX++hciKcVuA5FGUosU9wvJBYhk/QKR3lsRKYz1U7JKJOXm2qelX0kkP4i0mohJXiWS7uHOPgdZK0SSC0UkdRApj1RtEEkZRMojVRtEUgaR8kjVBpGUQaQ8UrVBJGUQKY9UbRBJGUTKI1UbRFIGkfJI1QaRlEGkPFK1QSRlECmPVG0QSRlEyiNVG0RSBpHySNUGkZRBpDxStUEkZRApj1RtEEkZRMojVRtEUgaR8kjVZp9YRApj/ZQgEiJFlDFAGSKtuVQEImWXKtXsmhQi0opYRMouVarZNUEkvVQviBRRxgCIpJfqBZEiyhgAkfRSvSBSRBkDIJJeqhdEiihjAETSS/WCSBFlDIBIeqleECmijAEQSS/VCyJFlDEAIumlekGkiDIGQCS9VC+IFFHGAIikl+oFkSLKGACR9FK9IFJEGQMgkl6qF0SKKGMARNJL9YJIEWUMkPOfvkQk67GIFMb6KUEkRIooYwBECtrEqFQviBRRxgC8R3pYF5FyS5Vqdk0Q6WFdRMotVarZNUEkvVQviBRRxgCIpJfqBZEiyhgAkfRSvSBSRBkDIJJeqhdEiihjAETSS/WCSBFlDIBIeqleECmijAEKEWnF58CIlF2qVLNrgkh6qV4QKaKMARBJL9ULIkWUMUAhIvEeyXKqVLNrgkh6qV4QKaKMARBJL9ULIkWUMQAi6aV6QaSIMgZAJL1UL4gUUcYAiKSX6gWRIsoYAJH0Ur0gUkQZAyCSXqoXRIooYwBE0kv1gkgRZQxQiEh8s8FyqlSza1KGSF4QyUqqVLNrgkh5pGqDSMogUh6p2iCSMmVcINILIllJlWp2TRKLNOL0JiLpg0jKIFIeqdogkjKIlEeqNoikDCLlkaoNIimDSHmkaoNIyiBSHqnaIJIyiJRHqjaIpAwi5ZGqDSIpg0h5pGqDSMogUh6p2iCSMoiUR6o2iKQMIuWRqg0iKYNIeaRqg0jKIFIeqdogkjK7ieTO08ztiGQ9FpHCkJkmREoAIimDSHmkaoNIygSIVDe4P46LMtOESAlAJGWei1Tf/tf/iEgaqdogkjJrRarZI6mkaoNIyqwUqebQTidVG0RSJlqk7vI/unhbWjlzr1QwzjqR6gt7JJ1UbdgjKbNKpLvzDogkl6oNIimzTqSe210y04RICUAkZVaf/maPpJKqDSIpg0h5pGqDSMqs+GaDc8JhQGaaECkBiKQM37XLI1UbRFIGkfJI1QaRlEGkPFK1QSRlECmPVG0QSRlEyiNVG0RSBpHySNUGkZRBpDxStUEkZRApj1RtEEkZRMojVRtEUgaR8kjVBpGUQaQ8UrVBJGUQKY9UbRBJGUTKI1UbRFIma5F8CGXOxyJSdqlSza4JIuWRqg0iKYNI8whmrUjVAZGUyVqknQ+yECmTVKlm1wSR5kGkTFKlml0TRJoHkTJJlWp2TRBpHkTKJFWq2TVBpHkQKZNUqWbXBJHmQaRMUqWaXRNEmgeRMkmVanZNEGkeRMokVarZNUGkeRApk1SpZtcEkeZBpExSpZpdE0SaB5EySZVqdk0QaR5EyiRVqtk1QaR5ECmTVKlm1wSR5kGkTFKlml0TRJoHkTJJlWp2TRBpHkTKJFWq2TVBpHkQKZNUqWbXBJHmQaRMUqWaXRNEmgeRMkmVanZNEGkeRMokVarZNUGkeRApk1SpZtcEkeZBpExSpZpdE0SaB5EySZVqdk0QaR5EyiRVqtk1yVokLhBpPBaRwpCZpoDp3qelESmTVKlm1wSRckvVAZGUQaTcUnVAJGUQKbdUHRBJGUTKLVUHRFIGkXJL1QGRlEGk3FJ1QCRlECm3VB0QSRlEyi1VB0RSBpFyS9UBkZRBpNxSdUAkZRApt1QdEEkZRMotVQdEUgaRckvVAZGUQaTcUnVAJGUQKbdUHRBJGUTKLVUHRFIGkXJL1QGRlEGk3FJ1QCRlECm3VB0QSRlEyi1VB0RSBpFyS9UBkZRBpNxSdUAkZRApt1QdEEkZRMotVQdEUgaREoNIEWUMgEiJQaSIMgZApMQgUkQZAyBSYhApoowBECkxiBRRxgCIlBhEiihjAERKDCJFlDEAIiUGkSLKGACREoNIEWUMYEMkFUz3lo1YRApDZprorZeNRaQwZKaJ3nrZWEQKQ2aa6K2XjUWkMGSmid562VhECkNmmuitl41FpDBkponeetlYRApDZprorZeNRaQwZKaJ3nrZWEQKQ2aa6K2XjUWkMGSmid562VhECkNmmuitl41FJABYA3ukIlJtD1aq2TVBpMxS3974nZGHMgZApLxS3950TMpysMFlDIBIWaW+vSmZlONgw8sYAJGySkUkbxkDIFJWqYjkLWMARMorlfdIvjIGQKTMUjlr5yljAEQqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdE0QqItX2YKWaXRNEKiLV9mClml0TRCoi1fZgpZpdk00iCfFWUiyDfU0QqYjUsga7B4hURGpZg90DRCoitazB7kEOIgGYB5EABEAkAAEQCUAARAIQAJEABNhRpPru38S5yrHz5VOP9xq7U24hlCnSrj21T/juGu2+AbogUnIQ6RXZWaS6OeAY/tWY6LoL6P/XP5P1cGN9W7qM8ZPV46LcWpdr4LTg3ZoPq4nPRT/gNId2bZZ/XhNtwF7sK1Lv0Njj4hH17X+uSJfrLff3uKtHRU107W9/GNzdmveryc9F5Ig2ZHnnNc0G7MX+Imke4tXu/zwiPd4T3cj3Q3lMWVjzYSNE0XqZWs66GyEiqTHtXJU9/y4i3Y7Ybvu96eA8a05WE5+IHUVyjl4RSQt3hpX2/XuI5NSuveN6GPTDauLvkTxbocR0Cmf2ya9IHiJpzfQOIrn/LovktNvDaqJzsZtI2k9vTuwvUu38qxBx19pJRKofa93vb9xBOyKpdF16ke5GiEiq9NNcT/5ViHBe+a8nvZ2l2z31w+qRUfe1L/fv/9yTw77VFE5/X5L18ZA1HeFt+YXhu3YZ8God9mrjCQGRMuDVGu/VxhMCIqWirmc+3n+9Q56XG1AAiAQgACIBCIBIAAIgEoAAiAQgACIBCIBIAAIgkhL1+9dft/D39e75XKWq5n8Cg/AMKlFV1albOFU+TRDpxeAZVKKqDsN3UQ+IVAA8g0pU1Wf10/z70/zbTvJfs2c6dQd7f8fqvVfn3N52viDSC8AzqERVNQo1/zY6tZqc6+YIr6rPw9J7p0532+GCSC8Az6ASjRt168ih6jT5qI6Xy7H66JfOx/a2z/7HL0R6AXgGlWjcOFV/l7/q1GlyaJabHw63pe62bsV3RHoBeAaVaNz4bnY2X9W/TpNelfulHkR6AXgGlWjcODcHccfqjEglwDOoROtGY1H71mj50O66MpiGZ1CJ1o2v6r09czc92fBZHc+XY39b8+O/q2pgGp5BJVo3mv1O9dsv+k5/97dd1wDT8AwqMXxQVF8XnQ9k368fyLa3HX8uiPQC8AwCCIBIAAIgEoAAiAQgACIBCIBIAAIgEoAAiAQgACIBCIBIAAIgEoAAiAQgwP8DTGarD3AGwAIAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define outer and inner folds\n",
    "outer_folds <- 5\n",
    "inner_folds <- 3\n",
    "\n",
    "classification_methods <- c(\"multinom\", \"naive_bayes\", \"lda\", \"rpart\", \"rf\")\n",
    "\n",
    "evaluate_model <- function(model, test_data, true_labels) {\n",
    "  predictions <- predict(model, newdata = test_data)\n",
    "  \n",
    "  levels <- levels(true_labels)\n",
    "  metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), lev = levels)\n",
    "  \n",
    "  return(list(\n",
    "    Accuracy = metrics[\"Accuracy\"],\n",
    "    Sensitivity = metrics[\"Mean_Sensitivity\"],\n",
    "    Specificity = metrics[\"Mean_Specificity\"]\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Function to apply sampling techniques\n",
    "sample_data <- function(data, method = \"none\") {\n",
    "  if (method == \"smote\") {\n",
    "    data_balanced <- SmoteClassif(y ~ ., dat = data, C.perc = \"balance\")\n",
    "  } else if (method == \"up\") {\n",
    "    data_balanced <- RandOverClassif(y ~ ., dat = data, C.perc = \"balance\")\n",
    "  } else if (method == \"down\") {\n",
    "    data_balanced <- RandUnderClassif(y ~ ., dat = data, C.perc = \"balance\")\n",
    "  } else {\n",
    "    # No sampling\n",
    "    data_balanced <- data\n",
    "  }\n",
    "  return(data_balanced)\n",
    "}\n",
    "\n",
    "sampling_methods <- c(\"none\", \"up\", \"down\", \"smote\") # Add your sampling methods here\n",
    "\n",
    "results <- data.frame(Model = character(), Variable_Set = character(), Sampling_Method = character(), Fold = integer(),\n",
    "                      Accuracy = numeric(), Sensitivity = numeric(), Specificity = numeric(), F1 = numeric(), row.names = NULL)\n",
    "\n",
    "for (method in classification_methods) {\n",
    "  for (variable_set in c(\"data\", \"data_ex\", \"data_ou\", \"data_ou_ex\")) {\n",
    "    \n",
    "    data_set <- switch(variable_set,\n",
    "                       \"data\" = data,\n",
    "                       \"data_ex\" = data_excluded,\n",
    "                       \"data_ou\" = data_outlier,\n",
    "                       \"data_ou_ex\" = data_outlier_excluded)\n",
    "    \n",
    "    for (sampling_method in sampling_methods) {\n",
    "      sampled_data_set <- sample_data(data_set, method = sampling_method)\n",
    "      \n",
    "      for (outer_fold in 1:outer_folds) {\n",
    "        outer_train_index <- createFolds(sampled_data_set$y, k = outer_folds, list = TRUE, returnTrain = TRUE)[[outer_fold]]\n",
    "        outer_train_data <- sampled_data_set[outer_train_index, ]\n",
    "        outer_test_data <- sampled_data_set[-outer_train_index, ]\n",
    "        \n",
    "        best_inner_model <- NULL\n",
    "        best_inner_accuracy <- 0\n",
    "        \n",
    "        for (inner_fold in 1:inner_folds) {\n",
    "          inner_train_index <- createFolds(outer_train_data$y, k = inner_folds, list = TRUE, returnTrain = TRUE)[[inner_fold]]\n",
    "          inner_train_data <- outer_train_data[inner_train_index, ]\n",
    "          inner_val_data <- outer_train_data[-inner_train_index, ]\n",
    "          \n",
    "          model <- train(y ~ ., data = inner_train_data, method = method, trControl = trainControl(method = \"cv\", number = inner_folds), metric = \"Accuracy\")\n",
    "          \n",
    "          val_pred <- predict(model, newdata = inner_val_data)\n",
    "          val_accuracy <- mean(val_pred == inner_val_data$y)\n",
    "          \n",
    "          if (val_accuracy > best_inner_accuracy) {\n",
    "            best_inner_model <- model\n",
    "            best_inner_accuracy <- val_accuracy\n",
    "          }\n",
    "        }\n",
    "        \n",
    "        outer_metrics <- evaluate_model(best_inner_model, outer_test_data, outer_test_data$y)\n",
    "        \n",
    "        results <- rbind(results, data.frame(Model = method, Variable_Set = variable_set, Sampling_Method = sampling_method, Fold = outer_fold,\n",
    "                                             Accuracy = outer_metrics$Accuracy,\n",
    "                                             Sensitivity = outer_metrics$Sensitivity,\n",
    "                                             Specificity = outer_metrics$Specificity, row.names = NULL))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Plot results\n",
    "ggplot(results, aes(x = Model, y = Accuracy, fill = Variable_Set)) +\n",
    "  geom_boxplot() +\n",
    "  facet_wrap(~ Sampling_Method) +\n",
    "  labs(title = \"Model Accuracy across Nested Cross-Validation Folds\",\n",
    "       x = \"Model\", y = \"Accuracy\")\n",
    "\n",
    "ggplot(results, aes(x = Model, y = Sensitivity, fill = Variable_Set)) +\n",
    "  geom_boxplot() +\n",
    "  facet_wrap(~ Sampling_Method) +\n",
    "  labs(title = \"Model Sensitivity across Nested Cross-Validation Folds\",\n",
    "       x = \"Model\", y = \"Sensitivity\")\n",
    "\n",
    "ggplot(results, aes(x = Model, y = Specificity, fill = Variable_Set)) +\n",
    "  geom_boxplot() +\n",
    "  facet_wrap(~ Sampling_Method) +\n",
    "  labs(title = \"Model Specificity across Nested Cross-Validation Folds\",\n",
    "       x = \"Model\", y = \"Specificity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Sampling method\"\n",
      "[1] \"none\"\n",
      "[1] \"Sampled data\"\n",
      "          X1           X2         X3         X4          X5         X6\n",
      "1  0.1520951 -0.001077043  1.3232418  0.4829507  1.18447294  0.3128938\n",
      "2  1.4828231 -1.320965483  0.8605130 -1.5410116 -1.19194583  1.0559602\n",
      "3  1.6973454  1.575098487 -0.9227483  0.8383256 -0.71254470 -0.2796727\n",
      "4 -1.1266522  1.213395380 -1.6323412  1.3704219 -0.77110979  0.5366186\n",
      "5  0.7427705  0.319138772 -1.4308311 -0.7153544 -1.43298490 -1.2511355\n",
      "6  1.0272638 -1.549598214 -1.3811201 -0.1612517  0.06608898  0.3763517\n",
      "          X7         X8         X9        X10         X11        X12\n",
      "1 -1.0309908 -1.1270022  1.0249860  1.4966017  0.11115773  0.8332604\n",
      "2 -0.9621786  1.0931273  1.2423460 -0.2570111  0.12281814  0.4889229\n",
      "3 -0.9251125 -0.5612810 -0.8580621  0.6826289 -1.20773705 -0.8165060\n",
      "4  1.6303239  0.4889026  0.4843326 -1.2531756  0.80254853  1.2836441\n",
      "5 -0.3360766  0.1892026  1.5472019  0.4840599 -0.03292476 -1.1545984\n",
      "6  0.7836426  0.3381814 -0.3515586 -0.3020698 -0.33811617  0.8372291\n",
      "          X13        X14         X15        X16        X17        X18\n",
      "1 -1.64909774 -1.6698796 -1.17241906  1.3357247  0.6106323  1.1375343\n",
      "2 -0.98034558 -1.5150755  1.22718114  0.3439252  1.0735877 -1.1905924\n",
      "3  0.07923653 -0.1799781 -0.06042082 -1.5576947  1.0805082  0.3051988\n",
      "4 -0.27838730 -0.4339457 -0.80721833  1.2026341 -1.6428891  0.6161562\n",
      "5 -1.04832424 -0.3836900 -1.50577354 -0.8795804  1.1814772 -1.7787277\n",
      "6 -1.03104179 -1.4205234  0.14042984  1.3165438  1.1324787  1.4639798\n",
      "          X19        X20        X21        X22        X23        X24        X25\n",
      "1 -0.35021859 -0.6418293 -1.9481336  0.6626811  1.0409441 -0.1706564  1.2654018\n",
      "2  0.05873767 -1.6046896  0.6014965  0.7149596 -1.0322204  0.9540324  0.4621475\n",
      "3 -0.40066757  0.7194948  2.5149911  1.5144055 -0.2564052  3.6133973  0.5778135\n",
      "4  0.22121874  0.7573599 -1.4160092 -0.5344183  0.1980008  0.8366899  0.6778158\n",
      "5  1.54868173 -1.0635129  0.1819618  0.2086752  0.3007170 -0.6310749 -0.5900218\n",
      "6  0.94848366 -1.7038345 -0.6540901 -0.8875494 -0.3419897  1.3266713  0.7132874\n",
      "         X26        X27          X28        X29         X30        X31\n",
      "1 -0.1278522  1.3351301 -0.240681517  1.7627004  0.01249865 -0.4249263\n",
      "2 -0.4799549  0.8389367 -0.451670855 -0.7720648  0.30479871 -0.9833008\n",
      "3  0.5670421  3.4968728  1.779625131  0.1153830  0.89190986 -1.8679981\n",
      "4  0.1023178 -1.4642701 -0.005317279 -1.1669568  1.08900673 -0.1962917\n",
      "5  0.2939318 -0.8476116  1.376821471  0.7596974 -1.53934791 -0.2661868\n",
      "6 -2.0187590  1.2892859 -1.163639587 -0.7424875 -0.86238200 -0.7945049\n",
      "          X32         X33        X34         X35        X36        X37\n",
      "1  2.06695932  0.77821695  1.2148748  1.15531280 -1.5573339  0.8815981\n",
      "2 -0.15895022 -0.35567345  0.3285720 -0.44718433 -0.6082948  1.0511136\n",
      "3  0.06309005  1.10183103 -2.8132440  1.22092848  1.6071860 -0.9056308\n",
      "4  0.70717687 -0.85255089  1.5121732 -0.02694163  0.5981125 -1.0750609\n",
      "5 -0.02631496 -0.78761679 -0.9226999 -0.65951028 -0.7911296 -0.2617080\n",
      "6 -0.45030731 -0.07875655 -1.3467341 -1.60617054 -0.9431196 -0.1084342\n",
      "         X38        X39        X40        X41         X42        X43        X44\n",
      "1 -0.6394869  0.6380977 -1.6566505 -0.5418631  0.40937804 -1.5643242  1.0974111\n",
      "2 -0.3454285  0.6778171  1.4379336 -0.3934808  0.81012744  0.7327486 -1.1152622\n",
      "3 -0.2376972  1.2335260 -4.9447665  1.7986084  1.71936530  2.3700186 -0.9275773\n",
      "4 -0.9242505 -0.2389173  0.3000153  0.5086487  0.97816371 -0.8756930  0.8775897\n",
      "5 -0.4926752 -0.6460023  0.9914571 -1.2751424 -0.03364256 -1.7740909 -0.1428675\n",
      "6 -0.1853594  1.2031359 -0.3653933  0.3609107  0.94416615  2.2211546  0.8479884\n",
      "         X45 y\n",
      "1  0.4185625 2\n",
      "2 -0.4685141 2\n",
      "3 -2.1348492 3\n",
      "4  2.6115839 2\n",
      "5  2.6379144 1\n",
      "6  0.3610012 3\n",
      "\n",
      "  1   2   3 \n",
      " 82 227 191 \n",
      "[1] \"Sampling method\"\n",
      "[1] \"up\"\n",
      "[1] \"Sampled data\"\n",
      "          X1           X2         X3         X4          X5         X6\n",
      "1  0.1520951 -0.001077043  1.3232418  0.4829507  1.18447294  0.3128938\n",
      "2  1.4828231 -1.320965483  0.8605130 -1.5410116 -1.19194583  1.0559602\n",
      "3  1.6973454  1.575098487 -0.9227483  0.8383256 -0.71254470 -0.2796727\n",
      "4 -1.1266522  1.213395380 -1.6323412  1.3704219 -0.77110979  0.5366186\n",
      "5  0.7427705  0.319138772 -1.4308311 -0.7153544 -1.43298490 -1.2511355\n",
      "6  1.0272638 -1.549598214 -1.3811201 -0.1612517  0.06608898  0.3763517\n",
      "          X7         X8         X9        X10         X11        X12\n",
      "1 -1.0309908 -1.1270022  1.0249860  1.4966017  0.11115773  0.8332604\n",
      "2 -0.9621786  1.0931273  1.2423460 -0.2570111  0.12281814  0.4889229\n",
      "3 -0.9251125 -0.5612810 -0.8580621  0.6826289 -1.20773705 -0.8165060\n",
      "4  1.6303239  0.4889026  0.4843326 -1.2531756  0.80254853  1.2836441\n",
      "5 -0.3360766  0.1892026  1.5472019  0.4840599 -0.03292476 -1.1545984\n",
      "6  0.7836426  0.3381814 -0.3515586 -0.3020698 -0.33811617  0.8372291\n",
      "          X13        X14         X15        X16        X17        X18\n",
      "1 -1.64909774 -1.6698796 -1.17241906  1.3357247  0.6106323  1.1375343\n",
      "2 -0.98034558 -1.5150755  1.22718114  0.3439252  1.0735877 -1.1905924\n",
      "3  0.07923653 -0.1799781 -0.06042082 -1.5576947  1.0805082  0.3051988\n",
      "4 -0.27838730 -0.4339457 -0.80721833  1.2026341 -1.6428891  0.6161562\n",
      "5 -1.04832424 -0.3836900 -1.50577354 -0.8795804  1.1814772 -1.7787277\n",
      "6 -1.03104179 -1.4205234  0.14042984  1.3165438  1.1324787  1.4639798\n",
      "          X19        X20        X21        X22        X23        X24        X25\n",
      "1 -0.35021859 -0.6418293 -1.9481336  0.6626811  1.0409441 -0.1706564  1.2654018\n",
      "2  0.05873767 -1.6046896  0.6014965  0.7149596 -1.0322204  0.9540324  0.4621475\n",
      "3 -0.40066757  0.7194948  2.5149911  1.5144055 -0.2564052  3.6133973  0.5778135\n",
      "4  0.22121874  0.7573599 -1.4160092 -0.5344183  0.1980008  0.8366899  0.6778158\n",
      "5  1.54868173 -1.0635129  0.1819618  0.2086752  0.3007170 -0.6310749 -0.5900218\n",
      "6  0.94848366 -1.7038345 -0.6540901 -0.8875494 -0.3419897  1.3266713  0.7132874\n",
      "         X26        X27          X28        X29         X30        X31\n",
      "1 -0.1278522  1.3351301 -0.240681517  1.7627004  0.01249865 -0.4249263\n",
      "2 -0.4799549  0.8389367 -0.451670855 -0.7720648  0.30479871 -0.9833008\n",
      "3  0.5670421  3.4968728  1.779625131  0.1153830  0.89190986 -1.8679981\n",
      "4  0.1023178 -1.4642701 -0.005317279 -1.1669568  1.08900673 -0.1962917\n",
      "5  0.2939318 -0.8476116  1.376821471  0.7596974 -1.53934791 -0.2661868\n",
      "6 -2.0187590  1.2892859 -1.163639587 -0.7424875 -0.86238200 -0.7945049\n",
      "          X32         X33        X34         X35        X36        X37\n",
      "1  2.06695932  0.77821695  1.2148748  1.15531280 -1.5573339  0.8815981\n",
      "2 -0.15895022 -0.35567345  0.3285720 -0.44718433 -0.6082948  1.0511136\n",
      "3  0.06309005  1.10183103 -2.8132440  1.22092848  1.6071860 -0.9056308\n",
      "4  0.70717687 -0.85255089  1.5121732 -0.02694163  0.5981125 -1.0750609\n",
      "5 -0.02631496 -0.78761679 -0.9226999 -0.65951028 -0.7911296 -0.2617080\n",
      "6 -0.45030731 -0.07875655 -1.3467341 -1.60617054 -0.9431196 -0.1084342\n",
      "         X38        X39        X40        X41         X42        X43        X44\n",
      "1 -0.6394869  0.6380977 -1.6566505 -0.5418631  0.40937804 -1.5643242  1.0974111\n",
      "2 -0.3454285  0.6778171  1.4379336 -0.3934808  0.81012744  0.7327486 -1.1152622\n",
      "3 -0.2376972  1.2335260 -4.9447665  1.7986084  1.71936530  2.3700186 -0.9275773\n",
      "4 -0.9242505 -0.2389173  0.3000153  0.5086487  0.97816371 -0.8756930  0.8775897\n",
      "5 -0.4926752 -0.6460023  0.9914571 -1.2751424 -0.03364256 -1.7740909 -0.1428675\n",
      "6 -0.1853594  1.2031359 -0.3653933  0.3609107  0.94416615  2.2211546  0.8479884\n",
      "         X45 y\n",
      "1  0.4185625 2\n",
      "2 -0.4685141 2\n",
      "3 -2.1348492 3\n",
      "4  2.6115839 2\n",
      "5  2.6379144 1\n",
      "6  0.3610012 3\n",
      "\n",
      "  1   2   3 \n",
      "227 227 227 \n",
      "[1] \"Sampling method\"\n",
      "[1] \"down\"\n",
      "[1] \"Sampled data\"\n",
      "           X1         X2         X3         X4         X5          X6\n",
      "5   0.7427705  0.3191388 -1.4308311 -0.7153544 -1.4329849 -1.25113546\n",
      "12 -1.0716087  1.0622222  1.3091992 -1.1122415  0.5394862  1.35886995\n",
      "28 -1.6369234  1.4145648 -0.3831343  1.7323990  0.2858444 -0.89370659\n",
      "36  1.1760513 -0.8761364 -0.2987461 -0.8097669  1.1676841  1.64231987\n",
      "46  0.5807248  1.5910924  0.5074666 -0.9319667 -1.3146697 -0.09616436\n",
      "56 -1.1898720  1.6314989 -1.2920908  1.5578043  0.6666921  0.50088299\n",
      "           X7         X8         X9        X10          X11        X12\n",
      "5  -0.3360766  0.1892026  1.5472019  0.4840599 -0.032924760 -1.1545984\n",
      "12 -1.2845077 -1.0202261 -1.2511126  0.9609324  1.697584229 -0.4579920\n",
      "28  0.8444403  0.1278901  1.0961120  0.7281197 -0.212769600  1.1679407\n",
      "36 -1.6113725 -0.1608942 -0.2797931  0.8870674 -0.008070967 -0.4153218\n",
      "46  0.8970700 -0.9845926 -0.7326626 -1.4720624 -1.579573537  1.6874081\n",
      "56  0.1266269 -0.9517609  1.3336242 -1.0706795  0.603685414  1.7324335\n",
      "          X13        X14         X15        X16        X17        X18\n",
      "5  -1.0483242 -0.3836900 -1.50577354 -0.8795804  1.1814772 -1.7787277\n",
      "12  1.5916041  1.5107018  0.78099950 -0.2542226  0.3461854  1.5518477\n",
      "28 -1.1745328  0.4503335  0.97214188 -0.6523103 -1.4484757 -1.0951801\n",
      "36  0.7698554 -1.3620302  0.04953251 -1.0877102 -1.3001965  0.2327077\n",
      "46  1.5238560  1.0207720 -0.09106778  0.5658148 -0.3528192  0.3032306\n",
      "56 -1.3024500 -1.0326802 -0.01573423 -0.4489997 -0.6097831  1.2499229\n",
      "          X19        X20        X21        X22        X23        X24        X25\n",
      "5   1.5486817 -1.0635129  0.1819618  0.2086752  0.3007170 -0.6310749 -0.5900218\n",
      "12  0.6971899 -1.6120425  0.2356277  0.6680663 -0.2905850  0.8513374  0.5143289\n",
      "28 -1.0072966  1.4117554  0.2039424  1.7515503  0.8792471  0.0830091 -0.7588899\n",
      "36  0.4647819  1.6606483 -1.4039319 -0.7725031  0.7467178  1.0596017 -1.3285727\n",
      "46 -0.7638505  1.4710206  1.3070415  1.5142934  0.8006881 -0.5126906  0.6818697\n",
      "56 -0.9319769 -0.4111392  0.7350262  0.9023786 -0.3851197  0.6565990  0.4682159\n",
      "          X26         X27        X28        X29         X30        X31\n",
      "5   0.2939318 -0.84761160  1.3768215  0.7596974 -1.53934791 -0.2661868\n",
      "12 -0.2918941  1.28726902  0.1902838 -1.0926421 -1.06477694 -0.1067068\n",
      "28 -0.5036473 -0.15573440  1.1722949 -0.6608052 -0.05904758  0.4801936\n",
      "36 -1.1514406 -0.05960153  1.3223519 -0.8678078 -0.11795852 -0.1433881\n",
      "46  0.5845417  0.06826952 -0.3103399  0.3807128 -0.21140866 -0.6030875\n",
      "56  0.4039908  0.10680241  1.2008084  1.4437072 -1.24189929 -0.3954471\n",
      "           X32         X33        X34        X35        X36        X37\n",
      "5  -0.02631496 -0.78761679 -0.9226999 -0.6595103 -0.7911296 -0.2617080\n",
      "12  0.43273223 -0.98603808  0.6317735  0.7887990  0.4209579  0.5517904\n",
      "28 -0.09808084 -0.07591746 -1.2230874  0.3248281 -0.5046830 -0.1825535\n",
      "36  0.88801070  1.67323065 -1.9322818 -0.6928685  1.4867820 -0.2136853\n",
      "46  0.09354180 -0.34627304 -1.2884121  0.1730714  0.7502640  0.0322453\n",
      "56 -0.33522103  0.37500173  0.5865835 -0.6871609 -1.5208471  0.8363457\n",
      "           X38           X39        X40        X41         X42        X43\n",
      "5  -0.49267515 -0.6460023060  0.9914571 -1.2751424 -0.03364256 -1.7740909\n",
      "12 -0.03057699 -0.4737299749  0.5326139  0.1136621  1.51499178 -0.1552479\n",
      "28 -1.12676274 -0.0171825154 -0.4939654  2.3803181  0.90034299  0.5195471\n",
      "36  0.48136705 -0.0991520848  1.3851395  1.1758311  1.23344772  0.3747079\n",
      "46  0.43314990 -0.7762720292 -1.1163761  1.6538058 -0.31301009 -0.2602821\n",
      "56 -1.43270473  0.0009989663  0.0910662  0.0737519 -1.61339580  1.3759658\n",
      "          X44        X45 y\n",
      "5  -0.1428675  2.6379144 1\n",
      "12 -0.3392364 -0.9519014 1\n",
      "28  0.2394961  0.1986487 1\n",
      "36  1.7108227  0.5227764 1\n",
      "46 -0.4373185 -0.7443922 1\n",
      "56  1.9757648 -3.0619791 1\n",
      "\n",
      " 1  2  3 \n",
      "82 82 82 \n",
      "[1] \"Sampling method\"\n",
      "[1] \"smote\"\n",
      "[1] \"Sampled data\"\n",
      "            X1          X2         X3         X4         X5          X6\n",
      "192 -0.7434792 -0.50899821 -0.5730613 -1.3175941 -1.6810917 -0.57022598\n",
      "450 -0.6616488  1.57475784 -0.4766394 -1.2001021 -1.0949487 -1.10200352\n",
      "92   1.3805954 -0.48357825  0.4488321  0.1234280  1.5351370  0.35860579\n",
      "38   0.4346775  1.47867461 -0.3760565 -0.1733058  0.1877038  1.08994798\n",
      "384 -0.7123273 -0.01564962  0.2894754  0.4912484 -0.4615686  0.05961795\n",
      "83   0.2944932 -1.28308187  0.9106601  0.8874718  0.3049282  1.37003375\n",
      "            X7         X8         X9        X10        X11        X12\n",
      "192  1.2240423  1.1539127 -0.9558927  1.2610158 -1.4843485 -0.2471341\n",
      "450 -1.3455457 -0.6576156 -0.4564669 -1.1596213  0.8223173 -1.4423894\n",
      "92  -1.7060978 -1.0741021 -0.4017132 -0.5687440  0.9568413  1.1640628\n",
      "38  -0.4760781  1.5123540 -1.4401912  0.0594343 -0.2130874  0.1333320\n",
      "384 -0.6043803 -0.8922242  0.4074926  1.0088959  1.5055192  0.9106105\n",
      "83   0.6332173 -1.7029092  0.8797965 -1.0877515  1.1012238 -0.3898108\n",
      "           X13        X14        X15        X16         X17        X18\n",
      "192  0.8523051 -1.1940267  1.0824512 -1.4737080 -0.08016509  1.4471859\n",
      "450  0.2541199 -1.3648181 -0.9687343 -1.5798430  0.44069544  0.4965868\n",
      "92   0.7181493  0.9587830  0.8420329  1.5623864  0.88974483  0.6511222\n",
      "38  -1.4862971  0.5441993 -1.7208767  1.1384789  1.72896262 -0.8141904\n",
      "384 -1.5561862  0.6727776 -1.6999806  1.5924291 -1.52608075 -0.6144268\n",
      "83   0.4544913  0.2966392 -0.1446104  0.3720579 -0.74284140  1.1779860\n",
      "             X19        X20         X21          X22         X23        X24\n",
      "192  0.617119258 -1.3084199  0.68098443 -0.877972246  0.15428002  0.1704425\n",
      "450 -0.097002587 -0.6904970 -0.85966743 -0.801956319 -0.75758957 -0.5788907\n",
      "92   0.640865105  1.3898041  1.59706000 -0.742290383 -0.51119263  0.7737386\n",
      "38  -0.764728889  1.0782394 -0.05416932 -0.008311232  0.21225488 -0.7562754\n",
      "384 -0.009358481 -1.3965459 -1.12782969  0.365311132 -0.04166272  1.4241448\n",
      "83  -0.720823915 -0.9869245  1.20226530 -0.344969565 -0.57691277  0.5948416\n",
      "           X25        X26         X27        X28        X29        X30\n",
      "192 -1.0283969  1.2701769 -0.81798330  0.6961412  0.9961054 -0.4519361\n",
      "450 -0.4279781 -0.2500947  0.03757788  0.6133026  0.3399380  0.2667604\n",
      "92   1.9246962 -1.7795920 -0.61695667 -0.5982928 -1.5535992  0.5119917\n",
      "38   0.6249365  0.4136448 -0.43800824 -0.7774420  0.6272043 -0.8432306\n",
      "384 -1.8828110  0.2380498 -1.15750683 -1.0372213  1.0781015  1.1894079\n",
      "83   0.5129162  0.9198891 -1.05989810 -1.8774774 -1.4419825  0.1367330\n",
      "           X31        X32        X33        X34          X35         X36\n",
      "192 -1.6290136 0.50325522  1.1451130  0.6306615 -0.005169433  0.01576032\n",
      "450  0.6597645 0.04286459 -1.9108161  0.4900810 -0.621043088 -0.58619322\n",
      "92  -0.9774410 0.58332416 -0.4089589 -2.2817876 -1.589969902 -0.41757532\n",
      "38   1.0133526 0.27253224 -0.4165967  1.1473681 -0.831812352 -0.59268267\n",
      "384 -0.6813986 1.22550181  1.6340057  0.5103105  0.406038316 -0.37120797\n",
      "83  -1.1348267 0.81072932 -1.0771184  1.9412266 -0.672117574 -0.34265543\n",
      "            X37        X38        X39        X40         X41        X42\n",
      "192  0.12419068  0.8836958  1.5378431 -0.9973884  1.31615595  1.6776658\n",
      "450 -0.69973442 -1.0445143 -0.6600015  0.4647344 -0.09352074 -0.4606067\n",
      "92  -0.51914094 -0.6234767  0.6057127  0.9567705  0.72950573 -0.6420515\n",
      "38  -0.58870377  1.3954684 -0.8073903  2.2241123 -0.25948295  0.6892568\n",
      "384 -0.06177787 -0.6424909  0.2653769  0.6814823  0.58322356 -0.4321042\n",
      "83  -1.31645323  0.4837630  0.6185344  0.7119113  0.19224121  0.5840962\n",
      "            X43        X44          X45 y\n",
      "192  0.07062914 -2.1758346 -0.930854280 2\n",
      "450  0.21715394 -0.2758964 -0.271314479 2\n",
      "92   0.13386160  0.2253301 -1.446091148 2\n",
      "38  -0.17621757  1.0508617  0.775166185 2\n",
      "384  0.69857435  1.2385028 -0.007402004 2\n",
      "83   0.50270099  0.1559932 -1.034534392 2\n",
      "\n",
      "  1   2   3 \n",
      "167 167 167 \n"
     ]
    }
   ],
   "source": [
    "# Function to apply sampling techniques\n",
    "sample_data <- function(data, method = \"none\") {\n",
    "  if (method == \"smote\") {\n",
    "    data_balanced <- SmoteClassif(y ~ ., dat = data, C.perc = \"balance\")\n",
    "  } else if (method == \"up\") {\n",
    "    data_balanced <- RandOverClassif(y ~ ., dat = data, C.perc = \"balance\")\n",
    "  } else if (method == \"down\") {\n",
    "    data_balanced <- RandUnderClassif(y ~ ., dat = data, C.perc = \"balance\")\n",
    "  } else {\n",
    "    # No sampling\n",
    "    data_balanced <- data\n",
    "  }\n",
    "  return(data_balanced)\n",
    "}\n",
    "\n",
    "sampling_methods <- c(\"none\", \"up\", \"down\", \"smote\") # Add your sampling methods here\n",
    "\n",
    "for (sampling_method in sampling_methods) {\n",
    "  sampled_data_set <- sample_data(data_excluded, method = sampling_method)\n",
    "  print(\"Sampling method\")\n",
    "  print(sampling_method)\n",
    "  print(\"Sampled data\")\n",
    "  print(head(sampled_data_set))\n",
    "  print(table(sampled_data_set$y))\n",
    "}\n",
    "\n",
    "# # Define outer and inner folds\n",
    "# outer_folds <- 5\n",
    "# inner_folds <- 3\n",
    "# sampling_methods <- c(\"none\", \"up\", \"down\", \"smote\") # Add your sampling methods here\n",
    "# classification_methods <- c(\"lda\")\n",
    "\n",
    "# # Initialize results DataFrame\n",
    "# results <- data.frame(Model = character(), Variable_Set = character(), Sampling_Method = character(), \n",
    "#                       Fold = integer(), Accuracy = numeric(), Sensitivity = numeric(), \n",
    "#                       Specificity = numeric(), F1 = numeric(), row.names = NULL)\n",
    "\n",
    "# for (method in classification_methods) {\n",
    "#   for (variable_set in c(\"data\", \"data_ex\", \"data_ou\", \"data_ou_ex\")) {\n",
    "    \n",
    "#     data_set <- switch(variable_set,\n",
    "#                        \"data\" = data,\n",
    "#                        \"data_ex\" = data_excluded,\n",
    "#                        \"data_ou\" = data_outlier,\n",
    "#                        \"data_ou_ex\" = data_outlier_excluded)\n",
    "\n",
    "#     for (sampling_method in sampling_methods) {\n",
    "#       sampled_data_set <- sample_data(data_set, method = sampling_method)\n",
    "\n",
    "#       for (outer_fold in 1:outer_folds) {\n",
    "#         outer_train_index <- createFolds(sampled_data_set$y, k = outer_folds, list = TRUE, returnTrain = TRUE)[[outer_fold]]\n",
    "#         outer_train_data <- sampled_data_set[outer_train_index, ]\n",
    "#         outer_test_data <- sampled_data_set[-outer_train_index, ]\n",
    "\n",
    "#         best_inner_model <- NULL\n",
    "#         best_inner_accuracy <- 0\n",
    "        \n",
    "#         for (inner_fold in 1:inner_folds) {\n",
    "#           inner_train_index <- createFolds(outer_train_data$y, k = inner_folds, list = TRUE, returnTrain = TRUE)[[inner_fold]]\n",
    "#           inner_train_data <- outer_train_data[inner_train_index, ]\n",
    "#           inner_val_data <- outer_train_data[-inner_train_index, ]\n",
    "\n",
    "#           model <- train(y ~ ., data = inner_train_data, method = method, \n",
    "#                          trControl = trainControl(method = \"cv\", number = inner_folds), metric = \"Accuracy\")\n",
    "          \n",
    "#           val_pred <- predict(model, newdata = inner_val_data)\n",
    "#           val_accuracy <- mean(val_pred == inner_val_data$y)\n",
    "          \n",
    "#           if (val_accuracy > best_inner_accuracy) {\n",
    "#             best_inner_model <- model\n",
    "#             best_inner_accuracy <- val_accuracy\n",
    "#           }\n",
    "#         }\n",
    "        \n",
    "#         outer_metrics <- evaluate_model(best_inner_model, outer_test_data, outer_test_data$y)\n",
    "        \n",
    "#         results <- rbind(results, data.frame(Model = method, Variable_Set = variable_set, \n",
    "#                                              Sampling_Method = sampling_method, Fold = outer_fold,\n",
    "#                                              Accuracy = outer_metrics$Accuracy,\n",
    "#                                              Sensitivity = outer_metrics$Sensitivity,\n",
    "#                                              Specificity = outer_metrics$Specificity, row.names = NULL))\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# # Plot results with sampling method\n",
    "# ggplot(results, aes(x = Sampling_Method, y = Accuracy, fill = Variable_Set)) +\n",
    "#   geom_boxplot() +\n",
    "#   labs(title = \"Model Accuracy across Nested Cross-Validation Folds by Sampling Method\",\n",
    "#        x = \"Sampling Method\", y = \"Accuracy\")\n",
    "\n",
    "# ggplot(results, aes(x = Sampling_Method, y = Sensitivity, fill = Variable_Set)) +\n",
    "#   geom_boxplot() +\n",
    "#   labs(title = \"Model Sensitivity across Nested Cross-Validation Folds by Sampling Method\",\n",
    "#        x = \"Sampling Method\", y = \"Sensitivity\")\n",
    "\n",
    "# ggplot(results, aes(x = Sampling_Method, y = Specificity, fill = Variable_Set)) +\n",
    "#   geom_boxplot() +\n",
    "#   labs(title = \"Model Specificity across Nested Cross-Validation Folds by Sampling Method\",\n",
    "#        x = \"Sampling Method\", y = \"Specificity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 100 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Model</th><th scope=col>Variable_Set</th><th scope=col>Fold</th><th scope=col>Accuracy</th><th scope=col>Sensitivity</th><th scope=col>Specificity</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>naive_bayes</td><td>data   </td><td>4</td><td>0.7100000</td><td>0.6887857</td><td>0.8426680</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou</td><td>2</td><td>0.6944444</td><td>0.7000495</td><td>0.8485850</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data   </td><td>3</td><td>0.6831683</td><td>0.6877555</td><td>0.8214594</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou</td><td>5</td><td>0.6666667</td><td>0.6435340</td><td>0.8108658</td></tr>\n",
       "\t<tr><td>lda        </td><td>data   </td><td>1</td><td>0.6633663</td><td>0.6155522</td><td>0.8198285</td></tr>\n",
       "\t<tr><td>rf         </td><td>data   </td><td>4</td><td>0.6568627</td><td>0.5551074</td><td>0.8042795</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data   </td><td>4</td><td>0.6565657</td><td>0.6041179</td><td>0.8165863</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data   </td><td>3</td><td>0.6500000</td><td>0.5860984</td><td>0.8095523</td></tr>\n",
       "\t<tr><td>rf         </td><td>data   </td><td>2</td><td>0.6464646</td><td>0.5537037</td><td>0.7981812</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou</td><td>1</td><td>0.6438356</td><td>0.5852887</td><td>0.7969247</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou</td><td>4</td><td>0.6438356</td><td>0.5852887</td><td>0.8062941</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data   </td><td>2</td><td>0.6435644</td><td>0.5895814</td><td>0.8077922</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data   </td><td>1</td><td>0.6400000</td><td>0.5532037</td><td>0.8049724</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data   </td><td>5</td><td>0.6400000</td><td>0.6084394</td><td>0.8036651</td></tr>\n",
       "\t<tr><td>rf         </td><td>data   </td><td>5</td><td>0.6336634</td><td>0.5156540</td><td>0.7896153</td></tr>\n",
       "\t<tr><td>lda        </td><td>data   </td><td>5</td><td>0.6300000</td><td>0.5874670</td><td>0.7982805</td></tr>\n",
       "\t<tr><td>lda        </td><td>data   </td><td>4</td><td>0.6274510</td><td>0.6094935</td><td>0.8027155</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou</td><td>3</td><td>0.6250000</td><td>0.5725257</td><td>0.7975262</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data   </td><td>1</td><td>0.6161616</td><td>0.5449074</td><td>0.7861013</td></tr>\n",
       "\t<tr><td>lda        </td><td>data   </td><td>3</td><td>0.6060606</td><td>0.5898392</td><td>0.7849504</td></tr>\n",
       "\t<tr><td>rf         </td><td>data   </td><td>1</td><td>0.6060606</td><td>0.5295322</td><td>0.7806051</td></tr>\n",
       "\t<tr><td>rpart      </td><td>data_ou</td><td>4</td><td>0.6027397</td><td>0.5488268</td><td>0.7692808</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data   </td><td>5</td><td>0.5900000</td><td>0.5365179</td><td>0.7736815</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ou</td><td>5</td><td>0.5833333</td><td>0.5834262</td><td>0.7866431</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ex</td><td>4</td><td>0.5800000</td><td>0.4508009</td><td>0.7597286</td></tr>\n",
       "\t<tr><td>lda        </td><td>data   </td><td>2</td><td>0.5800000</td><td>0.5287582</td><td>0.7707228</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data   </td><td>2</td><td>0.5700000</td><td>0.5371377</td><td>0.7697275</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ou</td><td>2</td><td>0.5694444</td><td>0.4929394</td><td>0.7544230</td></tr>\n",
       "\t<tr><td>rf         </td><td>data_ou</td><td>1</td><td>0.5694444</td><td>0.4057971</td><td>0.7154195</td></tr>\n",
       "\t<tr><td>rf         </td><td>data_ou</td><td>4</td><td>0.5694444</td><td>0.4765577</td><td>0.7375283</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ex   </td><td>1</td><td>0.4700000</td><td>0.3952136</td><td>0.7144279</td></tr>\n",
       "\t<tr><td>rpart      </td><td>data      </td><td>2</td><td>0.4700000</td><td>0.3604119</td><td>0.6879729</td></tr>\n",
       "\t<tr><td>rpart      </td><td>data      </td><td>5</td><td>0.4700000</td><td>0.3832952</td><td>0.7070888</td></tr>\n",
       "\t<tr><td>rpart      </td><td>data_ex   </td><td>2</td><td>0.4700000</td><td>0.3515670</td><td>0.6793840</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou_ex</td><td>5</td><td>0.4583333</td><td>0.3847393</td><td>0.7021568</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ou_ex</td><td>4</td><td>0.4583333</td><td>0.3795058</td><td>0.6914787</td></tr>\n",
       "\t<tr><td>rpart      </td><td>data_ou   </td><td>3</td><td>0.4583333</td><td>0.3264895</td><td>0.6683673</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ex   </td><td>1</td><td>0.4545455</td><td>0.3765595</td><td>0.7010483</td></tr>\n",
       "\t<tr><td>rpart      </td><td>data_ex   </td><td>3</td><td>0.4545455</td><td>0.3333333</td><td>0.6666667</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ex   </td><td>4</td><td>0.4455446</td><td>0.3750617</td><td>0.6944925</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ou_ex</td><td>5</td><td>0.4444444</td><td>0.3970953</td><td>0.6833724</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou_ex</td><td>1</td><td>0.4444444</td><td>0.3813948</td><td>0.6868314</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou_ex</td><td>3</td><td>0.4444444</td><td>0.3538647</td><td>0.6988130</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ou_ex</td><td>5</td><td>0.4444444</td><td>0.3859470</td><td>0.6915940</td></tr>\n",
       "\t<tr><td>rpart      </td><td>data      </td><td>3</td><td>0.4444444</td><td>0.3504873</td><td>0.6824529</td></tr>\n",
       "\t<tr><td>rpart      </td><td>data_ex   </td><td>5</td><td>0.4356436</td><td>0.3371472</td><td>0.6676287</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ex   </td><td>5</td><td>0.4343434</td><td>0.3926901</td><td>0.6879308</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ex   </td><td>3</td><td>0.4257426</td><td>0.3576749</td><td>0.6800625</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ou_ex</td><td>2</td><td>0.4246575</td><td>0.3172878</td><td>0.6685601</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ex   </td><td>4</td><td>0.4200000</td><td>0.3356725</td><td>0.6771661</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ex   </td><td>2</td><td>0.4141414</td><td>0.3430556</td><td>0.6790953</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ex   </td><td>3</td><td>0.4141414</td><td>0.3510234</td><td>0.6719166</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ex   </td><td>2</td><td>0.4117647</td><td>0.3388200</td><td>0.6695456</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ex   </td><td>5</td><td>0.4040404</td><td>0.3422515</td><td>0.6693489</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ou_ex</td><td>3</td><td>0.3888889</td><td>0.3234238</td><td>0.6450318</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ou_ex</td><td>1</td><td>0.3888889</td><td>0.3070420</td><td>0.6593195</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ou_ex</td><td>3</td><td>0.3750000</td><td>0.2709340</td><td>0.6464507</td></tr>\n",
       "\t<tr><td>multinom   </td><td>data_ou_ex</td><td>1</td><td>0.3611111</td><td>0.3317540</td><td>0.6627593</td></tr>\n",
       "\t<tr><td>lda        </td><td>data_ou_ex</td><td>2</td><td>0.3561644</td><td>0.2960087</td><td>0.6466300</td></tr>\n",
       "\t<tr><td>naive_bayes</td><td>data_ou_ex</td><td>4</td><td>0.3472222</td><td>0.2740307</td><td>0.6162516</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 100 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " Model & Variable\\_Set & Fold & Accuracy & Sensitivity & Specificity\\\\\n",
       " <chr> & <chr> & <int> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t naive\\_bayes & data    & 4 & 0.7100000 & 0.6887857 & 0.8426680\\\\\n",
       "\t naive\\_bayes & data\\_ou & 2 & 0.6944444 & 0.7000495 & 0.8485850\\\\\n",
       "\t multinom    & data    & 3 & 0.6831683 & 0.6877555 & 0.8214594\\\\\n",
       "\t naive\\_bayes & data\\_ou & 5 & 0.6666667 & 0.6435340 & 0.8108658\\\\\n",
       "\t lda         & data    & 1 & 0.6633663 & 0.6155522 & 0.8198285\\\\\n",
       "\t rf          & data    & 4 & 0.6568627 & 0.5551074 & 0.8042795\\\\\n",
       "\t multinom    & data    & 4 & 0.6565657 & 0.6041179 & 0.8165863\\\\\n",
       "\t naive\\_bayes & data    & 3 & 0.6500000 & 0.5860984 & 0.8095523\\\\\n",
       "\t rf          & data    & 2 & 0.6464646 & 0.5537037 & 0.7981812\\\\\n",
       "\t naive\\_bayes & data\\_ou & 1 & 0.6438356 & 0.5852887 & 0.7969247\\\\\n",
       "\t naive\\_bayes & data\\_ou & 4 & 0.6438356 & 0.5852887 & 0.8062941\\\\\n",
       "\t naive\\_bayes & data    & 2 & 0.6435644 & 0.5895814 & 0.8077922\\\\\n",
       "\t naive\\_bayes & data    & 1 & 0.6400000 & 0.5532037 & 0.8049724\\\\\n",
       "\t naive\\_bayes & data    & 5 & 0.6400000 & 0.6084394 & 0.8036651\\\\\n",
       "\t rf          & data    & 5 & 0.6336634 & 0.5156540 & 0.7896153\\\\\n",
       "\t lda         & data    & 5 & 0.6300000 & 0.5874670 & 0.7982805\\\\\n",
       "\t lda         & data    & 4 & 0.6274510 & 0.6094935 & 0.8027155\\\\\n",
       "\t naive\\_bayes & data\\_ou & 3 & 0.6250000 & 0.5725257 & 0.7975262\\\\\n",
       "\t multinom    & data    & 1 & 0.6161616 & 0.5449074 & 0.7861013\\\\\n",
       "\t lda         & data    & 3 & 0.6060606 & 0.5898392 & 0.7849504\\\\\n",
       "\t rf          & data    & 1 & 0.6060606 & 0.5295322 & 0.7806051\\\\\n",
       "\t rpart       & data\\_ou & 4 & 0.6027397 & 0.5488268 & 0.7692808\\\\\n",
       "\t multinom    & data    & 5 & 0.5900000 & 0.5365179 & 0.7736815\\\\\n",
       "\t multinom    & data\\_ou & 5 & 0.5833333 & 0.5834262 & 0.7866431\\\\\n",
       "\t naive\\_bayes & data\\_ex & 4 & 0.5800000 & 0.4508009 & 0.7597286\\\\\n",
       "\t lda         & data    & 2 & 0.5800000 & 0.5287582 & 0.7707228\\\\\n",
       "\t multinom    & data    & 2 & 0.5700000 & 0.5371377 & 0.7697275\\\\\n",
       "\t lda         & data\\_ou & 2 & 0.5694444 & 0.4929394 & 0.7544230\\\\\n",
       "\t rf          & data\\_ou & 1 & 0.5694444 & 0.4057971 & 0.7154195\\\\\n",
       "\t rf          & data\\_ou & 4 & 0.5694444 & 0.4765577 & 0.7375283\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t multinom    & data\\_ex    & 1 & 0.4700000 & 0.3952136 & 0.7144279\\\\\n",
       "\t rpart       & data       & 2 & 0.4700000 & 0.3604119 & 0.6879729\\\\\n",
       "\t rpart       & data       & 5 & 0.4700000 & 0.3832952 & 0.7070888\\\\\n",
       "\t rpart       & data\\_ex    & 2 & 0.4700000 & 0.3515670 & 0.6793840\\\\\n",
       "\t naive\\_bayes & data\\_ou\\_ex & 5 & 0.4583333 & 0.3847393 & 0.7021568\\\\\n",
       "\t lda         & data\\_ou\\_ex & 4 & 0.4583333 & 0.3795058 & 0.6914787\\\\\n",
       "\t rpart       & data\\_ou    & 3 & 0.4583333 & 0.3264895 & 0.6683673\\\\\n",
       "\t naive\\_bayes & data\\_ex    & 1 & 0.4545455 & 0.3765595 & 0.7010483\\\\\n",
       "\t rpart       & data\\_ex    & 3 & 0.4545455 & 0.3333333 & 0.6666667\\\\\n",
       "\t lda         & data\\_ex    & 4 & 0.4455446 & 0.3750617 & 0.6944925\\\\\n",
       "\t multinom    & data\\_ou\\_ex & 5 & 0.4444444 & 0.3970953 & 0.6833724\\\\\n",
       "\t naive\\_bayes & data\\_ou\\_ex & 1 & 0.4444444 & 0.3813948 & 0.6868314\\\\\n",
       "\t naive\\_bayes & data\\_ou\\_ex & 3 & 0.4444444 & 0.3538647 & 0.6988130\\\\\n",
       "\t lda         & data\\_ou\\_ex & 5 & 0.4444444 & 0.3859470 & 0.6915940\\\\\n",
       "\t rpart       & data       & 3 & 0.4444444 & 0.3504873 & 0.6824529\\\\\n",
       "\t rpart       & data\\_ex    & 5 & 0.4356436 & 0.3371472 & 0.6676287\\\\\n",
       "\t multinom    & data\\_ex    & 5 & 0.4343434 & 0.3926901 & 0.6879308\\\\\n",
       "\t lda         & data\\_ex    & 3 & 0.4257426 & 0.3576749 & 0.6800625\\\\\n",
       "\t multinom    & data\\_ou\\_ex & 2 & 0.4246575 & 0.3172878 & 0.6685601\\\\\n",
       "\t multinom    & data\\_ex    & 4 & 0.4200000 & 0.3356725 & 0.6771661\\\\\n",
       "\t multinom    & data\\_ex    & 2 & 0.4141414 & 0.3430556 & 0.6790953\\\\\n",
       "\t multinom    & data\\_ex    & 3 & 0.4141414 & 0.3510234 & 0.6719166\\\\\n",
       "\t lda         & data\\_ex    & 2 & 0.4117647 & 0.3388200 & 0.6695456\\\\\n",
       "\t lda         & data\\_ex    & 5 & 0.4040404 & 0.3422515 & 0.6693489\\\\\n",
       "\t multinom    & data\\_ou\\_ex & 3 & 0.3888889 & 0.3234238 & 0.6450318\\\\\n",
       "\t lda         & data\\_ou\\_ex & 1 & 0.3888889 & 0.3070420 & 0.6593195\\\\\n",
       "\t lda         & data\\_ou\\_ex & 3 & 0.3750000 & 0.2709340 & 0.6464507\\\\\n",
       "\t multinom    & data\\_ou\\_ex & 1 & 0.3611111 & 0.3317540 & 0.6627593\\\\\n",
       "\t lda         & data\\_ou\\_ex & 2 & 0.3561644 & 0.2960087 & 0.6466300\\\\\n",
       "\t naive\\_bayes & data\\_ou\\_ex & 4 & 0.3472222 & 0.2740307 & 0.6162516\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 100 × 6\n",
       "\n",
       "| Model &lt;chr&gt; | Variable_Set &lt;chr&gt; | Fold &lt;int&gt; | Accuracy &lt;dbl&gt; | Sensitivity &lt;dbl&gt; | Specificity &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| naive_bayes | data    | 4 | 0.7100000 | 0.6887857 | 0.8426680 |\n",
       "| naive_bayes | data_ou | 2 | 0.6944444 | 0.7000495 | 0.8485850 |\n",
       "| multinom    | data    | 3 | 0.6831683 | 0.6877555 | 0.8214594 |\n",
       "| naive_bayes | data_ou | 5 | 0.6666667 | 0.6435340 | 0.8108658 |\n",
       "| lda         | data    | 1 | 0.6633663 | 0.6155522 | 0.8198285 |\n",
       "| rf          | data    | 4 | 0.6568627 | 0.5551074 | 0.8042795 |\n",
       "| multinom    | data    | 4 | 0.6565657 | 0.6041179 | 0.8165863 |\n",
       "| naive_bayes | data    | 3 | 0.6500000 | 0.5860984 | 0.8095523 |\n",
       "| rf          | data    | 2 | 0.6464646 | 0.5537037 | 0.7981812 |\n",
       "| naive_bayes | data_ou | 1 | 0.6438356 | 0.5852887 | 0.7969247 |\n",
       "| naive_bayes | data_ou | 4 | 0.6438356 | 0.5852887 | 0.8062941 |\n",
       "| naive_bayes | data    | 2 | 0.6435644 | 0.5895814 | 0.8077922 |\n",
       "| naive_bayes | data    | 1 | 0.6400000 | 0.5532037 | 0.8049724 |\n",
       "| naive_bayes | data    | 5 | 0.6400000 | 0.6084394 | 0.8036651 |\n",
       "| rf          | data    | 5 | 0.6336634 | 0.5156540 | 0.7896153 |\n",
       "| lda         | data    | 5 | 0.6300000 | 0.5874670 | 0.7982805 |\n",
       "| lda         | data    | 4 | 0.6274510 | 0.6094935 | 0.8027155 |\n",
       "| naive_bayes | data_ou | 3 | 0.6250000 | 0.5725257 | 0.7975262 |\n",
       "| multinom    | data    | 1 | 0.6161616 | 0.5449074 | 0.7861013 |\n",
       "| lda         | data    | 3 | 0.6060606 | 0.5898392 | 0.7849504 |\n",
       "| rf          | data    | 1 | 0.6060606 | 0.5295322 | 0.7806051 |\n",
       "| rpart       | data_ou | 4 | 0.6027397 | 0.5488268 | 0.7692808 |\n",
       "| multinom    | data    | 5 | 0.5900000 | 0.5365179 | 0.7736815 |\n",
       "| multinom    | data_ou | 5 | 0.5833333 | 0.5834262 | 0.7866431 |\n",
       "| naive_bayes | data_ex | 4 | 0.5800000 | 0.4508009 | 0.7597286 |\n",
       "| lda         | data    | 2 | 0.5800000 | 0.5287582 | 0.7707228 |\n",
       "| multinom    | data    | 2 | 0.5700000 | 0.5371377 | 0.7697275 |\n",
       "| lda         | data_ou | 2 | 0.5694444 | 0.4929394 | 0.7544230 |\n",
       "| rf          | data_ou | 1 | 0.5694444 | 0.4057971 | 0.7154195 |\n",
       "| rf          | data_ou | 4 | 0.5694444 | 0.4765577 | 0.7375283 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| multinom    | data_ex    | 1 | 0.4700000 | 0.3952136 | 0.7144279 |\n",
       "| rpart       | data       | 2 | 0.4700000 | 0.3604119 | 0.6879729 |\n",
       "| rpart       | data       | 5 | 0.4700000 | 0.3832952 | 0.7070888 |\n",
       "| rpart       | data_ex    | 2 | 0.4700000 | 0.3515670 | 0.6793840 |\n",
       "| naive_bayes | data_ou_ex | 5 | 0.4583333 | 0.3847393 | 0.7021568 |\n",
       "| lda         | data_ou_ex | 4 | 0.4583333 | 0.3795058 | 0.6914787 |\n",
       "| rpart       | data_ou    | 3 | 0.4583333 | 0.3264895 | 0.6683673 |\n",
       "| naive_bayes | data_ex    | 1 | 0.4545455 | 0.3765595 | 0.7010483 |\n",
       "| rpart       | data_ex    | 3 | 0.4545455 | 0.3333333 | 0.6666667 |\n",
       "| lda         | data_ex    | 4 | 0.4455446 | 0.3750617 | 0.6944925 |\n",
       "| multinom    | data_ou_ex | 5 | 0.4444444 | 0.3970953 | 0.6833724 |\n",
       "| naive_bayes | data_ou_ex | 1 | 0.4444444 | 0.3813948 | 0.6868314 |\n",
       "| naive_bayes | data_ou_ex | 3 | 0.4444444 | 0.3538647 | 0.6988130 |\n",
       "| lda         | data_ou_ex | 5 | 0.4444444 | 0.3859470 | 0.6915940 |\n",
       "| rpart       | data       | 3 | 0.4444444 | 0.3504873 | 0.6824529 |\n",
       "| rpart       | data_ex    | 5 | 0.4356436 | 0.3371472 | 0.6676287 |\n",
       "| multinom    | data_ex    | 5 | 0.4343434 | 0.3926901 | 0.6879308 |\n",
       "| lda         | data_ex    | 3 | 0.4257426 | 0.3576749 | 0.6800625 |\n",
       "| multinom    | data_ou_ex | 2 | 0.4246575 | 0.3172878 | 0.6685601 |\n",
       "| multinom    | data_ex    | 4 | 0.4200000 | 0.3356725 | 0.6771661 |\n",
       "| multinom    | data_ex    | 2 | 0.4141414 | 0.3430556 | 0.6790953 |\n",
       "| multinom    | data_ex    | 3 | 0.4141414 | 0.3510234 | 0.6719166 |\n",
       "| lda         | data_ex    | 2 | 0.4117647 | 0.3388200 | 0.6695456 |\n",
       "| lda         | data_ex    | 5 | 0.4040404 | 0.3422515 | 0.6693489 |\n",
       "| multinom    | data_ou_ex | 3 | 0.3888889 | 0.3234238 | 0.6450318 |\n",
       "| lda         | data_ou_ex | 1 | 0.3888889 | 0.3070420 | 0.6593195 |\n",
       "| lda         | data_ou_ex | 3 | 0.3750000 | 0.2709340 | 0.6464507 |\n",
       "| multinom    | data_ou_ex | 1 | 0.3611111 | 0.3317540 | 0.6627593 |\n",
       "| lda         | data_ou_ex | 2 | 0.3561644 | 0.2960087 | 0.6466300 |\n",
       "| naive_bayes | data_ou_ex | 4 | 0.3472222 | 0.2740307 | 0.6162516 |\n",
       "\n"
      ],
      "text/plain": [
       "    Model       Variable_Set Fold Accuracy  Sensitivity Specificity\n",
       "1   naive_bayes data         4    0.7100000 0.6887857   0.8426680  \n",
       "2   naive_bayes data_ou      2    0.6944444 0.7000495   0.8485850  \n",
       "3   multinom    data         3    0.6831683 0.6877555   0.8214594  \n",
       "4   naive_bayes data_ou      5    0.6666667 0.6435340   0.8108658  \n",
       "5   lda         data         1    0.6633663 0.6155522   0.8198285  \n",
       "6   rf          data         4    0.6568627 0.5551074   0.8042795  \n",
       "7   multinom    data         4    0.6565657 0.6041179   0.8165863  \n",
       "8   naive_bayes data         3    0.6500000 0.5860984   0.8095523  \n",
       "9   rf          data         2    0.6464646 0.5537037   0.7981812  \n",
       "10  naive_bayes data_ou      1    0.6438356 0.5852887   0.7969247  \n",
       "11  naive_bayes data_ou      4    0.6438356 0.5852887   0.8062941  \n",
       "12  naive_bayes data         2    0.6435644 0.5895814   0.8077922  \n",
       "13  naive_bayes data         1    0.6400000 0.5532037   0.8049724  \n",
       "14  naive_bayes data         5    0.6400000 0.6084394   0.8036651  \n",
       "15  rf          data         5    0.6336634 0.5156540   0.7896153  \n",
       "16  lda         data         5    0.6300000 0.5874670   0.7982805  \n",
       "17  lda         data         4    0.6274510 0.6094935   0.8027155  \n",
       "18  naive_bayes data_ou      3    0.6250000 0.5725257   0.7975262  \n",
       "19  multinom    data         1    0.6161616 0.5449074   0.7861013  \n",
       "20  lda         data         3    0.6060606 0.5898392   0.7849504  \n",
       "21  rf          data         1    0.6060606 0.5295322   0.7806051  \n",
       "22  rpart       data_ou      4    0.6027397 0.5488268   0.7692808  \n",
       "23  multinom    data         5    0.5900000 0.5365179   0.7736815  \n",
       "24  multinom    data_ou      5    0.5833333 0.5834262   0.7866431  \n",
       "25  naive_bayes data_ex      4    0.5800000 0.4508009   0.7597286  \n",
       "26  lda         data         2    0.5800000 0.5287582   0.7707228  \n",
       "27  multinom    data         2    0.5700000 0.5371377   0.7697275  \n",
       "28  lda         data_ou      2    0.5694444 0.4929394   0.7544230  \n",
       "29  rf          data_ou      1    0.5694444 0.4057971   0.7154195  \n",
       "30  rf          data_ou      4    0.5694444 0.4765577   0.7375283  \n",
       "⋮   ⋮           ⋮            ⋮    ⋮         ⋮           ⋮          \n",
       "71  multinom    data_ex      1    0.4700000 0.3952136   0.7144279  \n",
       "72  rpart       data         2    0.4700000 0.3604119   0.6879729  \n",
       "73  rpart       data         5    0.4700000 0.3832952   0.7070888  \n",
       "74  rpart       data_ex      2    0.4700000 0.3515670   0.6793840  \n",
       "75  naive_bayes data_ou_ex   5    0.4583333 0.3847393   0.7021568  \n",
       "76  lda         data_ou_ex   4    0.4583333 0.3795058   0.6914787  \n",
       "77  rpart       data_ou      3    0.4583333 0.3264895   0.6683673  \n",
       "78  naive_bayes data_ex      1    0.4545455 0.3765595   0.7010483  \n",
       "79  rpart       data_ex      3    0.4545455 0.3333333   0.6666667  \n",
       "80  lda         data_ex      4    0.4455446 0.3750617   0.6944925  \n",
       "81  multinom    data_ou_ex   5    0.4444444 0.3970953   0.6833724  \n",
       "82  naive_bayes data_ou_ex   1    0.4444444 0.3813948   0.6868314  \n",
       "83  naive_bayes data_ou_ex   3    0.4444444 0.3538647   0.6988130  \n",
       "84  lda         data_ou_ex   5    0.4444444 0.3859470   0.6915940  \n",
       "85  rpart       data         3    0.4444444 0.3504873   0.6824529  \n",
       "86  rpart       data_ex      5    0.4356436 0.3371472   0.6676287  \n",
       "87  multinom    data_ex      5    0.4343434 0.3926901   0.6879308  \n",
       "88  lda         data_ex      3    0.4257426 0.3576749   0.6800625  \n",
       "89  multinom    data_ou_ex   2    0.4246575 0.3172878   0.6685601  \n",
       "90  multinom    data_ex      4    0.4200000 0.3356725   0.6771661  \n",
       "91  multinom    data_ex      2    0.4141414 0.3430556   0.6790953  \n",
       "92  multinom    data_ex      3    0.4141414 0.3510234   0.6719166  \n",
       "93  lda         data_ex      2    0.4117647 0.3388200   0.6695456  \n",
       "94  lda         data_ex      5    0.4040404 0.3422515   0.6693489  \n",
       "95  multinom    data_ou_ex   3    0.3888889 0.3234238   0.6450318  \n",
       "96  lda         data_ou_ex   1    0.3888889 0.3070420   0.6593195  \n",
       "97  lda         data_ou_ex   3    0.3750000 0.2709340   0.6464507  \n",
       "98  multinom    data_ou_ex   1    0.3611111 0.3317540   0.6627593  \n",
       "99  lda         data_ou_ex   2    0.3561644 0.2960087   0.6466300  \n",
       "100 naive_bayes data_ou_ex   4    0.3472222 0.2740307   0.6162516  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results %>% arrange(desc(Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X1           X2         X3         X4          X5         X6\n",
      "1  0.1520951 -0.001077043  1.3232418  0.4829507  1.18447294  0.3128938\n",
      "2  1.4828231 -1.320965483  0.8605130 -1.5410116 -1.19194583  1.0559602\n",
      "3  1.6973454  1.575098487 -0.9227483  0.8383256 -0.71254470 -0.2796727\n",
      "4 -1.1266522  1.213395380 -1.6323412  1.3704219 -0.77110979  0.5366186\n",
      "5  0.7427705  0.319138772 -1.4308311 -0.7153544 -1.43298490 -1.2511355\n",
      "6  1.0272638 -1.549598214 -1.3811201 -0.1612517  0.06608898  0.3763517\n",
      "          X7         X8         X9        X10         X11        X12\n",
      "1 -1.0309908 -1.1270022  1.0249860  1.4966017  0.11115773  0.8332604\n",
      "2 -0.9621786  1.0931273  1.2423460 -0.2570111  0.12281814  0.4889229\n",
      "3 -0.9251125 -0.5612810 -0.8580621  0.6826289 -1.20773705 -0.8165060\n",
      "4  1.6303239  0.4889026  0.4843326 -1.2531756  0.80254853  1.2836441\n",
      "5 -0.3360766  0.1892026  1.5472019  0.4840599 -0.03292476 -1.1545984\n",
      "6  0.7836426  0.3381814 -0.3515586 -0.3020698 -0.33811617  0.8372291\n",
      "          X13        X14         X15        X16        X17        X18\n",
      "1 -1.64909774 -1.6698796 -1.17241906  1.3357247  0.6106323  1.1375343\n",
      "2 -0.98034558 -1.5150755  1.22718114  0.3439252  1.0735877 -1.1905924\n",
      "3  0.07923653 -0.1799781 -0.06042082 -1.5576947  1.0805082  0.3051988\n",
      "4 -0.27838730 -0.4339457 -0.80721833  1.2026341 -1.6428891  0.6161562\n",
      "5 -1.04832424 -0.3836900 -1.50577354 -0.8795804  1.1814772 -1.7787277\n",
      "6 -1.03104179 -1.4205234  0.14042984  1.3165438  1.1324787  1.4639798\n",
      "          X19        X20        X21        X22        X23        X24        X25\n",
      "1 -0.35021859 -0.6418293 -1.9481336  0.6626811  1.0409441 -0.1706564  1.2654018\n",
      "2  0.05873767 -1.6046896  0.6014965  0.7149596 -1.0322204  0.9540324  0.4621475\n",
      "3 -0.40066757  0.7194948  2.5149911  1.5144055 -0.2564052  3.6133973  0.5778135\n",
      "4  0.22121874  0.7573599 -1.4160092 -0.5344183  0.1980008  0.8366899  0.6778158\n",
      "5  1.54868173 -1.0635129  0.1819618  0.2086752  0.3007170 -0.6310749 -0.5900218\n",
      "6  0.94848366 -1.7038345 -0.6540901 -0.8875494 -0.3419897  1.3266713  0.7132874\n",
      "         X26        X27          X28        X29         X30        X31\n",
      "1 -0.1278522  1.3351301 -0.240681517  1.7627004  0.01249865 -0.4249263\n",
      "2 -0.4799549  0.8389367 -0.451670855 -0.7720648  0.30479871 -0.9833008\n",
      "3  0.5670421  3.4968728  1.779625131  0.1153830  0.89190986 -1.8679981\n",
      "4  0.1023178 -1.4642701 -0.005317279 -1.1669568  1.08900673 -0.1962917\n",
      "5  0.2939318 -0.8476116  1.376821471  0.7596974 -1.53934791 -0.2661868\n",
      "6 -2.0187590  1.2892859 -1.163639587 -0.7424875 -0.86238200 -0.7945049\n",
      "          X32         X33        X34         X35        X36        X37\n",
      "1  2.06695932  0.77821695  1.2148748  1.15531280 -1.5573339  0.8815981\n",
      "2 -0.15895022 -0.35567345  0.3285720 -0.44718433 -0.6082948  1.0511136\n",
      "3  0.06309005  1.10183103 -2.8132440  1.22092848  1.6071860 -0.9056308\n",
      "4  0.70717687 -0.85255089  1.5121732 -0.02694163  0.5981125 -1.0750609\n",
      "5 -0.02631496 -0.78761679 -0.9226999 -0.65951028 -0.7911296 -0.2617080\n",
      "6 -0.45030731 -0.07875655 -1.3467341 -1.60617054 -0.9431196 -0.1084342\n",
      "         X38        X39        X40        X41         X42        X43        X44\n",
      "1 -0.6394869  0.6380977 -1.6566505 -0.5418631  0.40937804 -1.5643242  1.0974111\n",
      "2 -0.3454285  0.6778171  1.4379336 -0.3934808  0.81012744  0.7327486 -1.1152622\n",
      "3 -0.2376972  1.2335260 -4.9447665  1.7986084  1.71936530  2.3700186 -0.9275773\n",
      "4 -0.9242505 -0.2389173  0.3000153  0.5086487  0.97816371 -0.8756930  0.8775897\n",
      "5 -0.4926752 -0.6460023  0.9914571 -1.2751424 -0.03364256 -1.7740909 -0.1428675\n",
      "6 -0.1853594  1.2031359 -0.3653933  0.3609107  0.94416615  2.2211546  0.8479884\n",
      "         X45 X46 X47 X48 X49 X50 y\n",
      "1  0.4185625   3   3   8   3   7 2\n",
      "2 -0.4685141   3   1   3   3   3 2\n",
      "3 -2.1348492   1   5   4   3   3 3\n",
      "4  2.6115839   1   6   4   5   4 2\n",
      "5  2.6379144   7   5   4   4   5 1\n",
      "6  0.3610012   4   2   3   6   5 3\n",
      "y ~ s(X1) + s(X2) + s(X3) + s(X4) + s(X5) + s(X6) + s(X7) + s(X8) + \n",
      "    s(X9) + s(X10) + s(X11) + s(X12) + s(X13) + s(X14) + s(X15) + \n",
      "    s(X16) + s(X17) + s(X18) + s(X19) + s(X20) + s(X21) + s(X22) + \n",
      "    s(X23) + s(X24) + s(X25) + s(X26) + s(X27) + s(X28) + s(X29) + \n",
      "    s(X30) + s(X31) + s(X32) + s(X33) + s(X34) + s(X35) + s(X36) + \n",
      "    s(X37) + s(X38) + s(X39) + s(X40) + s(X41) + s(X42) + s(X43) + \n",
      "    s(X44) + s(X45) + X46 + X47 + X48 + X49 + X50\n"
     ]
    }
   ],
   "source": [
    "# Fit the GAM model\n",
    "data_gam <- data\n",
    "data_gam[, excluded_vars] <- lapply(data_gam[, excluded_vars], as.factor)\n",
    "preprocess_params_gam <- preProcess(data_gam[, numeric_vars], method = c(\"center\", \"scale\"))\n",
    "data_scaled_gam <- data_gam\n",
    "data_scaled_gam[, numeric_vars] <- predict(preprocess_params_gam, data_gam[, numeric_vars])\n",
    "print(head(data_scaled_gam))\n",
    "continuous_vars <- paste0(\"s(X\", 1:45, \")\", collapse = \" + \")\n",
    "categorical_vars <- paste0(\"X\", 46:50, collapse = \" + \")\n",
    "formula_string <- paste(\"y ~\", continuous_vars, \"+\", categorical_vars)\n",
    "model_formula <- as.formula(formula_string)\n",
    "print(model_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in offset[[i]]: tentative de sélection de moins d'un élément dans integerOneIndex\n",
     "output_type": "error",
     "traceback": [
      "Error in offset[[i]]: tentative de sélection de moins d'un élément dans integerOneIndex\nTraceback:\n",
      "1. gam(model_formula, family = multinom(K = 3), data = inner_train_data)",
      "2. estimate.gam(G, method, optimizer, control, in.out, scale, gamma, \n .     nei = nei, ...)",
      "3. initial.spg(G$X, G$y, G$w, G$family, G$S, G$rank, G$off, offset = G$offset, \n .     L = G$L, lsp0 = G$lsp0, E = G$Eb, ...)",
      "4. family$ll(y, x, start, weights, family, offset = offset, deriv = 1)"
     ]
    }
   ],
   "source": [
    "# Define outer and inner folds\n",
    "outer_folds <- 5\n",
    "inner_folds <- 3\n",
    "\n",
    "evaluate_gam_model <- function(model, test_data, true_labels) {\n",
    "    predictions <- predict(model, newdata = test_data, type = \"response\")\n",
    "    predicted_classes <- apply(predictions, 1, which.max)\n",
    "    levels <- levels(true_labels)\n",
    "    predicted_classes <- levels[predicted_classes]\n",
    "    \n",
    "    accuracy <- mean(predicted_classes == true_labels)\n",
    "    return(accuracy)\n",
    "}\n",
    "\n",
    "results_gam <- data.frame(Fold = integer(), Accuracy = numeric(), row.names = NULL)\n",
    "\n",
    "for (outer_fold in 1:outer_folds) {\n",
    "    outer_train_index <- createFolds(data_scaled_gam$y, k = outer_folds, list = TRUE, returnTrain = TRUE)[[outer_fold]]\n",
    "    outer_train_data <- data_scaled_gam[outer_train_index, ]\n",
    "    outer_test_data <- data_scaled_gam[-outer_train_index, ]\n",
    "    \n",
    "    best_inner_model <- NULL\n",
    "    best_inner_accuracy <- 0\n",
    "    \n",
    "    for (inner_fold in 1:inner_folds) {\n",
    "        inner_train_index <- createFolds(outer_train_data$y, k = inner_folds, list = TRUE, returnTrain = TRUE)[[inner_fold]]\n",
    "        inner_train_data <- outer_train_data[inner_train_index, ]\n",
    "        inner_val_data <- outer_train_data[-inner_train_index, ]\n",
    "        \n",
    "        gam_model <- gam(model_formula, family = multinom(K = 3), data = inner_train_data)\n",
    "        \n",
    "        val_accuracy <- evaluate_gam_model(gam_model, inner_val_data, inner_val_data$y)\n",
    "        \n",
    "        if (val_accuracy > best_inner_accuracy) {\n",
    "            best_inner_model <- gam_model\n",
    "            best_inner_accuracy <- val_accuracy\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    outer_accuracy <- evaluate_gam_model(best_inner_model, outer_test_data, outer_test_data$y)\n",
    "    \n",
    "    results_gam <- rbind(results_gam, data.frame(Fold = outer_fold, Accuracy = outer_accuracy, row.names = NULL))\n",
    "}\n",
    "\n",
    "row.names(results_gam) <- NULL\n",
    "\n",
    "\n",
    "# Plot results\n",
    "ggplot(results_gam, aes(x = factor(Fold), y = Accuracy)) +\n",
    "    geom_boxplot() +\n",
    "    labs(title = \"GAM Model Accuracy across Nested Cross-Validation Folds\",\n",
    "         x = \"Fold\", y = \"Accuracy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
