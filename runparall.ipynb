{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Le chargement a nécessité le package : glmnet\n",
      "\n",
      "Le chargement a nécessité le package : Matrix\n",
      "\n",
      "Loaded glmnet 4.1-8\n",
      "\n",
      "Le chargement a nécessité le package : caret\n",
      "\n",
      "Le chargement a nécessité le package : ggplot2\n",
      "\n",
      "Le chargement a nécessité le package : lattice\n",
      "\n",
      "Le chargement a nécessité le package : dplyr\n",
      "\n",
      "\n",
      "Attachement du package : 'dplyr'\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Le chargement a nécessité le package : MASS\n",
      "\n",
      "\n",
      "Attachement du package : 'MASS'\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:dplyr':\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "Le chargement a nécessité le package : mgcv\n",
      "\n",
      "Le chargement a nécessité le package : nlme\n",
      "\n",
      "\n",
      "Attachement du package : 'nlme'\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:dplyr':\n",
      "\n",
      "    collapse\n",
      "\n",
      "\n",
      "This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n",
      "\n",
      "Le chargement a nécessité le package : earth\n",
      "\n",
      "Warning message:\n",
      "\"le package 'earth' a été compilé avec la version R 4.4.2\"\n",
      "Le chargement a nécessité le package : Formula\n",
      "\n",
      "Le chargement a nécessité le package : plotmo\n",
      "\n",
      "Warning message:\n",
      "\"le package 'plotmo' a été compilé avec la version R 4.4.2\"\n",
      "Le chargement a nécessité le package : plotrix\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Lasso evaluation\n",
      "Lasso Outer fold 1/5: MSE = 109.07\n",
      "Lasso Outer fold 2/5: MSE = 145.72\n",
      "Lasso Outer fold 3/5: MSE = 148.38\n",
      "Lasso Outer fold 4/5: MSE = 128.17\n",
      "Lasso Outer fold 5/5: MSE = 141.67\n",
      "\n",
      "Starting Backward Selection evaluation\n",
      "Backward Outer fold 1/5: MSE = 106.16\n",
      "Backward Outer fold 2/5: MSE = 146.82\n",
      "Backward Outer fold 3/5: MSE = 157.84\n",
      "Backward Outer fold 4/5: MSE = 125.04\n",
      "Backward Outer fold 5/5: MSE = 135.06\n",
      "\n",
      "Tier 1 Summary:\n",
      "Number of Lasso Tier 1 features: 63\n",
      "Number of Backward Tier 1 features: 42\n",
      "Total unique Tier 1 features: 63\n",
      "Tier 1 features: X1, X10, X11, X13, X14, X15, X19, X2, X20, X21, X25, X27, X29, X3, X30, X31, X33, X36, X39, X4, X40, X42, X43, X44, X45, X46, X47, X48, X51, X52, X54, X55, X56, X57, X58, X59, X6, X61, X62, X65, X67, X68, X69, X71, X72, X74, X75, X76, X77, X8, X80, X81, X84, X87, X89, X90, X92, X93, X95, X96, X97, X98, X99 \n",
      "\n",
      "Tier 2 Summary:\n",
      "Number of Lasso Tier 2 features: 13\n",
      "Number of Backward Tier 2 features: 1\n",
      "Total unique Tier 2 features: 14\n",
      "Tier 2 features: X12, X13, X16, X28, X37, X41, X49, X5, X50, X63, X64, X7, X79, X88 \n",
      "\n",
      "Final Selection Summary:\n",
      "Selection type: intersection\n",
      "Number of selected features: 11\n",
      "Selected features: X13, X21, X29, X43, X44, X46, X57, X76, X8, X81, X92 \n",
      "\n",
      "Tier 1 Summary:\n",
      "Number of Lasso Tier 1 features: 63\n",
      "Number of Backward Tier 1 features: 42\n",
      "Total unique Tier 1 features: 63\n",
      "Tier 1 features: X1, X10, X11, X13, X14, X15, X19, X2, X20, X21, X25, X27, X29, X3, X30, X31, X33, X36, X39, X4, X40, X42, X43, X44, X45, X46, X47, X48, X51, X52, X54, X55, X56, X57, X58, X59, X6, X61, X62, X65, X67, X68, X69, X71, X72, X74, X75, X76, X77, X8, X80, X81, X84, X87, X89, X90, X92, X93, X95, X96, X97, X98, X99 \n",
      "\n",
      "Tier 2 Summary:\n",
      "Number of Lasso Tier 2 features: 13\n",
      "Number of Backward Tier 2 features: 1\n",
      "Total unique Tier 2 features: 14\n",
      "Tier 2 features: X12, X13, X16, X28, X37, X41, X49, X5, X50, X63, X64, X7, X79, X88 \n",
      "\n",
      "Final Selection Summary:\n",
      "Selection type: tier2\n",
      "Number of selected features: 24\n",
      "Selected features: X12, X13, X16, X21, X28, X29, X37, X41, X43, X44, X46, X49, X5, X50, X57, X63, X64, X7, X76, X79, X8, X81, X88, X92 \n",
      "\n",
      "Tier 1 Summary:\n",
      "Number of Lasso Tier 1 features: 63\n",
      "Number of Backward Tier 1 features: 42\n",
      "Total unique Tier 1 features: 63\n",
      "Tier 1 features: X1, X10, X11, X13, X14, X15, X19, X2, X20, X21, X25, X27, X29, X3, X30, X31, X33, X36, X39, X4, X40, X42, X43, X44, X45, X46, X47, X48, X51, X52, X54, X55, X56, X57, X58, X59, X6, X61, X62, X65, X67, X68, X69, X71, X72, X74, X75, X76, X77, X8, X80, X81, X84, X87, X89, X90, X92, X93, X95, X96, X97, X98, X99 \n",
      "\n",
      "Tier 2 Summary:\n",
      "Number of Lasso Tier 2 features: 13\n",
      "Number of Backward Tier 2 features: 1\n",
      "Total unique Tier 2 features: 14\n",
      "Tier 2 features: X12, X13, X16, X28, X37, X41, X49, X5, X50, X63, X64, X7, X79, X88 \n",
      "\n",
      "Final Selection Summary:\n",
      "Selection type: tier1\n",
      "Number of selected features: 63\n",
      "Selected features: X1, X10, X11, X13, X14, X15, X19, X2, X20, X21, X25, X27, X29, X3, X30, X31, X33, X36, X39, X4, X40, X42, X43, X44, X45, X46, X47, X48, X51, X52, X54, X55, X56, X57, X58, X59, X6, X61, X62, X65, X67, X68, X69, X71, X72, X74, X75, X76, X77, X8, X80, X81, X84, X87, X89, X90, X92, X93, X95, X96, X97, X98, X99 \n",
      "\n",
      "Tier 1 Summary:\n",
      "Number of Lasso Tier 1 features: 63\n",
      "Number of Backward Tier 1 features: 42\n",
      "Total unique Tier 1 features: 63\n",
      "Tier 1 features: X1, X10, X11, X13, X14, X15, X19, X2, X20, X21, X25, X27, X29, X3, X30, X31, X33, X36, X39, X4, X40, X42, X43, X44, X45, X46, X47, X48, X51, X52, X54, X55, X56, X57, X58, X59, X6, X61, X62, X65, X67, X68, X69, X71, X72, X74, X75, X76, X77, X8, X80, X81, X84, X87, X89, X90, X92, X93, X95, X96, X97, X98, X99 \n",
      "\n",
      "Tier 2 Summary:\n",
      "Number of Lasso Tier 2 features: 13\n",
      "Number of Backward Tier 2 features: 1\n",
      "Total unique Tier 2 features: 14\n",
      "Tier 2 features: X12, X13, X16, X28, X37, X41, X49, X5, X50, X63, X64, X7, X79, X88 \n",
      "\n",
      "Final Selection Summary:\n",
      "Selection type: union\n",
      "Number of selected features: 76\n",
      "Selected features: X1, X10, X11, X12, X13, X14, X15, X16, X19, X2, X20, X21, X25, X27, X28, X29, X3, X30, X31, X33, X36, X37, X39, X4, X40, X41, X42, X43, X44, X45, X46, X47, X48, X49, X5, X50, X51, X52, X54, X55, X56, X57, X58, X59, X6, X61, X62, X63, X64, X65, X67, X68, X69, X7, X71, X72, X74, X75, X76, X77, X79, X8, X80, X81, X84, X87, X88, X89, X90, X92, X93, X95, X96, X97, X98, X99 \n",
      "\n",
      "Evaluating models with intersection features:\n",
      "\n",
      "Starting GAM evaluation\n",
      "GAM Outer fold 1/5: MSE = 1147.83\n",
      "GAM Outer fold 2/5: MSE = 1493.79\n",
      "GAM Outer fold 3/5: MSE = 1526.69\n",
      "GAM Outer fold 4/5: MSE = 1018.16\n",
      "GAM Outer fold 5/5: MSE = 1679.70\n",
      "\n",
      "Starting MARS evaluation\n",
      "MARS Outer fold 1/5: MSE = 1196.53\n",
      "MARS Outer fold 2/5: MSE = 1420.65\n",
      "MARS Outer fold 3/5: MSE = 1506.27\n",
      "MARS Outer fold 4/5: MSE = 1132.26\n",
      "MARS Outer fold 5/5: MSE = 1843.31\n",
      "\n",
      "Evaluating models with tier2 features:\n",
      "\n",
      "Starting GAM evaluation\n",
      "GAM Outer fold 1/5: MSE = 1251.37\n",
      "GAM Outer fold 2/5: MSE = 1502.43\n",
      "GAM Outer fold 3/5: MSE = 1682.82\n",
      "GAM Outer fold 4/5: MSE = 1065.37\n",
      "GAM Outer fold 5/5: MSE = 1760.35\n",
      "\n",
      "Starting MARS evaluation\n",
      "MARS Outer fold 1/5: MSE = 1196.53\n",
      "MARS Outer fold 2/5: MSE = 1420.65\n",
      "MARS Outer fold 3/5: MSE = 1494.48\n",
      "MARS Outer fold 4/5: MSE = 1132.26\n",
      "MARS Outer fold 5/5: MSE = 1843.31\n",
      "\n",
      "Evaluating models with tier1 features:\n",
      "\n",
      "Starting GAM evaluation\n",
      "GAM Outer fold 1/5: MSE = 118.55\n",
      "GAM Outer fold 2/5: MSE = 144.86\n",
      "GAM Outer fold 3/5: MSE = 128.69\n",
      "GAM Outer fold 4/5: MSE = 119.49\n",
      "GAM Outer fold 5/5: MSE = 128.74\n",
      "\n",
      "Starting MARS evaluation\n",
      "MARS Outer fold 1/5: MSE = 391.74\n",
      "MARS Outer fold 2/5: MSE = 420.69\n",
      "MARS Outer fold 3/5: MSE = 422.75\n",
      "MARS Outer fold 4/5: MSE = 556.62\n",
      "MARS Outer fold 5/5: MSE = 383.16\n",
      "\n",
      "Evaluating models with union features:\n",
      "\n",
      "Starting GAM evaluation\n",
      "GAM Outer fold 1/5: MSE = 125.68\n",
      "GAM Outer fold 2/5: MSE = 151.03\n",
      "GAM Outer fold 3/5: MSE = 140.86\n",
      "GAM Outer fold 4/5: MSE = 119.37\n",
      "GAM Outer fold 5/5: MSE = 130.74\n",
      "\n",
      "Starting MARS evaluation\n",
      "MARS Outer fold 1/5: MSE = 391.74\n",
      "MARS Outer fold 2/5: MSE = 429.58\n",
      "MARS Outer fold 3/5: MSE = 422.75\n",
      "MARS Outer fold 4/5: MSE = 515.56\n",
      "MARS Outer fold 5/5: MSE = 383.16\n",
      "\n",
      "Final Results Summary:\n",
      "\n",
      "intersection Selection Method:\n",
      "GAM - MSE: 1373.23 (±277.89)\n",
      "MARS - MSE: 1419.80 (±282.57)\n",
      "tier2 Selection Method:\n",
      "GAM - MSE: 1452.47 (±291.82)\n",
      "MARS - MSE: 1417.45 (±281.71)\n",
      "tier1 Selection Method:\n",
      "GAM - MSE: 128.07 (±10.57)\n",
      "MARS - MSE: 434.99 (±70.19)\n",
      "union Selection Method:\n",
      "GAM - MSE: 133.54 (±12.55)\n",
      "MARS - MSE: 428.56 (±52.49)"
     ]
    }
   ],
   "source": [
    "# Package management\n",
    "required_packages <- c(\"glmnet\", \"caret\", \"dplyr\", \"MASS\", \"mgcv\", \"earth\")\n",
    "for(package in required_packages) {\n",
    "    if (!require(package, character.only = TRUE)) {\n",
    "        install.packages(package)\n",
    "        library(package, character.only = TRUE)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper function to extract important features\n",
    "get_important_features <- function(model_type, model, threshold = 0.01) {\n",
    "    if(model_type == \"lasso\") {\n",
    "        coefs <- as.matrix(coef(model, s=\"lambda.min\"))\n",
    "        features <- names(which(abs(coefs[-1,1]) > threshold))\n",
    "        return(features)\n",
    "    } else if(model_type == \"glm\") {\n",
    "        coefs <- coef(model)\n",
    "        features <- names(which(abs(coefs[-1]) > threshold))\n",
    "        return(features)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Lasso with nested CV\n",
    "evaluate_lasso_nested <- function(X, y, outer_folds=5, inner_folds=5) {\n",
    "    cat(\"\\nStarting Lasso evaluation\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    X <- as.matrix(X)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    \n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    feature_counts <- numeric(outer_folds)\n",
    "    important_features_list <- vector(\"list\", outer_folds)\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        X_train <- X[-outer_test_idx, ]\n",
    "        y_train <- y[-outer_test_idx]\n",
    "        X_test <- X[outer_test_idx, ]\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        cv_fit <- cv.glmnet(X_train, y_train, alpha=1, nfolds=inner_folds)\n",
    "        final_model <- glmnet(X_train, y_train, alpha=1, lambda=cv_fit$lambda.min)\n",
    "        \n",
    "        predictions <- predict(final_model, X_test, s=\"lambda.min\")\n",
    "        outer_scores[outer_fold] <- mean((y_test - predictions)^2)\n",
    "        \n",
    "        important_features_list[[outer_fold]] <- get_important_features(\"lasso\", final_model)\n",
    "        feature_counts[outer_fold] <- length(important_features_list[[outer_fold]])\n",
    "        \n",
    "        cat(sprintf(\"Lasso Outer fold %d/%d: MSE = %.2f\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold]))\n",
    "        flush.console()\n",
    "    }\n",
    "    \n",
    "    feature_freq <- table(unlist(important_features_list))\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores,\n",
    "        mean_features = mean(feature_counts),\n",
    "        sd_features = sd(feature_counts),\n",
    "        feature_frequency = feature_freq\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Backward selection with nested CV\n",
    "evaluate_backward_nested <- function(X, y, outer_folds=5) {\n",
    "    cat(\"\\nStarting Backward Selection evaluation\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    \n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    feature_counts <- numeric(outer_folds)\n",
    "    important_features_list <- vector(\"list\", outer_folds)\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        train_data <- data.frame(X[-outer_test_idx,], y=y[-outer_test_idx])\n",
    "        test_data <- data.frame(X[outer_test_idx,])\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        full_formula <- as.formula(paste(\"y ~\", paste(names(X), collapse = \" + \")))\n",
    "        model <- step(glm(full_formula, data=train_data),\n",
    "                     direction=\"backward\",\n",
    "                     k=log(nrow(train_data)),\n",
    "                     trace=0)\n",
    "        \n",
    "        predictions <- predict(model, newdata=test_data)\n",
    "        outer_scores[outer_fold] <- mean((y_test - predictions)^2)\n",
    "        \n",
    "        important_features_list[[outer_fold]] <- get_important_features(\"glm\", model)\n",
    "        feature_counts[outer_fold] <- length(important_features_list[[outer_fold]])\n",
    "        \n",
    "        cat(sprintf(\"Backward Outer fold %d/%d: MSE = %.2f\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold]))\n",
    "        flush.console()\n",
    "    }\n",
    "    \n",
    "    feature_freq <- table(unlist(important_features_list))\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores,\n",
    "        mean_features = mean(feature_counts),\n",
    "        sd_features = sd(feature_counts),\n",
    "        feature_frequency = feature_freq\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Feature selection function\n",
    "get_selected_features <- function(lasso_results, backward_results,\n",
    "                                selection_type = \"tier1\",\n",
    "                                fold_threshold_tier1 = 4,     \n",
    "                                fold_threshold_tier2 = 3,     \n",
    "                                top_corr_count = 10) {    \n",
    "    \n",
    "    # Top correlated variables (hardcoded based on your data)\n",
    "    top_corr_vars <- c(\"X92\", \"X43\", \"X57\", \"X8\", \"X76\", \"X44\", \"X81\", \"X29\", \"X46\", \"X21\")\n",
    "    \n",
    "    # Get features by frequency for each method and remove intercept if present\n",
    "    lasso_features <- names(lasso_results$feature_frequency)\n",
    "    lasso_features <- lasso_features[lasso_features != \"(Intercept)\"]\n",
    "    backward_features <- names(backward_results$feature_frequency)\n",
    "    backward_features <- backward_features[backward_features != \"(Intercept)\"]\n",
    "    \n",
    "    # Get Tier 1 features\n",
    "    lasso_tier1 <- lasso_features[lasso_results$feature_frequency[lasso_features] >= fold_threshold_tier1]\n",
    "    backward_tier1 <- backward_features[backward_results$feature_frequency[backward_features] >= fold_threshold_tier1]\n",
    "    \n",
    "    cat(\"\\nTier 1 Summary:\")\n",
    "    cat(\"\\nNumber of Lasso Tier 1 features:\", length(lasso_tier1))\n",
    "    cat(\"\\nNumber of Backward Tier 1 features:\", length(backward_tier1))\n",
    "    flush.console()\n",
    "    \n",
    "    tier1_features <- unique(c(lasso_tier1, backward_tier1))\n",
    "    cat(\"\\nTotal unique Tier 1 features:\", length(tier1_features))\n",
    "    cat(\"\\nTier 1 features:\", paste(sort(tier1_features), collapse=\", \"), \"\\n\")\n",
    "    # Get Tier 2 features\n",
    "    lasso_tier2 <- lasso_features[lasso_results$feature_frequency[lasso_features] >= fold_threshold_tier2 & \n",
    "                                 lasso_results$feature_frequency[lasso_features] < fold_threshold_tier1]\n",
    "    backward_tier2 <- backward_features[backward_results$feature_frequency[backward_features] >= fold_threshold_tier2 & \n",
    "                                      backward_results$feature_frequency[backward_features] < fold_threshold_tier1]\n",
    "    \n",
    "    cat(\"\\nTier 2 Summary:\")\n",
    "    cat(\"\\nNumber of Lasso Tier 2 features:\", length(lasso_tier2))\n",
    "    cat(\"\\nNumber of Backward Tier 2 features:\", length(backward_tier2))\n",
    "    flush.console()\n",
    "    tier2_features <- unique(c(lasso_tier2, backward_tier2))\n",
    "    cat(\"\\nTotal unique Tier 2 features:\", length(tier2_features))\n",
    "    cat(\"\\nTier 2 features:\", paste(sort(tier2_features), collapse=\", \"), \"\\n\")\n",
    "    selected_features <- switch(selection_type,\n",
    "        \"tier1\" = tier1_features,\n",
    "        \"tier2\" = tier2_features,\n",
    "        \"intersection\" = unique(intersect(tier1_features, tier2_features)),\n",
    "        \"union\" = unique(union(tier1_features, tier2_features))\n",
    "    )\n",
    "    \n",
    "    selected_features <- unique(c(selected_features, top_corr_vars))\n",
    "    \n",
    "    cat(\"\\nFinal Selection Summary:\")\n",
    "    cat(sprintf(\"\\nSelection type: %s\", selection_type))\n",
    "    cat(sprintf(\"\\nNumber of selected features: %d\", length(selected_features)))\n",
    "    cat(\"\\nSelected features:\", paste(sort(selected_features), collapse=\", \"), \"\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    return(selected_features)\n",
    "}\n",
    "\n",
    "# GAM with scaling and descaling\n",
    "evaluate_gam_nested <- function(X, y, selected_features, outer_folds=5) {\n",
    "    cat(\"\\nStarting GAM evaluation\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        # Split data\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        X_train <- X[selected_features][-outer_test_idx,]\n",
    "        y_train <- y[-outer_test_idx]\n",
    "        X_test <- X[selected_features][outer_test_idx,]\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        # Scale features and response\n",
    "        X_scale <- scale(X_train)\n",
    "        X_test_scale <- scale(X_test, center=attr(X_scale, \"scaled:center\"), \n",
    "                            scale=attr(X_scale, \"scaled:scale\"))\n",
    "        y_scale <- scale(y_train)\n",
    "        \n",
    "        # Create scaled training data\n",
    "        train_data <- data.frame(X_scale)\n",
    "        train_data$y <- scale(y_train)\n",
    "        \n",
    "        # Create GAM formula\n",
    "        gam_terms <- paste(sprintf(\"s(%s, bs='cr')\", selected_features), collapse=\" + \")\n",
    "        gam_formula <- as.formula(paste(\"y ~\", gam_terms))\n",
    "        \n",
    "        # Fit model on scaled data\n",
    "        model <- gam(gam_formula, data=train_data, method=\"REML\")\n",
    "        \n",
    "        # Make predictions and descale\n",
    "        predictions_scaled <- predict(model, newdata=data.frame(X_test_scale))\n",
    "        predictions <- predictions_scaled * attr(y_scale, \"scaled:scale\") + \n",
    "                      attr(y_scale, \"scaled:center\")\n",
    "        \n",
    "        # Calculate MSE\n",
    "        outer_scores[outer_fold] <- mean((y_test - predictions)^2)\n",
    "        \n",
    "        cat(sprintf(\"GAM Outer fold %d/%d: MSE = %.2f\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold]))\n",
    "        flush.console()\n",
    "    }\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores\n",
    "    ))\n",
    "}\n",
    "\n",
    "# MARS with scaling and descaling\n",
    "evaluate_mars_nested <- function(X, y, selected_features, outer_folds=5) {\n",
    "    cat(\"\\nStarting MARS evaluation\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    \n",
    "    param_grid <- expand.grid(\n",
    "        degree = c(1, 2),\n",
    "        nprune = seq(10, 30, by=5),\n",
    "        thresh = c(0.001, 0.01)\n",
    "    )\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        # Split data\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        X_train <- X[selected_features][-outer_test_idx,]\n",
    "        y_train <- y[-outer_test_idx]\n",
    "        X_test <- X[selected_features][outer_test_idx,]\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        # Scale features and response\n",
    "        X_scale <- scale(X_train)\n",
    "        X_test_scale <- scale(X_test, center=attr(X_scale, \"scaled:center\"), \n",
    "                            scale=attr(X_scale, \"scaled:scale\"))\n",
    "        y_scale <- scale(y_train)\n",
    "        \n",
    "        best_mse <- Inf\n",
    "        for(i in 1:nrow(param_grid)) {\n",
    "            model <- earth(x=X_scale, y=y_scale,\n",
    "                         degree=param_grid$degree[i],\n",
    "                         nprune=param_grid$nprune[i],\n",
    "                         thresh=param_grid$thresh[i],\n",
    "                         minspan=5,\n",
    "                         pmethod=\"backward\")\n",
    "            \n",
    "            # Make predictions and descale\n",
    "            predictions_scaled <- predict(model, X_test_scale)\n",
    "            predictions <- predictions_scaled * attr(y_scale, \"scaled:scale\") + \n",
    "                          attr(y_scale, \"scaled:center\")\n",
    "            \n",
    "            mse <- mean((y_test - predictions)^2)\n",
    "            \n",
    "            if(mse < best_mse) {\n",
    "                best_mse <- mse\n",
    "                best_model <- model\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        outer_scores[outer_fold] <- best_mse\n",
    "        cat(sprintf(\"MARS Outer fold %d/%d: MSE = %.2f\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold]))\n",
    "        flush.console()\n",
    "    }\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores\n",
    "    ))\n",
    "}\n",
    "\n",
    "\n",
    "# Read data\n",
    "X.reg <- read.table(\"a24_reg_app.txt\")\n",
    "X <- X.reg[, -ncol(X.reg)]\n",
    "y <- X.reg$y\n",
    "\n",
    "# Phase 1: Feature Selection\n",
    "lasso_results <- evaluate_lasso_nested(X, y)\n",
    "backward_results <- evaluate_backward_nested(X, y)\n",
    "\n",
    "# Get selected features for each method\n",
    "selection_methods <- c(\"intersection\",\"tier2\",\"tier1\", \"union\")\n",
    "selected_features_list <- lapply(selection_methods, function(method) {\n",
    "    get_selected_features(lasso_results, backward_results, selection_type=method)\n",
    "})\n",
    "names(selected_features_list) <- selection_methods\n",
    "\n",
    "# Phase 2: Final Models\n",
    "results <- list()\n",
    "for(method in selection_methods) {\n",
    "    cat(sprintf(\"\\nEvaluating models with %s features:\\n\", method))\n",
    "    flush.console()\n",
    "    features <- selected_features_list[[method]]\n",
    "    \n",
    "    results[[method]] <- list(\n",
    "        gam = evaluate_gam_nested(X, y, features),\n",
    "        mars = evaluate_mars_nested(X, y, features)\n",
    "    )\n",
    "}\n",
    "\n",
    "# Print final summary\n",
    "cat(\"\\nFinal Results Summary:\\n\")\n",
    "for(method in selection_methods) {\n",
    "    cat(sprintf(\"\\n%s Selection Method:\", method))\n",
    "    cat(sprintf(\"\\nGAM - MSE: %.2f (±%.2f)\", \n",
    "               results[[method]]$gam$mean_mse,\n",
    "               results[[method]]$gam$sd_mse))\n",
    "    cat(sprintf(\"\\nMARS - MSE: %.2f (±%.2f)\", \n",
    "               results[[method]]$mars$mean_mse,\n",
    "               results[[method]]$mars$sd_mse))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Le chargement a nécessité le package : corrplot\n",
      "\n",
      "corrplot 0.95 loaded\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "\n",
      "Top 10 correlated variables with target:\n",
      "    variable pearson_cor spearman_cor abs_pearson abs_spearman\n",
      "X92      X92   0.3775479    0.3652928   0.3775479    0.3652928\n",
      "X43      X43   0.3232837    0.3230231   0.3232837    0.3230231\n",
      "X57      X57  -0.2718024   -0.2617451   0.2718024    0.2617451\n",
      "X8        X8   0.2676847    0.2717730   0.2676847    0.2717730\n",
      "X76      X76  -0.2495047   -0.2459881   0.2495047    0.2459881\n",
      "X44      X44  -0.2283222   -0.2406929   0.2283222    0.2406929\n",
      "X81      X81  -0.2148017   -0.2068499   0.2148017    0.2068499\n",
      "X29      X29   0.2060082    0.1970644   0.2060082    0.1970644\n",
      "X46      X46  -0.1957796   -0.1916278   0.1957796    0.1916278\n",
      "X21      X21   0.1897579    0.1726961   0.1897579    0.1726961\n",
      "\n",
      "Starting Lasso evaluation\n",
      "Lasso Outer fold 1/5: MSE = 109.07, Features = 82\n",
      "Lasso Outer fold 2/5: MSE = 145.72, Features = 82\n",
      "Lasso Outer fold 3/5: MSE = 148.38, Features = 68\n",
      "Lasso Outer fold 4/5: MSE = 128.17, Features = 80\n",
      "Lasso Outer fold 5/5: MSE = 141.67, Features = 70\n",
      "\n",
      "Starting Backward Selection evaluation\n",
      "Backward Outer fold 1/5: MSE = 106.16, Features = 43\n",
      "Backward Outer fold 2/5: MSE = 146.82, Features = 45\n",
      "Backward Outer fold 3/5: MSE = 157.84, Features = 43\n",
      "Backward Outer fold 4/5: MSE = 125.04, Features = 44\n",
      "Backward Outer fold 5/5: MSE = 135.06, Features = 43\n",
      "\n",
      "=== COMPREHENSIVE ANALYSIS RESULTS ===\n",
      "\n",
      "1. BASELINE MODELS\n",
      "-----------------\n",
      "Lasso - Mean MSE: 134.60 (±16.26)\n",
      "Lasso feature selection stability:\n",
      " 1  2  3  4  5 \n",
      " 6 14 13  6 57 \n",
      "\n",
      "Backward - Mean MSE: 134.18 (±19.93)\n",
      "Backward feature selection stability:\n",
      " 1  2  3  4  5 \n",
      " 5  1  1  2 40 \n",
      "\n",
      "\n",
      "2. OPTIMIZED FEATURE SELECTION RESULTS\n",
      "-------------------------------------\n",
      "\n",
      "TIER1PLUS Selection Method:\n",
      "Number of features: 57\n",
      "Selected features: X1, X10, X13, X14, X15, X19, X2, X20, X21, X25, X27, X29, X3, X30, X31, X33, X39, X4, X40, X42, X43, X44, X45, X46, X47, X48, X51, X54, X55, X56, X57, X58, X59, X6, X61, X62, X65, X67, X68, X69, X71, X72, X74, X75, X76, X77, X8, X80, X81, X84, X87, X89, X92, X93, X96, X97, X99\n",
      "Starting GAM evaluation with 57 features\n",
      "GAM Outer fold 1/5: MSE = 113.69\n",
      "GAM Outer fold 2/5: MSE = 143.76\n",
      "GAM Outer fold 3/5: MSE = 129.88\n",
      "GAM Outer fold 4/5: MSE = 105.80\n",
      "GAM Outer fold 5/5: MSE = 123.82\n",
      "\n",
      "GAM Performance - MSE: 123.39 (±14.67)\n",
      "Feature overlap with top correlations: 10\n",
      "\n",
      "WEIGHTED Selection Method:\n",
      "Number of features: 50\n",
      "Selected features: X1, X10, X13, X15, X19, X2, X20, X21, X25, X27, X29, X3, X30, X31, X33, X4, X40, X42, X43, X44, X45, X46, X47, X48, X51, X54, X55, X56, X57, X58, X59, X6, X61, X62, X67, X69, X71, X72, X76, X77, X8, X80, X81, X84, X87, X89, X92, X93, X96, X99\n",
      "Starting GAM evaluation with 50 features\n",
      "GAM Outer fold 1/5: MSE = 112.38\n",
      "GAM Outer fold 2/5: MSE = 138.34\n",
      "GAM Outer fold 3/5: MSE = 132.86\n",
      "GAM Outer fold 4/5: MSE = 108.35\n",
      "GAM Outer fold 5/5: MSE = 113.46\n",
      "\n",
      "GAM Performance - MSE: 121.08 (±13.53)\n",
      "Feature overlap with top correlations: 10\n",
      "\n",
      "STABLE Selection Method:\n",
      "Number of features: 90\n",
      "Selected features: X1, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X2, X20, X21, X22, X25, X26, X27, X28, X29, X3, X30, X31, X32, X33, X34, X36, X37, X39, X4, X40, X41, X42, X43, X44, X45, X46, X47, X48, X49, X5, X50, X51, X52, X53, X54, X55, X56, X57, X58, X59, X6, X60, X61, X62, X63, X64, X65, X66, X67, X68, X69, X7, X71, X72, X74, X75, X76, X77, X78, X79, X8, X80, X81, X83, X84, X85, X86, X87, X88, X89, X9, X90, X92, X93, X95, X96, X97, X98, X99\n",
      "Starting GAM evaluation with 90 features\n",
      "GAM Outer fold 1/5: MSE = 134.64\n",
      "GAM Outer fold 2/5: MSE = 182.45\n",
      "GAM Outer fold 3/5: MSE = 146.62\n",
      "GAM Outer fold 4/5: MSE = 132.91\n",
      "GAM Outer fold 5/5: MSE = 145.29\n",
      "\n",
      "GAM Performance - MSE: 148.38 (±20.01)\n",
      "Feature overlap with top correlations: 10\n",
      "\n",
      "3. COMPARATIVE ANALYSIS\n",
      "----------------------\n",
      "Performance Summary (sorted by MSE):\n",
      "         Method Features      MSE       SD\n",
      "4  GAM weighted       50 121.0776 13.53208\n",
      "3 GAM tier1plus       57 123.3928 14.66769\n",
      "2      Backward       49 134.1845 19.92982\n",
      "1         Lasso       96 134.6018 16.25654\n",
      "5    GAM stable       90 148.3823 20.00924\n",
      "\n",
      "\n",
      "4. RECOMMENDATIONS\n",
      "----------------\n",
      "Best performing method: GAM weighted\n",
      "Number of features: 50\n",
      "Mean MSE: 121.08 (±13.53)\n",
      "Recommended features: X1, X10, X13, X15, X19, X2, X20, X21, X25, X27, X29, X3, X30, X31, X33, X4, X40, X42, X43, X44, X45, X46, X47, X48, X51, X54, X55, X56, X57, X58, X59, X6, X61, X62, X67, X69, X71, X72, X76, X77, X8, X80, X81, X84, X87, X89, X92, X93, X96, X99"
     ]
    }
   ],
   "source": [
    "# Package management\n",
    "required_packages <- c(\"glmnet\", \"caret\", \"dplyr\", \"MASS\", \"mgcv\", \"earth\", \"corrplot\")\n",
    "for(package in required_packages) {\n",
    "    if (!require(package, character.only = TRUE)) {\n",
    "        install.packages(package)\n",
    "        library(package, character.only = TRUE)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper function to extract important features with coefficients\n",
    "get_important_features <- function(model_type, model, threshold = 0.01) {\n",
    "    if(model_type == \"lasso\") {\n",
    "        coefs <- as.matrix(coef(model, s=\"lambda.min\"))\n",
    "        features <- names(which(abs(coefs[-1,1]) > threshold))\n",
    "        return(list(\n",
    "            features = features,\n",
    "            coefficients = coefs[-1,1][abs(coefs[-1,1]) > threshold]\n",
    "        ))\n",
    "    } else if(model_type == \"glm\") {\n",
    "        coefs <- coef(model)\n",
    "        features <- names(which(abs(coefs[-1]) > threshold))\n",
    "        return(list(\n",
    "            features = features,\n",
    "            coefficients = coefs[-1][abs(coefs[-1]) > threshold]\n",
    "        ))\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to calculate correlations with target\n",
    "get_top_correlations <- function(X, y, top_n = 10) {\n",
    "    correlations <- sapply(X, function(x) cor(x, y, method = \"pearson\"))\n",
    "    spearman_cors <- sapply(X, function(x) cor(x, y, method = \"spearman\"))\n",
    "    \n",
    "    cor_df <- data.frame(\n",
    "        variable = names(correlations),\n",
    "        pearson_cor = correlations,\n",
    "        spearman_cor = spearman_cors,\n",
    "        abs_pearson = abs(correlations),\n",
    "        abs_spearman = abs(spearman_cors)\n",
    "    )\n",
    "    \n",
    "    cor_df <- cor_df[order(-cor_df$abs_pearson), ]\n",
    "    return(list(\n",
    "        top_n = cor_df[1:top_n, ],\n",
    "        all_correlations = cor_df\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Lasso with nested CV and detailed feature tracking\n",
    "evaluate_lasso_nested <- function(X, y, outer_folds=5, inner_folds=5) {\n",
    "    cat(\"\\nStarting Lasso evaluation\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    X <- as.matrix(X)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    \n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    feature_info_list <- vector(\"list\", outer_folds)\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        X_train <- X[-outer_test_idx, ]\n",
    "        y_train <- y[-outer_test_idx]\n",
    "        X_test <- X[outer_test_idx, ]\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        cv_fit <- cv.glmnet(X_train, y_train, alpha=1, nfolds=inner_folds)\n",
    "        final_model <- glmnet(X_train, y_train, alpha=1, lambda=cv_fit$lambda.min)\n",
    "        \n",
    "        predictions <- predict(final_model, X_test, s=\"lambda.min\")\n",
    "        outer_scores[outer_fold] <- mean((y_test - predictions)^2)\n",
    "        \n",
    "        feature_info <- get_important_features(\"lasso\", final_model)\n",
    "        feature_info_list[[outer_fold]] <- feature_info\n",
    "        \n",
    "        cat(sprintf(\"Lasso Outer fold %d/%d: MSE = %.2f, Features = %d\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold],\n",
    "                   length(feature_info$features)))\n",
    "        flush.console()\n",
    "    }\n",
    "    \n",
    "    # Aggregate feature information\n",
    "    all_features <- unique(unlist(lapply(feature_info_list, function(x) x$features)))\n",
    "    feature_matrix <- matrix(0, nrow=length(all_features), ncol=outer_folds)\n",
    "    rownames(feature_matrix) <- all_features\n",
    "    \n",
    "    for(i in 1:outer_folds) {\n",
    "        feature_matrix[feature_info_list[[i]]$features, i] <- \n",
    "            abs(feature_info_list[[i]]$coefficients)\n",
    "    }\n",
    "    \n",
    "    feature_summary <- data.frame(\n",
    "        feature = all_features,\n",
    "        frequency = rowSums(feature_matrix > 0),\n",
    "        mean_coef = rowMeans(feature_matrix),\n",
    "        sd_coef = apply(feature_matrix, 1, sd)\n",
    "    )\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores,\n",
    "        feature_summary = feature_summary\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Backward selection with nested CV and detailed feature tracking\n",
    "evaluate_backward_nested <- function(X, y, outer_folds=5) {\n",
    "    cat(\"\\nStarting Backward Selection evaluation\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    \n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    feature_info_list <- vector(\"list\", outer_folds)\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        train_data <- data.frame(X[-outer_test_idx,], y=y[-outer_test_idx])\n",
    "        test_data <- data.frame(X[outer_test_idx,])\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        full_formula <- as.formula(paste(\"y ~\", paste(names(X), collapse = \" + \")))\n",
    "        model <- step(glm(full_formula, data=train_data),\n",
    "                     direction=\"backward\",\n",
    "                     k=log(nrow(train_data)),\n",
    "                     trace=0)\n",
    "        \n",
    "        predictions <- predict(model, newdata=test_data)\n",
    "        outer_scores[outer_fold] <- mean((y_test - predictions)^2)\n",
    "        \n",
    "        feature_info <- get_important_features(\"glm\", model)\n",
    "        feature_info_list[[outer_fold]] <- feature_info\n",
    "        \n",
    "        cat(sprintf(\"Backward Outer fold %d/%d: MSE = %.2f, Features = %d\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold],\n",
    "                   length(feature_info$features)))\n",
    "        flush.console()\n",
    "    }\n",
    "    \n",
    "    # Aggregate feature information\n",
    "    all_features <- unique(unlist(lapply(feature_info_list, function(x) x$features)))\n",
    "    feature_matrix <- matrix(0, nrow=length(all_features), ncol=outer_folds)\n",
    "    rownames(feature_matrix) <- all_features\n",
    "    \n",
    "    for(i in 1:outer_folds) {\n",
    "        feature_matrix[feature_info_list[[i]]$features, i] <- \n",
    "            abs(feature_info_list[[i]]$coefficients)\n",
    "    }\n",
    "    \n",
    "    feature_summary <- data.frame(\n",
    "        feature = all_features,\n",
    "        frequency = rowSums(feature_matrix > 0),\n",
    "        mean_coef = rowMeans(feature_matrix),\n",
    "        sd_coef = apply(feature_matrix, 1, sd)\n",
    "    )\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores,\n",
    "        feature_summary = feature_summary\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Optimized feature selection\n",
    "get_optimized_features <- function(lasso_results, backward_results, cor_results, \n",
    "                                 selection_methods = c(\"tier1plus\", \"weighted\", \"stable\")) {\n",
    "    # Get correlation information\n",
    "    top_cors <- cor_results$top_n$variable\n",
    "    \n",
    "    results <- list()\n",
    "    \n",
    "    # Tier1+ selection\n",
    "    if(\"tier1plus\" %in% selection_methods) {\n",
    "        # Variables in all 5 folds\n",
    "        lasso_perfect <- lasso_results$feature_summary$feature[\n",
    "            lasso_results$feature_summary$frequency == 5]\n",
    "        backward_perfect <- backward_results$feature_summary$feature[\n",
    "            backward_results$feature_summary$frequency == 5]\n",
    "        \n",
    "        # Variables in both methods with freq >= 4\n",
    "        lasso_freq4 <- lasso_results$feature_summary$feature[\n",
    "            lasso_results$feature_summary$frequency >= 4]\n",
    "        backward_freq4 <- backward_results$feature_summary$feature[\n",
    "            backward_results$feature_summary$frequency >= 4]\n",
    "        both_freq4 <- intersect(lasso_freq4, backward_freq4)\n",
    "        \n",
    "        tier1plus <- unique(c(lasso_perfect, backward_perfect, both_freq4, top_cors))\n",
    "        results$tier1plus <- tier1plus\n",
    "    }\n",
    "    \n",
    "    # Weighted approach\n",
    "    if(\"weighted\" %in% selection_methods) {\n",
    "        # Combine information from all sources\n",
    "        all_features <- unique(c(\n",
    "            lasso_results$feature_summary$feature,\n",
    "            backward_results$feature_summary$feature\n",
    "        ))\n",
    "        \n",
    "        weighted_scores <- data.frame(\n",
    "            feature = all_features,\n",
    "            score = 0\n",
    "        )\n",
    "        \n",
    "        # Add scores based on different criteria\n",
    "        for(feature in all_features) {\n",
    "            # Lasso frequency and coefficient\n",
    "            if(feature %in% lasso_results$feature_summary$feature) {\n",
    "                lasso_idx <- which(lasso_results$feature_summary$feature == feature)\n",
    "                weighted_scores$score[weighted_scores$feature == feature] <- \n",
    "                    weighted_scores$score[weighted_scores$feature == feature] +\n",
    "                    lasso_results$feature_summary$frequency[lasso_idx] * 0.2 +\n",
    "                    abs(lasso_results$feature_summary$mean_coef[lasso_idx]) * 0.3\n",
    "            }\n",
    "            \n",
    "            # Backward frequency and coefficient\n",
    "            if(feature %in% backward_results$feature_summary$feature) {\n",
    "                backward_idx <- which(backward_results$feature_summary$feature == feature)\n",
    "                weighted_scores$score[weighted_scores$feature == feature] <- \n",
    "                    weighted_scores$score[weighted_scores$feature == feature] +\n",
    "                    backward_results$feature_summary$frequency[backward_idx] * 0.2 +\n",
    "                    abs(backward_results$feature_summary$mean_coef[backward_idx]) * 0.3\n",
    "            }\n",
    "            \n",
    "            # Correlation bonus\n",
    "            if(feature %in% top_cors) {\n",
    "                cor_idx <- which(cor_results$all_correlations$variable == feature)\n",
    "                weighted_scores$score[weighted_scores$feature == feature] <- \n",
    "                    weighted_scores$score[weighted_scores$feature == feature] +\n",
    "                    abs(cor_results$all_correlations$pearson_cor[cor_idx]) * 0.5\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Select top features based on weighted score\n",
    "        weighted_scores <- weighted_scores[order(-weighted_scores$score), ]\n",
    "        results$weighted <- weighted_scores$feature[1:min(50, nrow(weighted_scores))]\n",
    "    }\n",
    "    \n",
    "    # Stable selection (based on cross-validation performance)\n",
    "    if(\"stable\" %in% selection_methods) {\n",
    "        # Get features from better performing folds\n",
    "        lasso_good_folds <- which(lasso_results$all_scores < median(lasso_results$all_scores))\n",
    "        backward_good_folds <- which(backward_results$all_scores < median(backward_results$all_scores))\n",
    "        \n",
    "        # Select features that appear in majority of good folds\n",
    "        stable_features <- unique(c(\n",
    "            lasso_results$feature_summary$feature[\n",
    "                lasso_results$feature_summary$frequency >= length(lasso_good_folds)],\n",
    "            backward_results$feature_summary$feature[\n",
    "                backward_results$feature_summary$frequency >= length(backward_good_folds)]\n",
    "        ))\n",
    "        \n",
    "        results$stable <- stable_features\n",
    "    }\n",
    "    \n",
    "    return(results)\n",
    "}\n",
    "\n",
    "# GAM evaluation\n",
    "evaluate_gam_nested <- function(X, y, selected_features, outer_folds=5) {\n",
    "    cat(sprintf(\"\\nStarting GAM evaluation with %d features\\n\", length(selected_features)))\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    \n",
    "    gam_terms <- paste(sprintf(\"s(%s, bs='cr')\", selected_features), collapse=\" + \")\n",
    "    gam_formula <- as.formula(paste(\"y ~\", gam_terms))\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        train_data <- data.frame(X[selected_features][-outer_test_idx,], \n",
    "                               y=y[-outer_test_idx])\n",
    "        test_data <- data.frame(X[selected_features][outer_test_idx,])\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        model <- gam(gam_formula, data=train_data, method=\"REML\")\n",
    "        predictions <- predict(model, newdata=test_data)\n",
    "        outer_scores[outer_fold] <- mean((y_test - predictions)^2)\n",
    "        \n",
    "        cat(sprintf(\"GAM Outer fold %d/%d: MSE = %.2f\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold]))\n",
    "        flush.console()\n",
    "    }\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Main execution\n",
    "main <- function() {\n",
    "    # Read data\n",
    "    X.reg <- read.table(\"a24_reg_app.txt\")\n",
    "    cat(\"Data loaded successfully\\n\")\n",
    "    X <- X.reg[, -ncol(X.reg)]\n",
    "    y <- X.reg$y\n",
    "    \n",
    "    # Get correlation information\n",
    "    cor_results <- get_top_correlations(X, y)\n",
    "    cat(\"\\nTop 10 correlated variables with target:\\n\")\n",
    "    print(cor_results$top_n)\n",
    "    \n",
    "    # Phase 1: Initial feature selection\n",
    "    lasso_results <- evaluate_lasso_nested(X, y)\n",
    "    backward_results <- evaluate_backward_nested(X, y)\n",
    "    \n",
    "    # Phase 2: Optimized feature selection\n",
    "    selected_features <- get_optimized_features(lasso_results, backward_results, cor_results)\n",
    "    \n",
    "    # Phase 3: Evaluate with different feature sets\n",
    "    results <- list()\n",
    "    \n",
    "    # Print detailed summary\n",
    "    cat(\"\\n=== COMPREHENSIVE ANALYSIS RESULTS ===\\n\")\n",
    "    \n",
    "    # 1. Baseline Results\n",
    "    cat(\"\\n1. BASELINE MODELS\")\n",
    "    cat(\"\\n-----------------\")\n",
    "    cat(sprintf(\"\\nLasso - Mean MSE: %.2f (±%.2f)\", \n",
    "                lasso_results$mean_mse, lasso_results$sd_mse))\n",
    "    cat(\"\\nLasso feature selection stability:\")\n",
    "    print(table(lasso_results$feature_summary$frequency))\n",
    "    \n",
    "    cat(sprintf(\"\\nBackward - Mean MSE: %.2f (±%.2f)\", \n",
    "                backward_results$mean_mse, backward_results$sd_mse))\n",
    "    cat(\"\\nBackward feature selection stability:\")\n",
    "    print(table(backward_results$feature_summary$frequency))\n",
    "    \n",
    "    # 2. Optimized Results\n",
    "    cat(\"\\n\\n2. OPTIMIZED FEATURE SELECTION RESULTS\")\n",
    "    cat(\"\\n-------------------------------------\")\n",
    "    for(method in names(selected_features)) {\n",
    "        cat(sprintf(\"\\n\\n%s Selection Method:\", toupper(method)))\n",
    "        cat(sprintf(\"\\nNumber of features: %d\", length(selected_features[[method]])))\n",
    "        cat(\"\\nSelected features:\", paste(sort(selected_features[[method]]), collapse=\", \"))\n",
    "        \n",
    "        # Evaluate GAM with this feature set\n",
    "        results[[method]] <- evaluate_gam_nested(X, y, selected_features[[method]])\n",
    "        \n",
    "        cat(sprintf(\"\\nGAM Performance - MSE: %.2f (±%.2f)\", \n",
    "                   results[[method]]$mean_mse, results[[method]]$sd_mse))\n",
    "        \n",
    "        # Feature overlap analysis\n",
    "        cat(\"\\nFeature overlap with top correlations:\", \n",
    "            length(intersect(selected_features[[method]], cor_results$top_n$variable)))\n",
    "    }\n",
    "    \n",
    "    # 3. Comparative Analysis\n",
    "    cat(\"\\n\\n3. COMPARATIVE ANALYSIS\")\n",
    "    cat(\"\\n----------------------\")\n",
    "    \n",
    "    # Create performance summary\n",
    "    performance_summary <- data.frame(\n",
    "        Method = character(),\n",
    "        Features = numeric(),\n",
    "        MSE = numeric(),\n",
    "        SD = numeric(),\n",
    "        stringsAsFactors = FALSE\n",
    "    )\n",
    "    \n",
    "    # Add baseline methods\n",
    "    performance_summary <- rbind(performance_summary, \n",
    "        data.frame(\n",
    "            Method = \"Lasso\",\n",
    "            Features = nrow(lasso_results$feature_summary),\n",
    "            MSE = lasso_results$mean_mse,\n",
    "            SD = lasso_results$sd_mse\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    performance_summary <- rbind(performance_summary,\n",
    "        data.frame(\n",
    "            Method = \"Backward\",\n",
    "            Features = nrow(backward_results$feature_summary),\n",
    "            MSE = backward_results$mean_mse,\n",
    "            SD = backward_results$sd_mse\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add optimized methods\n",
    "    for(method in names(results)) {\n",
    "        performance_summary <- rbind(performance_summary,\n",
    "            data.frame(\n",
    "                Method = paste(\"GAM\", method),\n",
    "                Features = length(selected_features[[method]]),\n",
    "                MSE = results[[method]]$mean_mse,\n",
    "                SD = results[[method]]$sd_mse\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Sort by MSE\n",
    "    performance_summary <- performance_summary[order(performance_summary$MSE), ]\n",
    "    \n",
    "    cat(\"\\nPerformance Summary (sorted by MSE):\\n\")\n",
    "    print(performance_summary)\n",
    "    \n",
    "    # 4. Recommendations\n",
    "    cat(\"\\n\\n4. RECOMMENDATIONS\")\n",
    "    cat(\"\\n----------------\")\n",
    "    best_method <- performance_summary$Method[1]\n",
    "    best_features <- selected_features[[gsub(\"GAM \", \"\", best_method)]]\n",
    "    \n",
    "    cat(sprintf(\"\\nBest performing method: %s\", best_method))\n",
    "    cat(sprintf(\"\\nNumber of features: %d\", length(best_features)))\n",
    "    cat(sprintf(\"\\nMean MSE: %.2f (±%.2f)\", \n",
    "                performance_summary$MSE[1], \n",
    "                performance_summary$SD[1]))\n",
    "    cat(\"\\nRecommended features:\", paste(sort(best_features), collapse=\", \"))\n",
    "    \n",
    "    # Return all results for further analysis if needed\n",
    "    return(list(\n",
    "        baseline = list(\n",
    "            lasso = lasso_results,\n",
    "            backward = backward_results\n",
    "        ),\n",
    "        optimized = results,\n",
    "        selected_features = selected_features,\n",
    "        performance_summary = performance_summary,\n",
    "        correlations = cor_results\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Run the analysis\n",
    "results <- main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Le chargement a nécessité le package : glmnet\n",
      "\n",
      "Le chargement a nécessité le package : Matrix\n",
      "\n",
      "Loaded glmnet 4.1-8\n",
      "\n",
      "Le chargement a nécessité le package : caret\n",
      "\n",
      "Le chargement a nécessité le package : ggplot2\n",
      "\n",
      "Le chargement a nécessité le package : lattice\n",
      "\n",
      "Le chargement a nécessité le package : dplyr\n",
      "\n",
      "\n",
      "Attachement du package : 'dplyr'\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Le chargement a nécessité le package : MASS\n",
      "\n",
      "\n",
      "Attachement du package : 'MASS'\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:dplyr':\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "Le chargement a nécessité le package : mgcv\n",
      "\n",
      "Le chargement a nécessité le package : nlme\n",
      "\n",
      "\n",
      "Attachement du package : 'nlme'\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis 'package:dplyr':\n",
      "\n",
      "    collapse\n",
      "\n",
      "\n",
      "This is mgcv 1.9-1. For overview type 'help(\"mgcv-package\")'.\n",
      "\n",
      "Le chargement a nécessité le package : earth\n",
      "\n",
      "Warning message:\n",
      "\"le package 'earth' a été compilé avec la version R 4.4.2\"\n",
      "Le chargement a nécessité le package : Formula\n",
      "\n",
      "Le chargement a nécessité le package : plotmo\n",
      "\n",
      "Warning message:\n",
      "\"le package 'plotmo' a été compilé avec la version R 4.4.2\"\n",
      "Le chargement a nécessité le package : plotrix\n",
      "\n",
      "Le chargement a nécessité le package : corrplot\n",
      "\n",
      "corrplot 0.95 loaded\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "\n",
      "Top 10 correlated variables with target:\n",
      "    variable pearson_cor spearman_cor abs_pearson abs_spearman\n",
      "X92      X92   0.3775479    0.3652928   0.3775479    0.3652928\n",
      "X43      X43   0.3232837    0.3230231   0.3232837    0.3230231\n",
      "X57      X57  -0.2718024   -0.2617451   0.2718024    0.2617451\n",
      "X8        X8   0.2676847    0.2717730   0.2676847    0.2717730\n",
      "X76      X76  -0.2495047   -0.2459881   0.2495047    0.2459881\n",
      "X44      X44  -0.2283222   -0.2406929   0.2283222    0.2406929\n",
      "X81      X81  -0.2148017   -0.2068499   0.2148017    0.2068499\n",
      "X29      X29   0.2060082    0.1970644   0.2060082    0.1970644\n",
      "X46      X46  -0.1957796   -0.1916278   0.1957796    0.1916278\n",
      "X21      X21   0.1897579    0.1726961   0.1897579    0.1726961\n",
      "\n",
      "Starting Lasso evaluation\n",
      "Lasso Outer fold 1/5: MSE = 109.04\n",
      "Lasso Outer fold 2/5: MSE = 145.76\n",
      "Lasso Outer fold 3/5: MSE = 148.43\n",
      "Lasso Outer fold 4/5: MSE = 128.18\n",
      "Lasso Outer fold 5/5: MSE = 141.68\n",
      "\n",
      "Starting Backward Selection evaluation\n",
      "Backward Outer fold 1/5: MSE = 106.16\n",
      "Backward Outer fold 2/5: MSE = 146.82\n",
      "Backward Outer fold 3/5: MSE = 157.84\n",
      "Backward Outer fold 4/5: MSE = 125.04\n",
      "Backward Outer fold 5/5: MSE = 135.06\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Package management\n",
    "required_packages <- c(\"glmnet\", \"caret\", \"dplyr\", \"MASS\", \"mgcv\", \"earth\", \"corrplot\")\n",
    "for(package in required_packages) {\n",
    "    if (!require(package, character.only = TRUE)) {\n",
    "        install.packages(package)\n",
    "        library(package, character.only = TRUE)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper function to extract important features with coefficients\n",
    "get_important_features <- function(model_type, model, threshold = 0.01) {\n",
    "    if(model_type == \"lasso\") {\n",
    "        coefs <- as.matrix(coef(model, s=\"lambda.min\"))\n",
    "        features <- names(which(abs(coefs[-1,1]) > threshold))\n",
    "        return(list(\n",
    "            features = features,\n",
    "            coefficients = coefs[-1,1][abs(coefs[-1,1]) > threshold]\n",
    "        ))\n",
    "    } else if(model_type == \"glm\") {\n",
    "        coefs <- coef(model)\n",
    "        features <- names(which(abs(coefs[-1]) > threshold))\n",
    "        return(list(\n",
    "            features = features,\n",
    "            coefficients = coefs[-1][abs(coefs[-1]) > threshold]\n",
    "        ))\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to calculate correlations with target\n",
    "get_top_correlations <- function(X, y, top_n = 10) {\n",
    "    correlations <- sapply(X, function(x) cor(x, y, method = \"pearson\"))\n",
    "    spearman_cors <- sapply(X, function(x) cor(x, y, method = \"spearman\"))\n",
    "    \n",
    "    cor_df <- data.frame(\n",
    "        variable = names(correlations),\n",
    "        pearson_cor = correlations,\n",
    "        spearman_cor = spearman_cors,\n",
    "        abs_pearson = abs(correlations),\n",
    "        abs_spearman = abs(spearman_cors)\n",
    "    )\n",
    "    \n",
    "    cor_df <- cor_df[order(-cor_df$abs_pearson), ]\n",
    "    return(list(\n",
    "        top_n = cor_df[1:top_n, ],\n",
    "        all_correlations = cor_df\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Lasso with nested CV\n",
    "evaluate_lasso_nested <- function(X, y, outer_folds=5, inner_folds=5) {\n",
    "    cat(\"\\nStarting Lasso evaluation\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    X <- as.matrix(X)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    \n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    feature_info_list <- vector(\"list\", outer_folds)\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        X_train <- X[-outer_test_idx, ]\n",
    "        y_train <- y[-outer_test_idx]\n",
    "        X_test <- X[outer_test_idx, ]\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        cv_fit <- cv.glmnet(X_train, y_train, alpha=1, nfolds=inner_folds)\n",
    "        predictions <- predict(cv_fit, X_test, s=\"lambda.min\")\n",
    "        outer_scores[outer_fold] <- mean((y_test - predictions)^2)\n",
    "        \n",
    "        feature_info <- get_important_features(\"lasso\", cv_fit)\n",
    "        feature_info_list[[outer_fold]] <- feature_info\n",
    "        \n",
    "        cat(sprintf(\"Lasso Outer fold %d/%d: MSE = %.2f\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold]))\n",
    "    }\n",
    "        flush.console()\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores,\n",
    "        feature_info = feature_info_list\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Backward selection with nested CV\n",
    "evaluate_backward_nested <- function(X, y, outer_folds=5) {\n",
    "    cat(\"\\nStarting Backward Selection evaluation\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    set.seed(42)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    \n",
    "    outer_scores <- numeric(outer_folds)\n",
    "    feature_info_list <- vector(\"list\", outer_folds)\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        train_data <- data.frame(X[-outer_test_idx,], y=y[-outer_test_idx])\n",
    "        test_data <- data.frame(X[outer_test_idx,])\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        full_formula <- as.formula(paste(\"y ~\", paste(names(X), collapse = \" + \")))\n",
    "        model <- step(glm(full_formula, data=train_data),\n",
    "                     direction=\"backward\",\n",
    "                     k=log(nrow(train_data)),\n",
    "                     trace=0)\n",
    "        \n",
    "        predictions <- predict(model, newdata=test_data)\n",
    "        outer_scores[outer_fold] <- mean((y_test - predictions)^2)\n",
    "        \n",
    "        feature_info <- get_important_features(\"glm\", model)\n",
    "        feature_info_list[[outer_fold]] <- feature_info\n",
    "        \n",
    "        cat(sprintf(\"Backward Outer fold %d/%d: MSE = %.2f\\n\", \n",
    "                   outer_fold, outer_folds, outer_scores[outer_fold]))\n",
    "\n",
    "    }\n",
    "        flush.console()\n",
    "    \n",
    "    return(list(\n",
    "        mean_mse = mean(outer_scores),\n",
    "        sd_mse = sd(outer_scores),\n",
    "        all_scores = outer_scores,\n",
    "        feature_info = feature_info_list\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Function to get optimized features\n",
    "get_optimized_features <- function(lasso_results, backward_results, cor_results) {\n",
    "    # Get correlation information\n",
    "    top_cors <- cor_results$top_n$variable\n",
    "    \n",
    "    # Get features that appear in both methods consistently\n",
    "    lasso_features <- unique(unlist(lapply(lasso_results$feature_info, \n",
    "                                         function(x) x$features)))\n",
    "    backward_features <- unique(unlist(lapply(backward_results$feature_info, \n",
    "                                            function(x) x$features)))\n",
    "    \n",
    "    # Combine features\n",
    "    all_features <- unique(c(lasso_features, backward_features, top_cors))\n",
    "    \n",
    "    return(all_features)\n",
    "}\n",
    "\n",
    "# Function to evaluate GAM with different settings\n",
    "evaluate_gam_variants <- function(X, y, selected_features, outer_folds=5) {\n",
    "    set.seed(42)\n",
    "    outer_cv <- createFolds(y, k=outer_folds, list=TRUE)\n",
    "    \n",
    "    # Results storage\n",
    "    results <- list(\n",
    "        cubic = numeric(outer_folds),\n",
    "        default_select = numeric(outer_folds)\n",
    "    )\n",
    "    \n",
    "    # Create formulas\n",
    "    cubic_terms <- paste(sprintf(\"s(%s, bs='cr')\", selected_features), collapse=\" + \")\n",
    "    default_terms <- paste(sprintf(\"s(%s)\", selected_features), collapse=\" + \")\n",
    "    \n",
    "    cubic_formula <- as.formula(paste(\"y ~\", cubic_terms))\n",
    "    default_formula <- as.formula(paste(\"y ~\", default_terms))\n",
    "    \n",
    "    cat(\"\\nStarting GAM evaluations with different settings\\n\")\n",
    "    \n",
    "    for(outer_fold in 1:outer_folds) {\n",
    "        outer_test_idx <- outer_cv[[outer_fold]]\n",
    "        train_data <- data.frame(X[selected_features][-outer_test_idx,], \n",
    "                               y=y[-outer_test_idx])\n",
    "        test_data <- data.frame(X[selected_features][outer_test_idx,])\n",
    "        y_test <- y[outer_test_idx]\n",
    "        \n",
    "        # Fit cubic spline model\n",
    "        model_cubic <- gam(cubic_formula, data=train_data, method=\"REML\")\n",
    "        pred_cubic <- predict(model_cubic, newdata=test_data)\n",
    "        results$cubic[outer_fold] <- mean((y_test - pred_cubic)^2)\n",
    "        \n",
    "        # Fit default spline with selection\n",
    "        model_default <- gam(default_formula, data=train_data, method=\"REML\", select=TRUE)\n",
    "        pred_default <- predict(model_default, newdata=test_data)\n",
    "        results$default_select[outer_fold] <- mean((y_test - pred_default)^2)\n",
    "        \n",
    "        cat(sprintf(\"\\nFold %d/%d:\", outer_fold, outer_folds))\n",
    "        cat(sprintf(\"\\n  Cubic Spline MSE: %.2f\", results$cubic[outer_fold]))\n",
    "        cat(sprintf(\"\\n  Default+Select MSE: %.2f\", results$default_select[outer_fold]))\n",
    "        flush.console() \n",
    "    }\n",
    "    \n",
    "    return(list(\n",
    "        cubic = list(\n",
    "            mean_mse = mean(results$cubic),\n",
    "            sd_mse = sd(results$cubic),\n",
    "            all_scores = results$cubic\n",
    "        ),\n",
    "        default_select = list(\n",
    "            mean_mse = mean(results$default_select),\n",
    "            sd_mse = sd(results$default_select),\n",
    "            all_scores = results$default_select\n",
    "        )\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Main execution\n",
    "main <- function() {\n",
    "    # Read data\n",
    "    X.reg <- read.table(\"a24_reg_app.txt\")\n",
    "    cat(\"Data loaded successfully\\n\")\n",
    "    X <- X.reg[, -ncol(X.reg)]\n",
    "    y <- X.reg$y\n",
    "    \n",
    "    # Get correlation information\n",
    "    cor_results <- get_top_correlations(X, y)\n",
    "    cat(\"\\nTop 10 correlated variables with target:\\n\")\n",
    "    print(cor_results$top_n)\n",
    "    \n",
    "    # Get baseline results\n",
    "    lasso_results <- evaluate_lasso_nested(X, y)\n",
    "    backward_results <- evaluate_backward_nested(X, y)\n",
    "    \n",
    "    # Get optimized features\n",
    "    selected_features <- get_optimized_features(lasso_results, backward_results, cor_results)\n",
    "    \n",
    "    # Evaluate GAM variants\n",
    "    gam_results <- evaluate_gam_variants(X, y, selected_features)\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    cat(\"\\n=== COMPREHENSIVE ANALYSIS RESULTS ===\\n\")\n",
    "    \n",
    "    # Create performance summary\n",
    "    performance_summary <- data.frame(\n",
    "        Method = c(\"Lasso\", \"Backward\", \"GAM (cubic)\", \"GAM (default+select)\"),\n",
    "        MSE = c(\n",
    "            lasso_results$mean_mse,\n",
    "            backward_results$mean_mse,\n",
    "            gam_results$cubic$mean_mse,\n",
    "            gam_results$default_select$mean_mse\n",
    "        ),\n",
    "        SD = c(\n",
    "            lasso_results$sd_mse,\n",
    "            backward_results$sd_mse,\n",
    "            gam_results$cubic$sd_mse,\n",
    "            gam_results$default_select$sd_mse\n",
    "        ),\n",
    "        Features = c(\n",
    "            length(unique(unlist(lapply(lasso_results$feature_info, function(x) x$features)))),\n",
    "            length(unique(unlist(lapply(backward_results$feature_info, function(x) x$features)))),\n",
    "            length(selected_features),\n",
    "            length(selected_features)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Sort by MSE\n",
    "    performance_summary <- performance_summary[order(performance_summary$MSE), ]\n",
    "    \n",
    "    cat(\"\\nPerformance Summary (sorted by MSE):\\n\")\n",
    "    print(performance_summary)\n",
    "    \n",
    "    return(list(\n",
    "        performance_summary = performance_summary,\n",
    "        selected_features = selected_features,\n",
    "        all_results = list(\n",
    "            lasso = lasso_results,\n",
    "            backward = backward_results,\n",
    "            gam = gam_results\n",
    "        )\n",
    "    ))\n",
    "}\n",
    "\n",
    "# Run the analysis\n",
    "results <- main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
