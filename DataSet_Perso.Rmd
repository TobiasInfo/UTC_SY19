---
output:
  pdf_document: default
  html_document: default
---


# Jeu de données réel



## Introduction

  Ce rapport porte sur un jeu de données concernant les assurances
  médicales aux États-Unis. Nous présenterons d'abord le jeu de données.
  Ensuite, nous appliquerons des outils de machine learning.  

L'accès aux soins de santé et la couverture médicale sont des enjeux majeurs aux
États-Unis. Les compagnies d'assurance adaptent leurs offres en fonction des 
profils clients. L'analyse des données des assurés permet d'identifier les 
facteurs influençant les coûts médicaux.  

Dans le cadre de notre projet, nous avons étudié un jeu de données
disponible sur la plateforme Kaggle. Ce jeu de
données comprend diverses informations sur les assurés.  

Notre objectif principal est d'identifier les facteurs clé influençant
les coûts d'assurance maladie et d'évaluer la performance des modèles de
machine learning dans la prédiction de ces coûts. Pour atteindre cet
objectif, nous avons répondu aux questions suivantes :  

- Quelle est l'influence des variables sur les coûts médicaux ?  
- Existe-t-il des différences régionales significatives ?  
- Quel est l'impact du nombre d'enfants à charge ?  
- Comment les résultats obtenus à partir de ce jeu de données
peuvent-ils aider les compagnies d'assurance médicale ?  

Dans ce rapport, nous présentons les résultats de notre étude en suivant
la structure suivante :  
1. Exploration des données (EDA)  
2. Pré-traitement des données  
3. Application de modèles de machine learning  
4. Conclusion et perspectives  

```{r}
# Load necessary libraries
library(dplyr)
library(ggplot2)
library(reshape2)
library(caret)
library(ggpubr)
library(lattice)
library(magrittr)
library(Amelia) 
library(corrplot)
library(cowplot)
library(gridExtra)

?dplyr::filter
?stats::filter
```

```{r}
df <- read.csv("data/medical_insurance.csv", sep = ",")
df <- df %>% distinct()
```


## Visualisation de la donnée
```{r}
# Initial overview of the data
head(df)
print("Overview :")
str(df)
print("Summary :")
summary(df)
```



## Analyse exploratoire des données : EDA  

Cette section vise à mieux comprendre notre jeu de données. Pour cela,
nous entreprenons une exploration approfondie des données pour mieux
comprendre la structure et les caractéristiques via des graphiques et
des calculs statistiques.  
```{r}
df$smoker_original <- df$smoker
for (col in c("children", "smoker", "region", "sex")) {
  cat("\n", col, "\n")
  print(table(df[[col]]))
}

# Label encoding for smoker and sex columns
df$smoker <- as.numeric(factor(df$smoker)) - 1  # Convert to binary
df$sex <- as.numeric(factor(df$sex)) - 1        # Convert to binary

# One-hot encoding for the region column
df <- cbind(df, model.matrix(~region - 1, data = df))
df$region <- NULL  # Drop the original region column

# BMI Analysis
nb <- nrow(df %>% filter(bmi < 24.9))
total <- nrow(df)

q1 <- quantile(df$bmi, 0.25)
q2 <- quantile(df$bmi, 0.5)
q3 <- quantile(df$bmi, 0.75)

df$bmi_cat <- cut(df$bmi, breaks = c(-Inf, q1, q2, q3, Inf), labels = c(1, 2, 3, 4))

cat("Percentage of people with BMI less than 24.9: ", (nb / total) * 100, "\n")
print(nb)

```
### Présentation des variables :  

- **Age** : l'âge de l'assuré, exprimé en années.  

- **Sexe** : le genre de l'assuré, correspondant soit à \"male\" soit
    à \"female\".  

- **IMC (Indice de Masse Corporelle)** : une mesure du poids corporel
    par rapport à la taille, calculée selon la formule suivante :
    $IMC = \frac{poids}{taille^2}$  

- **Enfants** : le nombre d'enfants à charge de l'assuré, entre 0 et 5.  

- **Fumeur** : un indicateur binaire indiquant si l'assuré est fumeur
    ou non.  

- **Région** : la région de résidence de l'assuré, classée par NW, SW,
    SE, NE (les points cardinaux de la rose des vents).  

- **Charges** : les charges médicales associées à chaque assuré,
    exprimées dollars.  

En effectuant une exploration approfondie de ces variables, notre
objectif est d'identifier des tendances, des corrélations et des
distributions de données susceptibles d'influencer les charges médicales
des assurés. Cette analyse exhaustive nous permettra de mieux comprendre
les facteurs sous-jacents et de poser les bases nécessaires à la
modélisation dans les sections ultérieures de notre étude.  

### Analyse univariée

Au sein de cette partie, nous allons effectuer une analyse univariée qui
permet de mettre en lumière les caractéristiques individuelles de chaque
variable du jeu de données, telles que leur distribution, leur tendance
centrale et leur dispersion. Cette analyse nous aidera à mieux
comprendre les données et à identifier les éventuelles anomalies ou
valeurs aberrantes.  

::: center
::: {#tab:description:variables}
   Indicateur    Age     IMC    Enfants   Assurance
  ------------ ------- ------- --------- -----------
    Moyenne     39.22   30.66    1.10     13279.12
    Médiane     39.00   30.40    1.00      9386.16
   Ecart-Type   14.04   6.10     1.20     12110.36
    Minimum     18.00   15.96    0.00      1121.87
    Maximum     64.00   53.13    5.00     63770.43

  : Description de certaines variables
:::
:::

```{r}
d1<-ggplot(data = df,aes(x=charges)) + geom_histogram(color="black", fill="mediumorchid1", bins=10)+
labs(title="Charges distribution")

d2<-ggplot(data = df,aes(x=bmi)) + geom_histogram(color="black", fill="mediumorchid1", bins=10)+
labs(title="BMI histogram")

d3<-ggplot(data = df,aes(x=age)) + geom_histogram(color="black", fill="mediumorchid1", bins=10)+
labs(title="Age Distribution")

d4<-ggplot(data = df,aes(x=smoker)) + geom_bar(color="black", fill="mediumorchid1", bins=10)+
labs(title="Smoker Distribution") 

plot_grid(d1, d2, d3, d4, rel_widths = c(1.15, 1),ncol = 2, align = "hv")
```

#### Variables quantitatives

La moyenne et la médiane d'âge sont très proches laissant supposer que
le jeu de données se focalise sur des personnes dans une tranche d'âge
active. La médiane peut laisser penser que la distribution est assez
symétrique. L'écart-type démontre une dispersion modérée des données
autour de la moyenne.  

On remarque aussi que l'âge minimum est de 18 ans et l'âge maximum est
de 64 ans confirmant que le jeu de données se concentre sur les
personnes actives.  

Selon l'OMS (Organisation Mondiale de la Santé), l'IMC peut
être divisé en 4 catégories majeures. Un risque faible pour les
personnes ayant un IMC \< 18.5, moyen pour un IMC entre 18.5 et 24.9,
importants pour un IMC entre 25 et 29.9 et très importants pour un IMC
supérieur à 30. Ces risques correspondent respectivement aux catégories
: sous la normale, normale, surpoids, obèse.  

On remarque que la moyenne d'IMC au sein du jeu de données est
considérée comme étant dans la catégorie \"obèse\" selon les normes de
l'OMS. La médiane et l'écart-type indiquent une variabilité modérée dans
les données d'IMC.  

On remarque que 18% des personnes représentés dans le jeu de données
présentent un IMC inférieur à 24.9. On note donc que le jeu de données
comporte beaucoup de personnes avec un IMC considéré comme \"Surpoids\"
ou \"Obèse\" selon l'OMS.  

Enfin, le minimum et le maximum indiquent que notre dataset couvre une
large gamme de catégories d'IMC.  

Le nombre d'enfants dans le jeu de données varie de 0 à 5. La moyenne de
1.10 et la médiane de 1.00 nous permettent de déduire que la plupart des
personnes ont un enfant ou moins. Une analyse en composantes principales
a été réalisée sur ces trois variables, mais les résultats ne permettent
pas de réduire la dimensionnalité de notre jeu de données.  

Enfin, le prix moyen de l'assurance maladie (représenté par la variable charge 
est de 13279.12\$. Nous avons pour le premier quartile 4,746.34\$, la médiane 
9,386.16\$ et le 3e quartile 16,657.72\$, indiquant que nos données sont 
massivement réparties autour de 10000\$, avec une asymétrie vers les valeurs 
élevées. L'écart-type élevé indique une variabilité significative dans les coûts 
parmi les assurés.  

#### Variables qualitatives

Sur les 1337 individus du jeu de données, 274 (soit 20.5%) sont fumeurs.  

Concernant le sexe, cette variable est très bien répartie au niveau du
jeu de données, on retrouve en effet environ 50% d'hommes et 50% de
femmes représentés.  


#### Conclusion

Cette analyse univariée nous permet de remarquer que ce jeu de données
semble se concentrer sur des personnes actives avec une variabilité dans
l'âge, l'IMC, le nombre d'enfants et le prix de l'assurance. Il y a des
signes d'asymétrie dans certaines variables, en particulier le prix de
l'assurance.  

#### Corrélation


```{r}
library(ggplot2)
library(reshape2)

corr_matrix <- cor(df %>% select_if(is.numeric))
corr_melt <- melt(corr_matrix)
ggplot(corr_melt, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  labs(title = "Correlation Matrix Heatmap", x = "", y = "") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_blank()
  ) +
  coord_fixed()

```
Nous avons commencé par examiner la matrice de corrélation des
variables, présentée dans la figure ci-dessus,
afin de déterminer les relations linéaires entre les variables. Cette
matrice nous permet de visualiser les niveaux de corrélation entre
chaque paire de variables.  

Dans cette figure, nous nous intéressons surtout à la variable
\"charges\" et \"smoker\". Ces variables correspondent respectivement aux coûts 
d'assurance et au statut tabagique de la personne. Il semble que les trois
variables ayant la corrélation la plus forte avec les charges soient, dans
l'ordre décroissant : le statut tabagique, l'âge et l'IMC.  

### L'impact du tabagisme sur les charges


```{r}
# Ensure 'smoker_original' is a factor with the correct levels
df$smoker_original <- factor(df$smoker_original, levels = c("no", "yes"))

# Plot the histogram
ggplot(df, aes(x = charges, fill = smoker_original)) +
  geom_histogram(bins = 30, position = "identity", alpha = 0.3) +
  scale_fill_manual(values = c("no" = "blue", "yes" = "red"), name = "Smoker") +
  labs(title = "Histogram of Charges by Smoking Status",
       x = "Charges",
       y = "Number of People") +
  theme_minimal()

```

Cette figure illustre une corrélation significative
entre le prix de l'assurance et le statut tabagique d'un individu. Les
personnes non-fumeuses, représentées en bleu, ont tendance à payer des
frais médicaux moins élevés que les fumeurs, représentés en rouge. Cette
différence de coût suggère que le tabagisme est un facteur déterminant
dans la fixation des tarifs d'assurance. En effet, les fumeurs sont
généralement considérés comme présentant un risque plus élevé pour la
santé, ce qui se traduit par des coûts d'assurance plus élevés. Par
conséquent, cette figure met en évidence l'importance du statut
tabagique dans la détermination des groupes tarifaires d'assurance
maladie.  

### L'impact de l'âge sur les charges

```{r}
# Histogram of charges by age range
ggplot(df, aes(x = age, weight = charges)) +
  geom_histogram(breaks = seq(15, 70, by = 5), fill = "blue", color = "black") +
  labs(title = "Histogram of Charges by Age Range", x = "Age", y = "Charges")
```


Cet histogramme permet de constater l'évolution du prix de l'assurance
en fonction de l'âge. On remarque une relation de corrélation entre le
prix de l'assurance et l'âge. Cette relation suggère que les personnes
plus âgées ont tendance à avoir des coûts médicaux plus élevés.  


### L'impact de l'IMC sur les charges

```{r}
# Define the quartiles
q1 <- 26.22
q2 <- 30.45
q3 <- 34.77

# Filter the data for charges greater than 30,000
df_filtered <- df %>% filter(charges > 30000)

# Create BMI categories based on the quartiles
df_filtered$bmi_cat <- cut(df_filtered$bmi, breaks = c(-Inf, q1, q2, q3, Inf),
                           labels = c("Q1: <26.22", "Q2: 26.22-30.45", "Q3: 30.45-34.77", "Q4: >34.77"))

# Create the histogram
ggplot(df_filtered, aes(x = bmi_cat, fill = bmi_cat)) +
  geom_bar(position = "dodge", size = 1.2) +
  scale_fill_manual(values = c("Q1: <26.22" = "blue", "Q2: 26.22-30.45" = "green",
                               "Q3: 30.45-34.77" = "orange", "Q4: >34.77" = "red")) +
  labs(title = "Distribution of BMI Categories for Charges > $30,000",
       x = "BMI Category",
       y = "Number of People") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 45, hjust = 1))

```

Pour cette analyse, nous avons divisé les données en quatre catégories
en utilisant les quartiles de l'IMC, ce qui nous permet de mieux
appréhender l'impact de l'IMC sur les frais médicaux.  

Les différents quartiles d'IMC sont : $q_1=26.22$, $q_2=30.45$,
$q_3=34.77$.  

Nous observons sur la figure que 50% des 340 assurés ayant
des charges supérieures à 30 000\$ sont des personnes avec un IMC
supérieur à 34.77, tandis que 87% de ces 340 assurances sont des
personnes avec un IMC supérieur à 30.4475.  

## Analyse multivariée

Cette approche nous permet de comprendre comment différentes
combinaisons de variables peuvent influencer les coûts médicaux aux
États-Unis. En examinant ces relations plus complexes, nous pourrons
identifier des patterns et des interactions qui pourraient ne pas être
évidents dans une analyse bivariée.  

Les différents graphiques que nous avons pu réaliser pour visualiser les
liens entre l'âge, le sexe la région et le nombre d'enfants ne
démontrent pas de lien particulier. On note néanmoins une augmentation
linéaire du prix de l'assurance comme nous avions pu le constater lors
de l'analyse de la figure illustrant les charges selon l'âge.  

```{r}
# Load necessary libraries
library(ggplot2)
# Scatter plot of charges vs bmi, colored by smoker
ggplot(df, aes(x = bmi, y = charges, color = factor(smoker))) +
  geom_point() +
  theme_minimal()

```
Dans cette figure illustrant l'IMC par rapport aux charges, on révèle une forte corrélation 
entre l'IMC, le statut tabagique et les frais médicaux. Plus précisément, on peut
observer une relation linéaire entre l'âge et les coûts médicaux chez
les fumeurs, tandis que cette relation n'est pas aussi marquée chez les
non-fumeurs. Cette observation suggère que le tabagisme est un facteur
important dans l'augmentation des coûts médicaux avec l'âge, et que
l'IMC peut être un indicateur utile pour estimer les coûts médicaux
futurs chez les fumeurs.  

```{r}
ggplot(df, aes(x = factor(sex), y = charges, fill = factor(smoker))) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Spectral") +
  labs(title = "Boxplot of Charges by Sex Status", x = "Sex", y = "Charges")
```
Le boxplot des charges par statut de sexe et de tabagisme révèle des informations 
intéressantes sur les coûts des assurances maladie. En observant les médianes et 
les intervalles interquartiles, on constate qu'il n'y a pas de différence 
significative dans le prix de l'assurance maladie entre les hommes et les femmes. 
Les distributions des charges pour les deux sexes sont relativement similaires, 
indiquant que le sexe n'est pas un facteur déterminant majeur des coûts d'assurance.   

Cependant, le statut de tabagisme semble avoir un impact beaucoup plus marqué. 
Les individus fumeurs, qu'ils soient hommes ou femmes, présentent des charges 
médicales nettement plus élevées par rapport aux non-fumeurs. Les boxplots 
montrent que les fumeurs ont des médianes de charges plus élevées et des 
distributions plus larges, indiquant une plus grande variabilité et des coûts 
potentiellement plus élevés. Cette observation souligne que le tabagisme est 
un facteur important influençant les coûts des assurances maladie, indépendamment 
du sexe.  


# Transformation et encodage des variables

```{r}
library(dplyr)
library(readr)
library(caret)
library(Matrix)
library(ggplot2)
library(data.table)
library(scales)

# Load the data
df <- read.csv("data/medical_insurance.csv", sep = ",")

# Remove duplicates
df <- distinct(df)

# Encode the "smoker" and "sex" columns as binary variables
df$smoker <- as.numeric(as.factor(df$smoker)) - 1
df$sex <- as.numeric(as.factor(df$sex)) - 1

# One-hot encode the "region" column
encoded_region <- model.matrix(~ region - 1, data = df)
colnames(encoded_region) <- c("northeast", "northwest", "southeast", "southwest")
df <- cbind(df, encoded_region)

# Drop the original "region" column
df <- df %>% select(-region)

# Standardize the "age", and "bmi" columns
scaler <- preProcess(df[, c("age", "bmi")], method = c("center", "scale"))
df_quant <- predict(scaler, df[, c("age", "bmi")])

# Combine the scaled quantitative data with non-quantitative columns
df_non_quant <- df %>% select(-c(age, bmi))
scaled_data <- cbind(df_quant, df_non_quant)

# Save the scaled data to a new CSV file
write.csv(scaled_data, "data/medical_insurance_scaled.csv", row.names = FALSE)

# Standardize the "age", "bmi", and "charges" columns
scaler <- preProcess(df[, c("age", "bmi", "charges")], method = c("center", "scale"))
df_scaled_quant <- predict(scaler, df[, c("age", "bmi", "charges")])

# Combine the scaled quantitative data with non-quantitative columns
df_non_quant <- df %>% select(-c(age, bmi, charges))
scaled_data <- cbind(df_scaled_quant, df_non_quant)

# Save the scaled data to a new CSV file
write.csv(scaled_data, "data/medical_insurance_scaled_class.csv", row.names = FALSE)
```

Comme nous l'avons vu, trois variables sont catégorielles : le sexe, le
statut tabagique et la région. Il faut les encoder pour pouvoir
effectuer des calculs mathématiques.

Tout d'abord le label encoding permet de transformer une colonne en un
ensemble de nombres. Ainsi, nous allons pouvoir transformer le sexe
femme/homme en 0/1, de même pour le statut tabagique. Cet encodage
pourrait induire un ordre dans des variables catégorielles sans qu'il
n'en existe un dans le monde réel, les régions n'ayant pas d'ordre, nous
allons devoir utiliser un autre encodage.

Nous allons utiliser le One hot encoding, afin de transformer une
colonne en un ensemble de colonne binaire pour chacune des valeurs. Ici,
comme nous l'avons vu lors de l'EDA, la région ne possède que quatre
valeurs donc nous n'augmentons la dimension que de 3 ce qui est
raisonnable. Une piste de réflexion est de reproduire les étapes
suivantes en utilisant du label encoding et voir s'il y a un impact sur
la précision de nos modèles.


# Modèles de machine learning

```{r}
missing_values <- colSums(is.na(df))
missing_values <- missing_values[missing_values > 0]
if (length(missing_values) > 0) {
  cat("Missing values in the dataset:\n")
  print(missing_values)
} else {
  cat("No missing values in the dataset\n")
}
```

```{r}
df_preprocess <- read.csv("data/medical_insurance_scaled.csv", sep = ",")
df_preprocess_class <- read.csv("data/medical_insurance_scaled_class.csv", sep = ",")

data <- read.csv("data/medical_insurance_scaled_class.csv", sep = ",")

# Create copies of original data
data_with_outliers <- data
data_cleaned <- data

# Define continuous variables (based on inspection)
continuous_vars <- c("age", "bmi", "charges")

# Remove outliers for continuous variables only
for (var in continuous_vars) {
  Q1 <- quantile(data_cleaned[[var]], 0.25, na.rm = TRUE)
  Q3 <- quantile(data_cleaned[[var]], 0.75, na.rm = TRUE)
  IQR_val <- Q3 - Q1
  
  lower_bound <- Q1 - 1.5 * IQR_val
  upper_bound <- Q3 + 1.5 * IQR_val
  
  # Remove rows with outliers in any continuous variable
  data_cleaned <- data_cleaned[!(data_cleaned[[var]] < lower_bound | data_cleaned[[var]] > upper_bound), ]
}

# Calculate the ratio of rows deleted
cat("Rows deleted due to outliers:", (1 - nrow(data_cleaned) / nrow(data)) * 100, "%\n")

write.csv(data_cleaned, "data/medical_insurance_scaled_class_without_ouliers.csv", row.names = FALSE)

```

```{r}
df_preprocess_class_without_outliers <- read.csv("data/medical_insurance_scaled_class_without_ouliers.csv", sep = ",")
set.seed(123) # For reproducibility
train_indices <- createDataPartition(df_preprocess_class_without_outliers$smoker, p = 0.8, list = FALSE)
train_data <- df_preprocess_class_without_outliers[train_indices, ]
test_data <- df_preprocess_class_without_outliers[-train_indices, ]
```

## Classification

```{r}
library(caret)
library(e1071)
library(ROSE)
library(dplyr)
library(MASS)
library(klaR)
library(randomForest) 
library(class)
library(rpart)

train_data$smoker <- as.factor(train_data$smoker)
test_data$smoker <- as.factor(test_data$smoker)

levels(test_data$smoker) <- levels(train_data$smoker)

evaluate_model <- function(model_name, model, test_data, true_labels) {
  if (model_name %in% c("lda", "qda", "rda")) {
    predictions <- predict(model, newdata = test_data)$class
  } else if (model_name == "knn") {
    predictions <- knn(train = train_data[, c("bmi", "charges")], test = test_data[, c("bmi", "charges")], cl = train_data$smoker, k = 5)
  } else if (model_name == "logistic_regression") {
    probabilities <- predict(model, newdata = test_data, type = "response")
    predictions <- ifelse(probabilities > 0.5, 1, 0)  # Convert probabilities to binary labels
    predictions <- factor(predictions, levels = levels(true_labels))
  } else if (model_name == "decision_tree") {
    probabilities <- predict(model, newdata = test_data, type = "prob")
    predictions <- colnames(probabilities)[max.col(probabilities)]
    predictions <- factor(predictions, levels = levels(true_labels))
  } else {
    predictions <- predict(model, newdata = test_data)
  }

  levels <- levels(true_labels)
  metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), lev = levels)

  # Calculate Precision and Recall
  confusion_matrix <- table(predictions, true_labels)
  precision <- diag(confusion_matrix) / colSums(confusion_matrix)
  recall <- diag(confusion_matrix) / rowSums(confusion_matrix)

  return(list(
    Accuracy = metrics["Accuracy"],
    Precision = mean(precision),
    Recall = mean(recall)
  ))
}

sample_data <- function(data, method = "none") {
  if (method == "up") {
    # Oversampling using ROSE
    data_balanced <- ROSE(smoker ~ ., data = data, seed = 123)$data
  } else if (method == "down") {
    # Undersampling using ROSE
    data_balanced <- ovun.sample(smoker ~ ., data = data, method = "under", seed = 123)$data
  } else {
    # No sampling
    data_balanced <- data
  }
  return(data_balanced)
}

set.seed(123)
sampling_methods <- c("none", "up", "down")

results <- data.frame(
  Model = character(),
  Sampling_Method = character(),
  Accuracy = double(),
  Precision = double(),
  Recall = double()
)

find_best_rda_params <- function(train_data, formula) {
  lambdas <- seq(0, 1, by = 0.1)    # Range for lambda
  gammas <- seq(0, 0.5, by = 0.05)  # Range for gamma

  best_params <- list(lambda = 0, gamma = 0, accuracy = 0)

  for (l in lambdas) {
    for (g in gammas) {
      tryCatch({
        model <- rda(formula, data = train_data, gamma = g, lambda = l)
        preds <- predict(model, train_data)$class
        acc <- mean(preds == train_data$smoker)

        if (acc > best_params$accuracy) {
          best_params <- list(lambda = l, gamma = g, accuracy = acc)
        }
      }, error = function(e) NULL)
    }
  }
  return(best_params)
}

models <- list(
  naive_bayes = function(data) naiveBayes(smoker ~ bmi + charges, data = data),
  lda = function(data) lda(smoker ~ bmi + charges, data = data),
  qda = function(data) qda(smoker ~ bmi + charges, data = data),
  rda = function(data) {
    best_params <- find_best_rda_params(data, smoker ~ bmi + charges)
    rda(smoker ~ bmi + charges, data = data, gamma = best_params$gamma, lambda = best_params$lambda)
  },
  randomForest = function(data) randomForest(smoker ~ bmi + charges, data = data),
  logistic_regression = function(data) glm(smoker ~ bmi + charges, data = data, family = binomial),
  knn = function(data) {
    NULL
  },
  svm = function(data) svm(smoker ~ bmi + charges, data = data, kernel = "linear"),
  svm_poly = function(data) svm(smoker ~ bmi + charges, data = data, kernel = "polynomial"),
  svm_gaussian = function(data) svm(smoker ~ bmi + charges, data = data, kernel = "radial"),
  decision_tree = function(data) rpart(smoker ~ bmi + charges, data = data, method = "class")
)

for (sampling_method in sampling_methods) {
  print(paste("Sampling method:", sampling_method))
  flush.console()

  sampled_train <- sample_data(train_data, sampling_method)

  for (model_name in names(models)) {
    print(paste("Training model:", model_name))
    flush.console()

    model <- models[[model_name]](sampled_train)

    test_metrics <- evaluate_model(model_name, model, test_data, test_data$smoker)

    results <- rbind(results, data.frame(
      Model = model_name,
      Sampling_Method = sampling_method,
      Accuracy = test_metrics$Accuracy,
      Precision = test_metrics$Precision,
      Recall = test_metrics$Recall
    ))
    rownames(results) <- NULL
  }
}

sorted_results <- results[order(-results$Accuracy), ]

print(sorted_results)
```



## Regression 

```{r}

# TODO : Implement 
# Simple Linear Regression
# Multiple Linear Regression
# Polynomial Regression
# Ridge Regression (L2 Regularization)
# Lasso Regression (L1 Regularization)
# Elastic Net Regression
# Decision Tree Regression
# Random Forest Regression
# Support Vector Regression
# k-Nearest Neighbors Regression
# Kernel Regression
 


# Load necessary libraries
library(caret)
library(e1071)
library(dplyr)
library(MASS)  # For lda function
library(klaR)  # For rda function
library(randomForest)  # For randomForest function
library(class)  # For knn function
library(rpart)  # For decision tree function

# Load the dataset
df_preprocess_reg <- read.csv("data/medical_insurance_scaled.csv", sep = ",")

# Set seed for reproducibility
set.seed(123)

# Create train-test split for regression
train_indices <- createDataPartition(df_preprocess_reg$charges, p = 0.8, list = FALSE)
train_data_reg <- df_preprocess_reg[train_indices, ]
test_data_reg <- df_preprocess_reg[-train_indices, ]

# Convert "charges" to a numeric variable
train_data_reg$charges <- as.numeric(train_data_reg$charges)
test_data_reg$charges <- as.numeric(test_data_reg$charges)

# Define the evaluation function for regression
evaluate_model <- function(model_name, model, test_data_reg, true_labels) {
  predictions <- predict(model, newdata = test_data_reg)

  # Calculate MAE, MSE, and R-squared
  mae <- mean(abs(predictions - true_labels))
  mse <- mean((predictions - true_labels)^2)
  r_squared <- 1 - (sum((predictions - true_labels)^2) / sum((true_labels - mean(true_labels))^2))

  return(list(
    MAE = mae,
    MSE = mse,
    R_squared = r_squared
  ))
}

# Initialize results dataframe
results <- data.frame(
  Model = character(),
  MAE = double(),
  MSE = double(),
  R_squared = double()
)

# Define the models to train
models <- list(
  linear_regression = function(data) lm(charges ~ ., data = data),
  randomForest = function(data) randomForest(charges ~ ., data = data),
  decision_tree = function(data) rpart(charges ~ ., data = data, method = "anova"),
  svm = function(data) svm(charges ~ ., data = data, kernel = "linear"),
  svm_poly = function(data) svm(charges ~ ., data = data, kernel = "polynomial"),
  svm_gaussian = function(data) svm(charges ~ ., data = data, kernel = "radial")
)

# Train and evaluate each model
for (model_name in names(models)) {
  print(paste("Training model:", model_name))
  flush.console()

  # Train model
  model <- models[[model_name]](train_data_reg)

  # Evaluate on test set
  test_metrics <- evaluate_model(model_name, model, test_data_reg, test_data_reg$charges)

  # Add results
  results <- rbind(results, data.frame(
    Model = model_name,
    MAE = test_metrics$MAE,
    MSE = test_metrics$MSE,
    R_squared = test_metrics$R_squared
  ))
  rownames(results) <- NULL
}

# Sort the results by R-squared
sorted_results <- results[order(-results$R_squared), ]

# Print the sorted results
print(sorted_results)


```

```{r}
# Load necessary libraries
library(caret)
library(e1071)
library(dplyr)
library(MASS)  # For lda function
library(klaR)  # For rda function
library(randomForest)  # For randomForest function
library(class)  # For knn function
library(rpart)  # For decision tree function
library(glmnet)  # For Ridge, Lasso, and Elastic Net regression
library(kernlab)  # For Kernel regression

# Load the dataset
df_preprocess_reg <- read.csv("data/medical_insurance_scaled.csv", sep = ",")

# Set seed for reproducibility
set.seed(123)

# Create train-test split for regression
train_indices <- createDataPartition(df_preprocess_reg$charges, p = 0.8, list = FALSE)
train_data_reg <- df_preprocess_reg[train_indices, ]
test_data_reg <- df_preprocess_reg[-train_indices, ]

# Convert "charges" to a numeric variable
train_data_reg$charges <- as.numeric(train_data_reg$charges)
test_data_reg$charges <- as.numeric(test_data_reg$charges)

# Define the evaluation function for regression
evaluate_model <- function(model_name, model, test_data_reg, true_labels) {
  predictions <- predict(model, newdata = test_data_reg)

  # Calculate MAE, MSE, and R-squared
  mae <- mean(abs(predictions - true_labels))
  mse <- mean((predictions - true_labels)^2)
  r_squared <- 1 - (sum((predictions - true_labels)^2) / sum((true_labels - mean(true_labels))^2))

  return(list(
    MAE = mae,
    MSE = mse,
    R_squared = r_squared
  ))
}

# Initialize results dataframe
results <- data.frame(
  Model = character(),
  MAE = double(),
  MSE = double(),
  R_squared = double()
)

# Define the models to train
models <- list(
  simple_linear_regression = function(data) lm(charges ~ bmi, data = data),
  multiple_linear_regression = function(data) lm(charges ~ ., data = data),
  polynomial_regression = function(data) lm(charges ~ poly(bmi, 2), data = data)
  # ridge_regression = function(data) {
  #   x <- as.matrix(data[, -which(names(data) == "charges")])
  #   y <- data$charges
  #   cv.out <- cv.glmnet(x, y, alpha = 0)
  #   best_lambda <- cv.out$lambda.min
  #   glmnet(x, y, alpha = 0, lambda = best_lambda)
  # },
  # lasso_regression = function(data) {
  #   x <- as.matrix(data[, -which(names(data) == "charges")])
  #   y <- data$charges
  #   cv.out <- cv.glmnet(x, y, alpha = 1)
  #   best_lambda <- cv.out$lambda.min
  #   glmnet(x, y, alpha = 1, lambda = best_lambda)
  # },
  # elastic_net_regression = function(data) {
  #   x <- as.matrix(data[, -which(names(data) == "charges")])
  #   y <- data$charges
  #   cv.out <- cv.glmnet(x, y, alpha = 0.5)
  #   best_lambda <- cv.out$lambda.min
  #   glmnet(x, y, alpha = 0.5, lambda = best_lambda)
  # },
  # decision_tree_regression = function(data) rpart(charges ~ ., data = data, method = "anova"),
  # random_forest_regression = function(data) randomForest(charges ~ ., data = data),
  # support_vector_regression = function(data) svm(charges ~ ., data = data, kernel = "linear"),
  # knn_regression = function(data) {
  #   # KNN does not have a training step, so we return NULL
  #   NULL
  # },
  # kernel_regression = function(data) ksvm(charges ~ ., data = data, kernel = "rbfdot")
)

# Train and evaluate each model
for (model_name in names(models)) {
  print(paste("Training model:", model_name))
  flush.console()

  # Train model
  model <- models[[model_name]](train_data_reg)

  # Evaluate on test set
  if (model_name == "knn_regression") {
    predictions <- knn.reg(train = train_data_reg[, -which(names(train_data_reg) == "charges")],
                           test = test_data_reg[, -which(names(test_data_reg) == "charges")],
                           y = train_data_reg$charges,
                           k = 5)
    mae <- mean(abs(predictions - test_data_reg$charges))
    mse <- mean((predictions - test_data_reg$charges)^2)
    r_squared <- 1 - (sum((predictions - test_data_reg$charges)^2) / sum((test_data_reg$charges - mean(test_data_reg$charges))^2))

    # Add results
    results <- rbind(results, data.frame(
      Model = model_name,
      MAE = mae,
      MSE = mse,
      R_squared = r_squared
    ))
    rownames(results) <- NULL
  } else {
    test_metrics <- evaluate_model(model_name, model, test_data_reg, test_data_reg$charges)

    # Add results
    results <- rbind(results, data.frame(
      Model = model_name,
      MAE = test_metrics$MAE,
      MSE = test_metrics$MSE,
      R_squared = test_metrics$R_squared
    ))
    rownames(results) <- NULL
  }
}

# Sort the results by R-squared
sorted_results <- results[order(-results$R_squared), ]

# Print the sorted results
print(sorted_results)

```



## TODO : Reprendre ici 

```{r}
library(caret)
library(e1071)
library(ROSE) # For oversampling and undersampling
library(dplyr)

# Convert "smoker" to a factor
train_data$smoker <- as.factor(train_data$smoker)
test_data$smoker <- as.factor(test_data$smoker)

# Define the evaluation function
evaluate_model <- function(model, test_data, true_labels) {
  predictions <- predict(model, newdata = test_data)
  levels <- levels(true_labels)
  metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), lev = levels)
  return(list(
    Accuracy = metrics["Accuracy"],
    F1 = metrics["Mean_F1"]
  ))
}

# Function to apply sampling techniques
sample_data <- function(data, method = "none") {
  if (method == "up") {
    # Oversampling using ROSE
    data_balanced <- ROSE(smoker ~ ., data = data, seed = 123)$data
  } else if (method == "down") {
    # Undersampling using ROSE
    data_balanced <- ovun.sample(smoker ~ ., data = data, method = "under", seed = 123)$data
  } else {
    # No sampling
    data_balanced <- data
  }
  return(data_balanced)
}

# Define sampling methods
set.seed(123)
sampling_methods <- c("none", "up", "down")
classification_method <- "naive_bayes"

# Initialize results dataframe
nb_results <- data.frame(
  Model = character(),
  Sampling_Method = character(),
  Accuracy = double(),
  F1 = double()
)

# For each sampling method
for (sampling_method in sampling_methods) {
  print(paste("Sampling method:", sampling_method))
  flush.console()
  
  # Apply sampling to training data
  sampled_train <- sample_data(train_data, sampling_method)
  
  # Train model
  model <- naiveBayes(smoker ~ bmi + charges, data = sampled_train)
  
  # Evaluate on test set
  test_metrics <- evaluate_model(model, test_data, test_data$smoker)
  
  # Add results
  nb_results <- rbind(nb_results, data.frame(
    Model = classification_method,
    Sampling_Method = sampling_method,
    Accuracy = test_metrics$Accuracy,
    F1 = test_metrics$F1
  ))
  rownames(nb_results) <- NULL
}

# Display the results
print(nb_results)
```

```{r}
library(caret)
library(e1071)
library(ROSE) # For oversampling and undersampling
library(dplyr)
library(MASS)

# Convert "smoker" to a factor
train_data$smoker <- as.factor(train_data$smoker)
test_data$smoker <- as.factor(test_data$smoker)

# Define the evaluation function
evaluate_model <- function(model, test_data, true_labels) {
  predictions <- predict(model, newdata = test_data)$class
  levels <- levels(true_labels)
  metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), lev = levels)
  return(list(
    Accuracy = metrics["Accuracy"],
    F1 = metrics["Mean_F1"]
  ))
}

# Function to apply sampling techniques
sample_data <- function(data, method = "none") {
  if (method == "up") {
    # Oversampling using ROSE
    data_balanced <- ROSE(smoker ~ ., data = data, seed = 123)$data
  } else if (method == "down") {
    # Undersampling using ROSE
    data_balanced <- ovun.sample(smoker ~ ., data = data, method = "under", seed = 123)$data
  } else {
    # No sampling
    data_balanced <- data
  }
  return(data_balanced)
}

# Define sampling methods
set.seed(123)
sampling_methods <- c("none", "up", "down")
classification_method <- "lda"

# Initialize results dataframe
lda_results <- data.frame(
  Model = character(),
  Sampling_Method = character(),
  Accuracy = double(),
  F1 = double()
)

# For each sampling method
for (sampling_method in sampling_methods) {
  print(paste("Sampling method:", sampling_method))
  flush.console()
  
  # Apply sampling to training data
  sampled_train <- sample_data(train_data, sampling_method)
  
  # Train model
  model <- lda(smoker ~ ., data = sampled_train)
  
  # Evaluate on test set
  test_metrics <- evaluate_model(model, test_data, test_data$smoker)
  
  # Add results
  lda_results <- rbind(lda_results, data.frame(
    Model = classification_method,
    Sampling_Method = sampling_method,
    Accuracy = test_metrics$Accuracy,
    F1 = test_metrics$F1
  ))
  rownames(lda_results) <- NULL
}

# Display the results
print(lda_results)
```


```{r}
library(caret)
library(e1071)
library(ROSE) # For oversampling and undersampling
library(dplyr)

# Convert "smoker" to a factor
train_data$smoker <- as.factor(train_data$smoker)
test_data$smoker <- as.factor(test_data$smoker)

# Define the evaluation function
evaluate_model <- function(model, test_data, true_labels) {
  predictions <- predict(model, newdata = test_data)$class
  levels <- levels(true_labels)
  metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), lev = levels)
  return(list(
    Accuracy = metrics["Accuracy"],
    F1 = metrics["Mean_F1"]
  ))
}

# Function to apply sampling techniques
sample_data <- function(data, method = "none") {
  if (method == "up") {
    # Oversampling using ROSE
    data_balanced <- ROSE(smoker ~ ., data = data, seed = 123)$data
  } else if (method == "down") {
    # Undersampling using ROSE
    data_balanced <- ovun.sample(smoker ~ ., data = data, method = "under", seed = 123)$data
  } else {
    # No sampling
    data_balanced <- data
  }
  return(data_balanced)
}

# Define sampling methods
set.seed(123)
sampling_methods <- c("none", "up", "down")
classification_method <- "qda"

# Initialize results dataframe
qda_results <- data.frame(
  Model = character(),
  Sampling_Method = character(),
  Accuracy = double(),
  F1 = double()
)

# For each sampling method
for (sampling_method in sampling_methods) {
  print(paste("Sampling method:", sampling_method))
  flush.console()
  
  # Apply sampling to training data
  sampled_train <- sample_data(train_data, sampling_method)
  
  # Train model
  model <- qda(smoker  ~ bmi + charges, data = sampled_train)
  
  # Evaluate on test set
  test_metrics <- evaluate_model(model, test_data, test_data$smoker)
  
  # Add results
  qda_results <- rbind(qda_results, data.frame(
    Model = classification_method,
    Sampling_Method = sampling_method,
    Accuracy = test_metrics$Accuracy,
    F1 = test_metrics$F1
  ))
  rownames(qda_results) <- NULL
}

# Display the results
print(qda_results)
```

```{r}
# Load necessary libraries
library(caret)
library(e1071)
library(ROSE) # For oversampling and undersampling
library(dplyr)
library(klaR)  # For rda function

# Convert "smoker" to a factor
train_data$smoker <- as.factor(train_data$smoker)
test_data$smoker <- as.factor(test_data$smoker)

# Define the evaluation function
evaluate_model <- function(model, test_data, true_labels) {
  predictions <- predict(model, newdata = test_data)$class
  levels <- levels(true_labels)
  metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), lev = levels)
  return(list(
    Accuracy = metrics["Accuracy"],
    F1 = metrics["Mean_F1"]
  ))
}

# Function to apply sampling techniques
sample_data <- function(data, method = "none") {
  if (method == "up") {
    # Oversampling using ROSE
    data_balanced <- ROSE(smoker ~ ., data = data, seed = 123)$data
  } else if (method == "down") {
    # Undersampling using ROSE
    data_balanced <- ovun.sample(smoker ~ ., data = data, method = "under", seed = 123)$data
  } else {
    # No sampling
    data_balanced <- data
  }
  return(data_balanced)
}

# Define sampling methods
set.seed(123)
sampling_methods <- c("none", "up", "down")
classification_method <- "rda"

# Initialize results dataframe
rda_results <- data.frame(
  Model = character(),
  Sampling_Method = character(),
  Accuracy = double(),
  F1 = double()
)

# Function to find the best RDA parameters
find_best_rda_params <- function(train_data, formula) {
  lambdas <- seq(0, 1, by = 0.1)    # Range for lambda
  gammas <- seq(0, 0.5, by = 0.05)  # Range for gamma

  best_params <- list(lambda = 0, gamma = 0, accuracy = 0)

  for (l in lambdas) {
    for (g in gammas) {
      tryCatch({
        model <- rda(formula, data = train_data, gamma = g, lambda = l)
        preds <- predict(model, train_data)$class
        acc <- mean(preds == train_data$smoker)

        if (acc > best_params$accuracy) {
          best_params <- list(lambda = l, gamma = g, accuracy = acc)
        }
      }, error = function(e) NULL)
    }
  }
  return(best_params)
}

# For each sampling method
for (sampling_method in sampling_methods) {
  print(paste("Sampling method:", sampling_method))
  flush.console()

  # Apply sampling to training data
  sampled_train <- sample_data(train_data, sampling_method)

  # Find best parameters for RDA
  best_params <- find_best_rda_params(sampled_train, smoker ~ bmi + charges)

  # Train model with best parameters
  model <- rda(smoker ~ bmi+ charges, data = sampled_train,
               gamma = best_params$gamma,
               lambda = best_params$lambda)

  # Evaluate on test set
  test_metrics <- evaluate_model(model, test_data, test_data$smoker)

  # Add results
  rda_results <- rbind(rda_results, data.frame(
    Model = classification_method,
    Sampling_Method = sampling_method,
    Accuracy = test_metrics$Accuracy,
    F1 = test_metrics$F1
  ))
  rownames(rda_results) <- NULL
}

# Display the results
print(rda_results)

```



```{r}
# Load necessary libraries
library(caret)
library(e1071)
library(ROSE) # For oversampling and undersampling
library(dplyr)
library(randomForest)  # For randomForest function

# Convert "smoker" to a factor
train_data$smoker <- as.factor(train_data$smoker)
test_data$smoker <- as.factor(test_data$smoker)

# Define the evaluation function
evaluate_model <- function(model, test_data, true_labels) {
  predictions <- predict(model, newdata = test_data)
  levels <- levels(true_labels)
  metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), lev = levels)
  return(list(
    Accuracy = metrics["Accuracy"],
    F1 = metrics["Mean_F1"]
  ))
}

# Function to apply sampling techniques
sample_data <- function(data, method = "none") {
  if (method == "up") {
    # Oversampling using ROSE
    data_balanced <- ROSE(smoker ~ ., data = data, seed = 123)$data
  } else if (method == "down") {
    # Undersampling using ROSE
    data_balanced <- ovun.sample(smoker ~ ., data = data, method = "under", seed = 123)$data
  } else {
    # No sampling
    data_balanced <- data
  }
  return(data_balanced)
}

# Define sampling methods
set.seed(123)
sampling_methods <- c("none", "up", "down")
classification_method <- "randomForest"

# Initialize results dataframe
rf_results <- data.frame(
  Model = character(),
  Sampling_Method = character(),
  Accuracy = double(),
  F1 = double()
)

# For each sampling method
for (sampling_method in sampling_methods) {
  print(paste("Sampling method:", sampling_method))
  flush.console()

  # Apply sampling to training data
  sampled_train <- sample_data(train_data, sampling_method)

  # Train Random Forest model
  model <- randomForest(smoker ~ ., data = sampled_train)

  # Evaluate on test set
  test_metrics <- evaluate_model(model, test_data, test_data$smoker)

  # Add results
  rf_results <- rbind(rf_results, data.frame(
    Model = classification_method,
    Sampling_Method = sampling_method,
    Accuracy = test_metrics$Accuracy,
    F1 = test_metrics$F1
  ))
  rownames(rf_results) <- NULL
}

# Display the results
print(rf_results)

```


```{r}
merged_results <- rbind(nb_results, lda_results, qda_results, rda_results, rf_results)

# Add a column to differentiate models if needed
merged_results$Model <- c(rep("Naive Bayes", nrow(nb_results)), rep("LDA", nrow(lda_results)), rep("QDA", nrow(qda_results)), rep("RDA", nrow(rda_results)), rep("RandomForest", nrow(rf_results)))

sorted_results <- merged_results[order(-merged_results$Accuracy), ]

# Print the sorted results
print(sorted_results)
```

```{r}
# Calculate correlation between BMI category and charges
encoded_bmi <- model.matrix(~ bmi_cat - 1, data = df) %>% as.data.frame()
encoded_bmi$charges <- df$charges

# Compute the correlation matrix
correlation_matrix <- cor(encoded_bmi)

# Extract the correlations of "charges" with other variables and sort them
correlation <- correlation_matrix["charges", ] %>% sort(decreasing = TRUE)
print(correlation)
```
L'analyse de corrélation confirme cette tendance, suggérant une relation positive entre l'IMC et les dépenses médicales.


## Visualisation de la répartition des charges 

```{r}
library(dplyr)
library(readr)
library(caret)

# Load the data
df <- read.csv("data/medical_insurance.csv", sep = ",")

# Remove duplicates
df <- distinct(df)

# Encode the "smoker" and "sex" columns as binary variables
df$smoker <- as.numeric(as.factor(df$smoker)) - 1
df$sex <- as.numeric(as.factor(df$sex)) - 1

# Convert the "region" column to a numerical factor
df$region <- as.numeric(factor(df$region, levels = c("southeast", "southwest", "northeast", "northwest"))) - 1

# Standardize the "age", "children", and "bmi" columns (optional based on your preference)
scaler <- preProcess(df[, c("age", "children", "bmi")], method = c("center", "scale"))
df_quant <- predict(scaler, df[, c("age", "children", "bmi")])

# Combine the scaled quantitative data with non-quantitative columns
df_non_quant <- df %>% select(-c(age, children, bmi))
scaled_data <- cbind(df_quant, df_non_quant)

# Preview the result
head(scaled_data)

# Save the scaled data to a new CSV file
write.csv(scaled_data, "data/medical_insurance_scaled.csv", row.names = FALSE)
```
Zone bleue (Charges < 10 000) : La majorité des individus ont des dépenses médicales inférieures à 10 000. Cela montre une grande concentration de personnes avec des coûts de santé relativement bas.

Zone verte (10 000 ≤ Charges ≤ 30 000) : Un nombre modéré d'individus ont des dépenses dans cette plage, suggérant des coûts de santé intermédiaires.

Zone rouge (Charges > 30 000) : Peu de personnes ont des dépenses médicales supérieures à 30 000, représentant les cas de coûts de santé élevés.

La majorité des dépenses sont concentrées dans la zone de coûts faibles, tandis que les dépenses élevées sont rares mais significatives en termes de montant.

```{r}
ggplot(df) + 
  geom_histogram(aes(x = charges), bins = 30, fill = "blue", data = df %>% filter(charges < 10000)) +
  geom_histogram(aes(x = charges), bins = 30, fill = "green", data = df %>% filter(charges >= 10000 & charges <= 30000)) +
  geom_histogram(aes(x = charges), bins = 30, fill = "red", data = df %>% filter(charges > 30000)) +
  labs(title = "Histogram of Charges", x = "Charges", y = "Number of People")
```


## Classification sur les smokers


On essaye de gérer l'équilibrage des classes ne utilisant des poids
```{r}
class_counts <- table(df$smoker)
total_samples <- sum(class_counts)
weights <- total_samples / (2 * class_counts)  # Scaling by 2 keeps total weight as 1
weights
```



```{r}
library(caret)

# Split data into training and testing sets (e.g., 80% train, 20% test)
set.seed(123)  # For reproducibility
train_index <- createDataPartition(df$smoker, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]

# Ensure that both train and test sets have `smoker` as a factor with the same levels
train_data$smoker <- factor(train_data$smoker, levels = c(0, 1))
test_data$smoker <- factor(test_data$smoker, levels = c(0, 1))

# Calculate class weights based on the training set
class_counts <- table(train_data$smoker)
total_samples <- sum(class_counts)
weights <- total_samples / (2 * class_counts)  # Ensures total weight of 1
sample_weights <- ifelse(train_data$smoker == 0, weights[1], weights[2])

# Define training control with cross-validation
train_control <- trainControl(method = "cv", number = 5)

# Train a weighted Random Forest model
model_rf <- train(
  smoker ~ ., 
  data = train_data, 
  method = "rf", 
  trControl = train_control,
  weights = sample_weights
)

# Train a weighted Linear Discriminant Analysis (LDA) model
model_lda <- train(
  smoker ~ ., 
  data = train_data, 
  method = "lda", 
  trControl = train_control,
  weights = sample_weights
)

# Train a weighted Logistic Regression model
model_logistic <- train(
  smoker ~ ., 
  data = train_data, 
  method = "glm", 
  family = "binomial",
  trControl = train_control,
  weights = sample_weights
)

# Train a weighted Gradient Boosting model
# model_gbm <- train(
#   smoker ~ ., 
#   data = train_data, 
#   method = "gbm",
#   trControl = train_control,
#   weights = sample_weights,
#   verbose = FALSE
# )

# Model Evaluation
evaluate_model <- function(model, test_data) {
  predictions <- predict(model, newdata = test_data)
  predictions <- factor(predictions, levels = levels(test_data$smoker))  # Ensure factor levels are the same
  confusion_matrix <- confusionMatrix(predictions, test_data$smoker)
  return(confusion_matrix)
}

# Evaluate all models on the test set
cat("Random Forest Performance:\n")
print(evaluate_model(model_rf, test_data))

cat("\nLDA Performance:\n")
print(evaluate_model(model_lda, test_data))

cat("\nLogistic Regression Performance:\n")
print(evaluate_model(model_logistic, test_data))

# cat("\nGradient Boosting Performance:\n")
# print(evaluate_model(model_gbm, test_data))

```



```{r}
# Load libraries
library(dplyr)
library(caret)
library(rpart)
library(randomForest)
library(kknn)
library(e1071)
library(tidymodels)  # For feature scaling and one-hot encoding
#library(vip)  # For feature importance
set.seed(123)

# Check if 'charges' exists in the dataframe and filter out NA values
if("charges" %in% names(df)) {
  df <- df %>% filter(!is.na(charges))
} else {
  stop("The 'charges' column does not exist in the dataframe.")
}

# Add charge groups and drop "charges" column
df <- df %>% mutate(charges_group = cut(charges, breaks = c(0, 10000, 30000, Inf), labels = c(0, 1, 2)))
df <- df %>% select(-charges)

# Convert charges_group to factor for classification
df$charges_group <- as.factor(df$charges_group)

# Split data into training and testing sets
training_samples <- df$charges_group %>%
  createDataPartition(p = 0.8, list = FALSE)
training_set <- df[training_samples, ]
testing_set <- df[-training_samples, ]

# Create a recipe for preprocessing
recipe <- recipe(charges_group ~ ., data = training_set) %>%
  step_normalize(all_predictors()) %>%
  step_dummy(all_nominal_predictors())

# Apply the recipe to create a training set for modeling
training_set <- prep(recipe, training_set) %>%
  juice() %>%
  as.data.frame()

# Define train control with 5-fold cross-validation
ctrl <- trainControl(method = "cv", number = 5)

# Train each model with cross-validation and parameter tuning
models_cv <- list()

# Decision Tree
models_cv$DecisionTree <- train(charges_group ~ ., data = training_set, method = "rpart", trControl = ctrl, tuneGrid = expand.grid(cp = seq(0.01, 0.1, 0.01)))

# K-Nearest Neighbors
models_cv$KNeighbors <- train(charges_group ~ ., data = training_set, method = "kknn", trControl = ctrl,
                              tuneGrid = expand.grid(kmax = seq(1, 10, 1), distance = 2, kernel = "optimal"))


# Naive Bayes
models_cv$NaiveBayes <- train(charges_group ~ ., data = training_set, method = "nb", trControl = ctrl)

# Random Forest
# Random Forest
models_cv$RandomForest <- train(charges_group ~ ., data = df, method = "rf", trControl = ctrl)

# Extract accuracies from cross-validation results
results_cv <- sapply(models_cv, function(model) {
  max(model$results$Accuracy)  # Getting the maximum accuracy achieved during CV for each model
})

# Convert results to DataFrame for easier viewing
results_cv <- data.frame(
  Model = names(results_cv),
  Accuracy = as.numeric(results_cv)
)

print(results_cv)

# Interpret the Random Forest model
#vip(models_cv$RandomForest$finalModel)

```


```{r}
# Adjusted hyperparameter tuning grid for caret with RandomForest
# rf_grid <- expand.grid(
#   mtry = c(2, 4, 6, 8)  # mtry is the number of variables available for splitting at each tree node
# )
# 
# # Define train control with cross-validation
# ctrl <- trainControl(method = "cv", number = 3)

# # Train RandomForest model with tuning grid
# rf_model <- train(charges_group ~ ., data = train, method = "rf", trControl = ctrl, tuneGrid = rf_grid)
# 
# # Output best parameters found
# print(rf_model$bestTune)
# print(rf_model$results)

```


```{r}
# K-means clustering on the data
df_no_charges <- df %>% select(-charges_group)
set.seed(123)
wss <- sapply(1:10, function(k) {kmeans(df_no_charges, k, nstart = 10)$tot.withinss})

# Elbow plot for optimal clusters
plot(1:10, wss, type = "b", pch = 19, frame = FALSE, 
     xlab = "Number of Clusters", ylab = "Total Within Sum of Squares")
```


```{r}
# Applying k-means with optimal clusters
optimal_k <- 3
kmeans_model <- kmeans(df_no_charges, centers = optimal_k, nstart = 25)
df$cluster <- as.factor(kmeans_model$cluster)

# Create a plotting copy with 'charges' added
df_plot <- cbind(df_no_charges, charges = df$charges, cluster = as.factor(kmeans_model$cluster))

# Plot clusters with age and charges
ggplot(df_plot, aes(x = age, y = charges, color = cluster)) + 
  geom_point() + 
  labs(title = "Clusters based on Age and Charges", x = "Age", y = "Charges")

```




