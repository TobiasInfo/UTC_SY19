---
output:
  pdf_document: default
  html_document: default
---


# Jeu de données réel



## Introduction

  Ce rapport porte sur un jeu de données concernant les assurances
  médicales aux États-Unis. Nous présenterons d'abord le jeu de données.
  Ensuite, nous appliquerons des outils de machine learning.  

L'accès aux soins de santé et la couverture médicale sont des enjeux majeurs aux
États-Unis. Les compagnies d'assurance adaptent leurs offres en fonction des 
profils clients. L'analyse des données des assurés permet d'identifier les 
facteurs influençant les coûts médicaux.  

Dans le cadre de notre projet, nous avons étudié un jeu de données
disponible sur la plateforme Kaggle. Ce jeu de
données comprend diverses informations sur les assurés.  

Notre objectif principal est d'identifier les facteurs clé influençant
les coûts d'assurance maladie et d'évaluer la performance des modèles de
machine learning dans la prédiction de ces coûts. Pour atteindre cet
objectif, nous avons répondu aux questions suivantes :  

- Quelle est l'influence des variables sur les coûts médicaux ?  
- Existe-t-il des différences régionales significatives ?  
- Quel est l'impact du nombre d'enfants à charge ?  
- Comment les résultats obtenus à partir de ce jeu de données
peuvent-ils aider les compagnies d'assurance médicale ?  

Dans ce rapport, nous présentons les résultats de notre étude en suivant
la structure suivante :  
1. Exploration des données (EDA)  
2. Pré-traitement des données  
3. Application de modèles de machine learning  
4. Conclusion et perspectives  

```{r}
# Load necessary libraries
library(dplyr)
library(ggplot2)
library(reshape2)
library(caret)
library(ggpubr)
library(lattice)
library(magrittr)
library(Amelia) 
library(corrplot)
library(cowplot)
library(gridExtra)

?dplyr::filter
?stats::filter
```

```{r}
df <- read.csv("data/medical_insurance.csv", sep = ",")
df <- df %>% distinct()
```


## Visualisation de la donnée
```{r}
# Initial overview of the data
head(df)
print("Overview :")
str(df)
print("Summary :")
summary(df)
```



## Analyse exploratoire des données : EDA  

Cette section vise à mieux comprendre notre jeu de données. Pour cela,
nous entreprenons une exploration approfondie des données pour mieux
comprendre la structure et les caractéristiques via des graphiques et
des calculs statistiques.  
```{r}
df$smoker_original <- df$smoker
for (col in c("children", "smoker", "region", "sex")) {
  cat("\n", col, "\n")
  print(table(df[[col]]))
}

# Label encoding for smoker and sex columns
df$smoker <- as.numeric(factor(df$smoker)) - 1  # Convert to binary
df$sex <- as.numeric(factor(df$sex)) - 1        # Convert to binary

# One-hot encoding for the region column
df <- cbind(df, model.matrix(~region - 1, data = df))
df$region <- NULL  # Drop the original region column

# BMI Analysis
nb <- nrow(df %>% filter(bmi < 24.9))
total <- nrow(df)

q1 <- quantile(df$bmi, 0.25)
q2 <- quantile(df$bmi, 0.5)
q3 <- quantile(df$bmi, 0.75)

df$bmi_cat <- cut(df$bmi, breaks = c(-Inf, q1, q2, q3, Inf), labels = c(1, 2, 3, 4))

cat("Percentage of people with BMI less than 24.9: ", (nb / total) * 100, "\n")
print(nb)

```
### Présentation des variables :  

- **Age** : l'âge de l'assuré, exprimé en années.  

- **Sexe** : le genre de l'assuré, correspondant soit à \"male\" soit
    à \"female\".  

- **IMC (Indice de Masse Corporelle)** : une mesure du poids corporel
    par rapport à la taille, calculée selon la formule suivante :
    $IMC = \frac{poids}{taille^2}$  

- **Enfants** : le nombre d'enfants à charge de l'assuré, entre 0 et 5.  

- **Fumeur** : un indicateur binaire indiquant si l'assuré est fumeur
    ou non.  

- **Région** : la région de résidence de l'assuré, classée par NW, SW,
    SE, NE (les points cardinaux de la rose des vents).  

- **Charges** : les charges médicales associées à chaque assuré,
    exprimées dollars.  

En effectuant une exploration approfondie de ces variables, notre
objectif est d'identifier des tendances, des corrélations et des
distributions de données susceptibles d'influencer les charges médicales
des assurés. Cette analyse exhaustive nous permettra de mieux comprendre
les facteurs sous-jacents et de poser les bases nécessaires à la
modélisation dans les sections ultérieures de notre étude.  

### Analyse univariée

Au sein de cette partie, nous allons effectuer une analyse univariée qui
permet de mettre en lumière les caractéristiques individuelles de chaque
variable du jeu de données, telles que leur distribution, leur tendance
centrale et leur dispersion. Cette analyse nous aidera à mieux
comprendre les données et à identifier les éventuelles anomalies ou
valeurs aberrantes.  

::: center
::: {#tab:description:variables}
   Indicateur    Age     IMC    Enfants   Assurance
  ------------ ------- ------- --------- -----------
    Moyenne     39.22   30.66    1.10     13279.12
    Médiane     39.00   30.40    1.00      9386.16
   Ecart-Type   14.04   6.10     1.20     12110.36
    Minimum     18.00   15.96    0.00      1121.87
    Maximum     64.00   53.13    5.00     63770.43

  : Description de certaines variables
:::
:::

```{r}
d1<-ggplot(data = df,aes(x=charges)) + geom_histogram(color="black", fill="mediumorchid1", bins=10)+
labs(title="Charges distribution")

d2<-ggplot(data = df,aes(x=bmi)) + geom_histogram(color="black", fill="mediumorchid1", bins=10)+
labs(title="BMI histogram")

d3<-ggplot(data = df,aes(x=age)) + geom_histogram(color="black", fill="mediumorchid1", bins=10)+
labs(title="Age Distribution")

d4<-ggplot(data = df,aes(x=smoker)) + geom_bar(color="black", fill="mediumorchid1", bins=10)+
labs(title="Smoker Distribution") 

plot_grid(d1, d2, d3, d4, rel_widths = c(1.15, 1),ncol = 2, align = "hv")
```

#### Variables quantitatives

La moyenne et la médiane d'âge sont très proches laissant supposer que
le jeu de données se focalise sur des personnes dans une tranche d'âge
active. La médiane peut laisser penser que la distribution est assez
symétrique. L'écart-type démontre une dispersion modérée des données
autour de la moyenne.  

On remarque aussi que l'âge minimum est de 18 ans et l'âge maximum est
de 64 ans confirmant que le jeu de données se concentre sur les
personnes actives.  

Selon l'OMS (Organisation Mondiale de la Santé), l'IMC peut
être divisé en 4 catégories majeures. Un risque faible pour les
personnes ayant un IMC \< 18.5, moyen pour un IMC entre 18.5 et 24.9,
importants pour un IMC entre 25 et 29.9 et très importants pour un IMC
supérieur à 30. Ces risques correspondent respectivement aux catégories
: sous la normale, normale, surpoids, obèse.  

On remarque que la moyenne d'IMC au sein du jeu de données est
considérée comme étant dans la catégorie \"obèse\" selon les normes de
l'OMS. La médiane et l'écart-type indiquent une variabilité modérée dans
les données d'IMC.  

On remarque que 18% des personnes représentés dans le jeu de données
présentent un IMC inférieur à 24.9. On note donc que le jeu de données
comporte beaucoup de personnes avec un IMC considéré comme \"Surpoids\"
ou \"Obèse\" selon l'OMS.  

Enfin, le minimum et le maximum indiquent que notre dataset couvre une
large gamme de catégories d'IMC.  

Le nombre d'enfants dans le jeu de données varie de 0 à 5. La moyenne de
1.10 et la médiane de 1.00 nous permettent de déduire que la plupart des
personnes ont un enfant ou moins. Une analyse en composantes principales
a été réalisée sur ces trois variables, mais les résultats ne permettent
pas de réduire la dimensionnalité de notre jeu de données.  

Enfin, le prix moyen de l'assurance maladie (représenté par la variable charge 
est de 13279.12\$. Nous avons pour le premier quartile 4,746.34\$, la médiane 
9,386.16\$ et le 3e quartile 16,657.72\$, indiquant que nos données sont 
massivement réparties autour de 10000\$, avec une asymétrie vers les valeurs 
élevées. L'écart-type élevé indique une variabilité significative dans les coûts 
parmi les assurés.  

#### Variables qualitatives

Sur les 1337 individus du jeu de données, 274 (soit 20.5%) sont fumeurs.  

Concernant le sexe, cette variable est très bien répartie au niveau du
jeu de données, on retrouve en effet environ 50% d'hommes et 50% de
femmes représentés.  


#### Conclusion

Cette analyse univariée nous permet de remarquer que ce jeu de données
semble se concentrer sur des personnes actives avec une variabilité dans
l'âge, l'IMC, le nombre d'enfants et le prix de l'assurance. Il y a des
signes d'asymétrie dans certaines variables, en particulier le prix de
l'assurance.  

#### Corrélation


```{r}
library(ggplot2)
library(reshape2)

corr_matrix <- cor(df %>% select_if(is.numeric))
corr_melt <- melt(corr_matrix)
ggplot(corr_melt, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  labs(title = "Correlation Matrix Heatmap", x = "", y = "") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_blank()
  ) +
  coord_fixed()

```
Nous avons commencé par examiner la matrice de corrélation des
variables, présentée dans la figure ci-dessus,
afin de déterminer les relations linéaires entre les variables. Cette
matrice nous permet de visualiser les niveaux de corrélation entre
chaque paire de variables.  

Dans cette figure, nous nous intéressons surtout à la variable
\"charges\" et \"smoker\". Ces variables correspondent respectivement aux coûts 
d'assurance et au statut tabagique de la personne. Il semble que les trois
variables ayant la corrélation la plus forte avec les charges soient, dans
l'ordre décroissant : le statut tabagique, l'âge et l'IMC.  

### L'impact du tabagisme sur les charges


```{r}
# Ensure 'smoker_original' is a factor with the correct levels
df$smoker_original <- factor(df$smoker_original, levels = c("no", "yes"))

# Plot the histogram
ggplot(df, aes(x = charges, fill = smoker_original)) +
  geom_histogram(bins = 30, position = "identity", alpha = 0.3) +
  scale_fill_manual(values = c("no" = "blue", "yes" = "red"), name = "Smoker") +
  labs(title = "Histogram of Charges by Smoking Status",
       x = "Charges",
       y = "Number of People") +
  theme_minimal()

```

Cette figure illustre une corrélation significative
entre le prix de l'assurance et le statut tabagique d'un individu. Les
personnes non-fumeuses, représentées en bleu, ont tendance à payer des
frais médicaux moins élevés que les fumeurs, représentés en rouge. Cette
différence de coût suggère que le tabagisme est un facteur déterminant
dans la fixation des tarifs d'assurance. En effet, les fumeurs sont
généralement considérés comme présentant un risque plus élevé pour la
santé, ce qui se traduit par des coûts d'assurance plus élevés. Par
conséquent, cette figure met en évidence l'importance du statut
tabagique dans la détermination des groupes tarifaires d'assurance
maladie.  

### L'impact de l'âge sur les charges

```{r}
# Histogram of charges by age range
ggplot(df, aes(x = age, weight = charges)) +
  geom_histogram(breaks = seq(15, 70, by = 5), fill = "blue", color = "black") +
  labs(title = "Histogram of Charges by Age Range", x = "Age", y = "Charges")
```


Cet histogramme permet de constater l'évolution du prix de l'assurance
en fonction de l'âge. On remarque une relation de corrélation entre le
prix de l'assurance et l'âge. Cette relation suggère que les personnes
plus âgées ont tendance à avoir des coûts médicaux plus élevés.  


### L'impact de l'IMC sur les charges

```{r}
# Define the quartiles
q1 <- 26.22
q2 <- 30.45
q3 <- 34.77

# Filter the data for charges greater than 30,000
df_filtered <- df %>% filter(charges > 30000)

# Create BMI categories based on the quartiles
df_filtered$bmi_cat <- cut(df_filtered$bmi, breaks = c(-Inf, q1, q2, q3, Inf),
                           labels = c("Q1: <26.22", "Q2: 26.22-30.45", "Q3: 30.45-34.77", "Q4: >34.77"))

# Create the histogram
ggplot(df_filtered, aes(x = bmi_cat, fill = bmi_cat)) +
  geom_bar(position = "dodge", size = 1.2) +
  scale_fill_manual(values = c("Q1: <26.22" = "blue", "Q2: 26.22-30.45" = "green",
                               "Q3: 30.45-34.77" = "orange", "Q4: >34.77" = "red")) +
  labs(title = "Distribution of BMI Categories for Charges > $30,000",
       x = "BMI Category",
       y = "Number of People") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle = 45, hjust = 1))

```

Pour cette analyse, nous avons divisé les données en quatre catégories
en utilisant les quartiles de l'IMC, ce qui nous permet de mieux
appréhender l'impact de l'IMC sur les frais médicaux.  

Les différents quartiles d'IMC sont : $q_1=26.22$, $q_2=30.45$,
$q_3=34.77$.  

Nous observons sur la figure que 50% des 340 assurés ayant
des charges supérieures à 30 000\$ sont des personnes avec un IMC
supérieur à 34.77, tandis que 87% de ces 340 assurances sont des
personnes avec un IMC supérieur à 30.4475.  

## Analyse multivariée

Cette approche nous permet de comprendre comment différentes
combinaisons de variables peuvent influencer les coûts médicaux aux
États-Unis. En examinant ces relations plus complexes, nous pourrons
identifier des patterns et des interactions qui pourraient ne pas être
évidents dans une analyse bivariée.  

Les différents graphiques que nous avons pu réaliser pour visualiser les
liens entre l'âge, le sexe la région et le nombre d'enfants ne
démontrent pas de lien particulier. On note néanmoins une augmentation
linéaire du prix de l'assurance comme nous avions pu le constater lors
de l'analyse de la figure illustrant les charges selon l'âge.  

```{r}
# Load necessary libraries
library(ggplot2)
# Scatter plot of charges vs bmi, colored by smoker
ggplot(df, aes(x = bmi, y = charges, color = factor(smoker))) +
  geom_point() +
  theme_minimal()

```
Dans cette figure illustrant l'IMC par rapport aux charges, on révèle une forte corrélation 
entre l'IMC, le statut tabagique et les frais médicaux. Plus précisément, on peut
observer une relation linéaire entre l'âge et les coûts médicaux chez
les fumeurs, tandis que cette relation n'est pas aussi marquée chez les
non-fumeurs. Cette observation suggère que le tabagisme est un facteur
important dans l'augmentation des coûts médicaux avec l'âge, et que
l'IMC peut être un indicateur utile pour estimer les coûts médicaux
futurs chez les fumeurs.  

```{r}
ggplot(df, aes(x = factor(sex), y = charges, fill = factor(smoker))) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Spectral") +
  labs(title = "Boxplot of Charges by Sex Status", x = "Sex", y = "Charges")
```
Le boxplot des charges par statut de sexe et de tabagisme révèle des informations 
intéressantes sur les coûts des assurances maladie. En observant les médianes et 
les intervalles interquartiles, on constate qu'il n'y a pas de différence 
significative dans le prix de l'assurance maladie entre les hommes et les femmes. 
Les distributions des charges pour les deux sexes sont relativement similaires, 
indiquant que le sexe n'est pas un facteur déterminant majeur des coûts d'assurance.   

Cependant, le statut de tabagisme semble avoir un impact beaucoup plus marqué. 
Les individus fumeurs, qu'ils soient hommes ou femmes, présentent des charges 
médicales nettement plus élevées par rapport aux non-fumeurs. Les boxplots 
montrent que les fumeurs ont des médianes de charges plus élevées et des 
distributions plus larges, indiquant une plus grande variabilité et des coûts 
potentiellement plus élevés. Cette observation souligne que le tabagisme est 
un facteur important influençant les coûts des assurances maladie, indépendamment 
du sexe.  


# Transformation et encodage des variables

```{r}
library(dplyr)
library(readr)
library(caret)
library(Matrix)
library(ggplot2)
library(data.table)
library(scales)

# Load the data
df <- read.csv("data/medical_insurance.csv", sep = ",")

# Remove duplicates
df <- distinct(df)

# Encode the "smoker" and "sex" columns as binary variables
df$smoker <- as.numeric(as.factor(df$smoker)) - 1
df$sex <- as.numeric(as.factor(df$sex)) - 1

# One-hot encode the "region" column
encoded_region <- model.matrix(~ region - 1, data = df)
colnames(encoded_region) <- c("northeast", "northwest", "southeast", "southwest")
df <- cbind(df, encoded_region)

# Drop the original "region" column
df_without_region <- df[, !colnames(df) %in% "region"]
head(df_without_region)
# Standardize the "age", "bmi", and "charges" columns
scaler <- preProcess(df_without_region[, c("age", "bmi", "charges")], method = c("center", "scale"))
df_scaled_quant <- predict(scaler, df_without_region[, c("age", "bmi", "charges")])

# Combine the scaled quantitative data with non-quantitative columns
df_non_quant <- df_without_region[, !colnames(df_without_region) %in% c("age", "bmi", "charges")]
scaled_data <- cbind(df_scaled_quant, df_non_quant)

# Save the scaled data to a new CSV file
write.csv(scaled_data, "data/medical_insurance_scaled.csv", row.names = FALSE)
```

Comme nous l'avons vu, trois variables sont catégorielles : le sexe, le
statut tabagique et la région. Il faut les encoder pour pouvoir
effectuer des calculs mathématiques.

Tout d'abord le label encoding permet de transformer une colonne en un
ensemble de nombres. Ainsi, nous allons pouvoir transformer le sexe
femme/homme en 0/1, de même pour le statut tabagique. Cet encodage
pourrait induire un ordre dans des variables catégorielles sans qu'il
n'en existe un dans le monde réel, les régions n'ayant pas d'ordre, nous
allons devoir utiliser un autre encodage.

Nous allons utiliser le One hot encoding, afin de transformer une
colonne en un ensemble de colonne binaire pour chacune des valeurs. Ici,
comme nous l'avons vu lors de l'EDA, la région ne possède que quatre
valeurs donc nous n'augmentons la dimension que de 3 ce qui est
raisonnable. Une piste de réflexion est de reproduire les étapes
suivantes en utilisant du label encoding et voir s'il y a un impact sur
la précision de nos modèles.


# Modèles de machine learning

```{r}
missing_values <- colSums(is.na(df))
missing_values <- missing_values[missing_values > 0]
if (length(missing_values) > 0) {
  cat("Missing values in the dataset:\n")
  print(missing_values)
} else {
  cat("No missing values in the dataset\n")
}
```

# Suppression des outliers

Notre objectif dans cette partie est de traiter les outliers dans le but d'améliorer la performance des modèles de classification/régréssion en éliminant les valeurs atypiques qui pourraient fausser les résultats. Une fonction dédiée identifie et supprime ces outliers en se basant sur l'IQR des variables continues pertinentes, à savoir l'âge, l'indice de masse corporelle (BMI) et les charges médicales. Les données sont ainsi divisées en deux versions : avec les outliers et sans les outliers. Cela permet une comparaison directe des performances des modèles sur des jeux de données nettoyés et non nettoyés.

```{r}
# Load required libraries
library(caret)
library(e1071)
library(ROSE)
library(dplyr)
library(MASS)
library(klaR)
library(randomForest)
library(class)
library(rpart)

# Function to remove outliers
remove_outliers <- function(data) {
    data_cleaned <- data
    continuous_vars <- c("age", "bmi", "charges")

    for (var in continuous_vars) {
        Q1 <- quantile(data_cleaned[[var]], 0.25, na.rm = TRUE)
        Q3 <- quantile(data_cleaned[[var]], 0.75, na.rm = TRUE)
        IQR_val <- Q3 - Q1

        lower_bound <- Q1 - 1.5 * IQR_val
        upper_bound <- Q3 + 1.5 * IQR_val

        data_cleaned <- data_cleaned[!(data_cleaned[[var]] < lower_bound |
                                     data_cleaned[[var]] > upper_bound), ]
    }
    return(data_cleaned)
}

# Function to create datasets
create_datasets <- function(data, var_split) {
    set.seed(123)
    train_indices <- createDataPartition(data[[var_split]], p = 0.8, list = FALSE)
    train_data_with_outliers <- data[train_indices, ]
    test_data_with_outliers <- data[-train_indices, ]
    train_data_without_outliers <- remove_outliers(train_data_with_outliers)
    test_data_without_outliers <- remove_outliers(test_data_with_outliers)
    return(list(train_data_without_outliers = train_data_without_outliers, 
                train_data_with_outliers = train_data_with_outliers, 
                test_data_without_outliers = test_data_without_outliers, 
                test_data_with_outliers = test_data_with_outliers))
}
```

## Classification

Dans cette partie, l'objectif principal est de prédire si une personne est fumeuse (smoker) en fonction de ses caractéristiques (comme le BMI et les charges médicales). Pour cela, plusieurs modèles de classification sont entraînés et évalués. Ces modèles sont testés sur des jeux de données équilibrés par différentes méthodes d'échantillonnage (aucun, sur-échantillonnage, ou sous-échantillonnage), à la fois sur les données contenant des outliers et sur celles nettoyées.

La performance de chaque modèle est mesurée par trois métriques principales : Accuracy (précision globale), Precision (capacité à réduire les faux positifs), et Recall (capacité à détecter les vrais positifs).

```{r}

data <- read.csv("data/medical_insurance_scaled.csv", sep = ",")
datasets <- create_datasets(data, "smoker")
train_data_without_outliers <- datasets$train_data_without_outliers
test_data_without_outliers <- datasets$test_data_without_outliers
train_data_with_outliers <- datasets$train_data_with_outliers
test_data_with_outliers <- datasets$test_data_with_outliers

# Convert target variable to factor for all datasets
train_data_with_outliers$smoker <- as.factor(train_data_with_outliers$smoker)
test_data_with_outliers$smoker <- as.factor(test_data_with_outliers$smoker)
train_data_without_outliers$smoker <- as.factor(train_data_without_outliers$smoker)
test_data_without_outliers$smoker <- as.factor(test_data_without_outliers$smoker)

# Evaluation function
evaluate_model <- function(model_name, model, test_data, true_labels) {
    if (model_name %in% c("lda", "qda", "rda")) {
        predictions <- predict(model, newdata = test_data)$class
    } else if (model_name == "knn") {
        predictions <- knn(train = train_data[, c("bmi", "charges")], 
                         test = test_data[, c("bmi", "charges")], 
                         cl = train_data$smoker, k = 5)
    } else if (model_name == "logistic_regression") {
        probabilities <- predict(model, newdata = test_data, type = "response")
        predictions <- ifelse(probabilities > 0.5, 1, 0)
        predictions <- factor(predictions, levels = levels(true_labels))
    } else if (model_name == "decision_tree") {
        probabilities <- predict(model, newdata = test_data, type = "prob")
        predictions <- colnames(probabilities)[max.col(probabilities)]
        predictions <- factor(predictions, levels = levels(true_labels))
    } else {
        predictions <- predict(model, newdata = test_data)
    }

    levels <- levels(true_labels)
    metrics <- multiClassSummary(data.frame(pred = predictions, obs = true_labels), 
                               lev = levels)

    confusion_matrix <- table(predictions, true_labels)
    precision <- diag(confusion_matrix) / colSums(confusion_matrix)
    recall <- diag(confusion_matrix) / rowSums(confusion_matrix)

    return(list(
        Accuracy = metrics["Accuracy"],
        Precision = mean(precision),
        Recall = mean(recall)
    ))
}

# Sampling function remains the same
sample_data <- function(data, method = "none") {
    if (method == "up") {
        data_balanced <- ROSE(smoker ~ ., data = data, seed = 123)$data
    } else if (method == "down") {
        data_balanced <- ovun.sample(smoker ~ ., data = data, 
                                   method = "under", seed = 123)$data
    } else {
        data_balanced <- data
    }
    return(data_balanced)
}

# RDA parameter optimization function
find_best_rda_params <- function(train_data, formula) {
    lambdas <- seq(0, 1, by = 0.1)
    gammas <- seq(0, 0.5, by = 0.05)
    best_params <- list(lambda = 0, gamma = 0, accuracy = 0)

    for (l in lambdas) {
        for (g in gammas) {
            tryCatch({
                model <- rda(formula, data = train_data, gamma = g, lambda = l)
                preds <- predict(model, train_data)$class
                acc <- mean(preds == train_data$smoker)

                if (acc > best_params$accuracy) {
                    best_params <- list(lambda = l, gamma = g, accuracy = acc)
                }
            }, error = function(e) NULL)
        }
    }
    return(best_params)
}

# Define models
models <- list(
    naive_bayes = function(data) naiveBayes(smoker ~ bmi + charges, data = data),
    lda = function(data) lda(smoker ~ bmi + charges, data = data),
    qda = function(data) qda(smoker ~ bmi + charges, data = data),
    rda = function(data) {
        best_params <- find_best_rda_params(data, smoker ~ bmi + charges)
        rda(smoker ~ bmi + charges, data = data,
            gamma = best_params$gamma, lambda = best_params$lambda)
    },
    randomForest = function(data) randomForest(smoker ~ bmi + charges, data = data),
    logistic_regression = function(data) glm(smoker ~ bmi + charges,
                                           data = data, family = binomial),
    knn = function(data) NULL,
    svm = function(data) svm(smoker ~ bmi + charges, data = data, kernel = "linear"),
    svm_poly = function(data) svm(smoker ~ bmi + charges, data = data,
                                 kernel = "polynomial"),
    svm_gaussian = function(data) svm(smoker ~ bmi + charges, data = data,
                                    kernel = "radial"),
    decision_tree = function(data) rpart(smoker ~ bmi + charges, data = data,
                                       method = "class")
)

# Results dataframe
results <- data.frame(
    Model = character(),
    Sampling_Method = character(),
    Dataset_Type = character(),
    Accuracy = double(),
    Precision = double(),
    Recall = double(),
    stringsAsFactors = FALSE
)

# Training and evaluation loop
sampling_methods <- c("none", "up", "down")
dataset_types <- list(
    with_outliers = list(train = train_data_with_outliers, 
                        test = test_data_with_outliers),
    without_outliers = list(train = train_data_without_outliers, 
                           test = test_data_with_outliers)
)

for (dataset_name in names(dataset_types)) {
    current_dataset <- dataset_types[[dataset_name]]
    
    for (sampling_method in sampling_methods) {
        print(paste("Dataset:", dataset_name, "- Sampling method:", sampling_method))
        flush.console()
        
        sampled_train <- sample_data(current_dataset$train, sampling_method)
        
        for (model_name in names(models)) {
            print(paste("Training model:", model_name))
            flush.console()
            
            model <- models[[model_name]](sampled_train)
            
            test_metrics <- evaluate_model(model_name, model, 
                                         current_dataset$test, 
                                         current_dataset$test$smoker)
            
            results <- rbind(results, data.frame(
                Model = model_name,
                Sampling_Method = sampling_method,
                Dataset_Type = dataset_name,
                Accuracy = test_metrics$Accuracy,
                Precision = test_metrics$Precision,
                Recall = test_metrics$Recall
            ))
        }
    }
}

# Global result 
print(results[order(-results$Accuracy), ])

# Sort and display results
results_with_outliers <- results[results$Dataset_Type == "with_outliers", ]
results_without_outliers <- results[results$Dataset_Type == "without_outliers", ]

print("Results for dataset with outliers:")
print(results_with_outliers[order(-results_with_outliers$Accuracy), ])

print("\nResults for dataset without outliers:")
print(results_without_outliers[order(-results_without_outliers$Accuracy), ])

# Find best model for each dataset type
best_with_outliers <- results_with_outliers[
    which.max(results_with_outliers$Accuracy), ]
best_without_outliers <- results_without_outliers[
    which.max(results_without_outliers$Accuracy), ]

print("\nBest model for dataset with outliers:")
print(best_with_outliers)

print("\nBest model for dataset without outliers:")
print(best_without_outliers)
```

Les résultats montrent que les modèles comme randomForest et decision_tree ont tendance à obtenir les meilleures performances, particulièrement sur les données avec des outliers. Cela pourrait indiquer que ces modèles sont robustes face aux données bruitées.

En comparant les jeux de données avec et sans outliers, les performances restent relativement similaires pour certains modèles, ce qui pourrait suggérer que les outliers n'ont pas un impact significatif dans ce cas précis. Toutefois, le nettoyage des données pourrait être plus bénéfique dans des scénarios où les outliers sont plus prononcés. En effet, dans ce dataset nous n'avons que 10% d'outliers ce qui reste assez faible. Cette analyse met donc en évidence l'importance de tester plusieurs configurations pour identifier le modèle et les traitements des données les plus adaptés.


## Regression 

Dans cette partie dédiée à la régression, l'objectif est de construire et d'évaluer différents modèles de régression pour prédire les charges médicales. Les données ont été divisées de la même manière que dans la partie de classification. Cela permet de comparer les performances des modèles dans plusieurs contextes. Plusieurs algorithmes de régression ont été testés. Chaque modèle a été entraîné sur les données d'apprentissage et évalué sur les données de test à l'aide de métriques telles que MAE, MSE, RMSE, R2, et une mesure d'accuracy personnalisée.

```{r}
library(caret)
library(e1071)
library(dplyr)
library(MASS)
library(glmnet)
library(randomForest)
library(kernlab)
library(rpart)
library(FNN)

# Read the data
df_preprocess_reg <- read.csv("data/medical_insurance_scaled.csv", sep = ",")

# Create datasets
datasets <- create_datasets(df_preprocess_reg, "charges")
train_data_with_outliers <- datasets$train_data_with_outliers
test_data_with_outliers <- datasets$test_data_with_outliers
train_data_without_outliers <- datasets$train_data_without_outliers
test_data_without_outliers <- datasets$test_data_without_outliers

# Prepare data matrices
prepare_matrix_data <- function(train_data, test_data) {
    train_data$charges <- as.numeric(train_data$charges)
    test_data$charges <- as.numeric(test_data$charges)
    
    x_train <- model.matrix(charges ~ ., train_data)[, -1]
    y_train <- train_data$charges
    x_test <- model.matrix(charges ~ ., test_data)[, -1]
    
    return(list(x_train = x_train, y_train = y_train, x_test = x_test))
}

matrix_data_with_outliers <- prepare_matrix_data(train_data_with_outliers, test_data_with_outliers)
matrix_data_without_outliers <- prepare_matrix_data(train_data_without_outliers, test_data_with_outliers)

# Calculate accuracy function
calculate_accuracy <- function(predictions, true_values) {
    errors <- abs(predictions - true_values)
    max_error <- max(abs(true_values - mean(true_values)))
    accuracies <- 1 - (errors / max_error)
    mean_accuracy <- mean(accuracies) * 100
    return(mean_accuracy)
}

# Enhanced evaluation function
evaluate_model <- function(model_name, model, test_data_reg, true_labels, 
                           x_test = NULL, model_type = "standard") {
    predictions <- switch(model_type,
        "standard" = predict(model, newdata = test_data_reg),
        "regularized" = predict(model, newx = x_test),
        "knn" = model
    )

    # Handle matrix output
    if (is.matrix(predictions)) {
        predictions <- predictions[, 1]
    }

    mae <- mean(abs(predictions - true_labels))
    mse <- mean((predictions - true_labels)^2)
    rmse <- sqrt(mse)
    r_squared <- 1 - (sum((predictions - true_labels)^2) /
                     sum((true_labels - mean(true_labels))^2))
    accuracy <- calculate_accuracy(predictions, true_labels)

    return(list(
        MAE = mae,
        MSE = mse,
        RMSE = rmse,
        R_squared = r_squared,
        Accuracy = accuracy
    ))
}

# Define the models (function remains mostly the same)
models <- list(
    # Simple Linear Regression
    simple_linear = list(
        fn = function(data) {
            lm(charges ~ bmi, data = data)
        },
        type = "standard"
    ),

    # Multiple Linear Regression
    multiple_linear = list(
        fn = function(data) {
            lm(charges ~ ., data = data)
        },
        type = "standard"
    ),

    # Polynomial Regression (degree 2)
    polynomial = list(
        fn = function(data) {
            numeric_cols <- sapply(data, is.numeric)
            poly_formula <- as.formula(paste("charges ~",
                paste(paste0("poly(", names(data)[numeric_cols & names(data) != "charges"],
                              ", 2, raw = TRUE)"), collapse = " + ")))
            lm(poly_formula, data = data)
        },
        type = "standard"
    ),

    # Ridge Regression
    ridge = list(
        fn = function(data, x_train, y_train) {
            cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0)
            glmnet(x_train, y_train, alpha = 0, lambda = cv_ridge$lambda.min)
        },
        type = "regularized"
    ),

    # Lasso Regression
    lasso = list(
        fn = function(data, x_train, y_train) {
            cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1)
            glmnet(x_train, y_train, alpha = 1, lambda = cv_lasso$lambda.min)
        },
        type = "regularized"
    ),

    # Elastic Net Regression
    elastic_net = list(
        fn = function(data, x_train, y_train) {
            cv_elastic <- cv.glmnet(x_train, y_train, alpha = 0.5)
            glmnet(x_train, y_train, alpha = 0.5, lambda = cv_elastic$lambda.min)
        },
        type = "regularized"
    ),

    # Decision Tree Regression
    decision_tree = list(
        fn = function(data) {
            rpart(charges ~ ., data = data, method = "anova")
        },
        type = "standard"
    ),

    # Random Forest Regression
    random_forest = list(
        fn = function(data) {
            randomForest(charges ~ ., data = data, ntree = 500)
        },
        type = "standard"
    ),

    # Support Vector Regression
    svr = list(
        fn = function(data) {
            svm(charges ~ ., data = data, kernel = "radial")
        },
        type = "standard"
    ),

    knn = list(
        fn = function(data) {
            # Set up training control
            train_control <- trainControl(
                method = "cv",
                number = 5
            )
            
            # Train KNN model using caret
            model <- train(
                charges ~ .,
                data = data,
                method = "knn",
                trControl = train_control,
                preProcess = c("center", "scale"),
                tuneGrid = data.frame(k = c(5, 7, 9, 11, 13)),
                metric = "RMSE"
            )
            
            return(model)
        },
        type = "standard"
    ),

    # Kernel Regression
    kernel = list(
        fn = function(data) {
            ksvm(charges ~ ., data = data, kernel = "rbfdot")
        },
        type = "standard"
    )
)

# Initialize results dataframe
results <- data.frame(
    Model = character(),
    Dataset_Type = character(),
    MAE = double(),
    MSE = double(),
    RMSE = double(),
    R_squared = double(),
    Accuracy = double(),
    stringsAsFactors = FALSE
)

# Dataset types to evaluate
dataset_types <- list(
    with_outliers = list(
        train_data = train_data_with_outliers, 
        test_data = test_data_with_outliers,
        x_train = matrix_data_with_outliers$x_train,
        y_train = matrix_data_with_outliers$y_train,
        x_test = matrix_data_with_outliers$x_test
    ),
    without_outliers = list(
        train_data = train_data_without_outliers, 
        test_data = test_data_with_outliers,
        x_train = matrix_data_without_outliers$x_train,
        y_train = matrix_data_without_outliers$y_train,
        x_test = matrix_data_without_outliers$x_test
    )
)

# Train and evaluate each model for each dataset type
for (dataset_name in names(dataset_types)) {
    current_dataset <- dataset_types[[dataset_name]]
    
    for (model_name in names(models)) {
        print(paste("Dataset:", dataset_name, "- Training model:", model_name))
        flush.console()

        # Train model
        model <- tryCatch({
            if (models[[model_name]]$type == "regularized") {
                models[[model_name]]$fn(
                    current_dataset$train_data, 
                    current_dataset$x_train, 
                    current_dataset$y_train
                )
            } else {
                models[[model_name]]$fn(current_dataset$train_data)
            }
        }, error = function(e) {
            print(paste("Error in", model_name, ":", e$message))
            return(NULL)
        })

        if (!is.null(model)) {
            # Evaluate on test set
            test_metrics <- evaluate_model(
                model_name,
                model,
                current_dataset$test_data,
                current_dataset$test_data$charges,
                current_dataset$x_test,
                models[[model_name]]$type
            )

            # Add results
            results <- rbind(results, data.frame(
                Model = model_name,
                Dataset_Type = dataset_name,
                MAE = test_metrics$MAE,
                MSE = test_metrics$MSE,
                RMSE = test_metrics$RMSE,
                R_squared = test_metrics$R_squared,
                Accuracy = test_metrics$Accuracy
            ))
        }
    }
}

# Sort and format results
results$MAE <- round(results$MAE, 3)
results$MSE <- round(results$MSE, 3)
results$RMSE <- round(results$RMSE, 3)
results$R_squared <- round(results$R_squared, 3)
results$Accuracy <- round(results$Accuracy, 2)

# Separate results by dataset type
results_with_outliers <- results[results$Dataset_Type == "with_outliers", ]
results_without_outliers <- results[results$Dataset_Type == "without_outliers", ]

# Print overall results
print("Overall Results:")
print(results[order(-results$Accuracy), ])

print("\nResults for dataset with outliers:")
print(results_with_outliers[order(-results_with_outliers$Accuracy), ])

print("\nResults for dataset without outliers:")
print(results_without_outliers[order(-results_without_outliers$Accuracy), ])

# Find best model for each dataset type
best_with_outliers <- results_with_outliers[which.max(results_with_outliers$Accuracy), ]
best_without_outliers <- results_without_outliers[which.max(results_without_outliers$Accuracy), ]

print("\nBest model for dataset with outliers:")
print(best_with_outliers)

print("\nBest model for dataset without outliers:")
print(best_without_outliers)

```

Les résultats montrent que les modèles non linéaires tels que la machine à vecteurs de support (SVR) et les modèles à noyau (Kernel Regression) donnent de meilleures performances globales en termes de précision et de R2 lorsque les données contiennent des valeurs aberrantes. Dans le cas où les valeurs aberrantes ont été supprimées, les forêts aléatoires et les arbres de décision semblent être les plus performants. Cela suggère que certains modèles sont plus robustes face aux valeurs aberrantes que d'autres. De manière générale, cette comparaison met en évidence l'importance du choix du modèle et du traitement des données dans les tâches de régression.